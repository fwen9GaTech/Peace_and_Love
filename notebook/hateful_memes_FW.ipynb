{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hateful_memes_demo.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Mount into drive\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhxPauUIJPvw","executionInfo":{"status":"ok","timestamp":1651333648353,"user_tz":300,"elapsed":23185,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"c7c43937-848d-431c-990f-2ae1733f2551"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/Project/'\n","# Verify the contents of the current folder\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zVZFqqo8JVA7","executionInfo":{"status":"ok","timestamp":1651333650845,"user_tz":300,"elapsed":258,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"18ec54dd-4a1d-404b-bef2-d4cd80f98af0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project\n","hateful-memes  hateful_memes_demo.ipynb  hateful_memes.zip  no_text_50.zip\n"]}]},{"cell_type":"code","source":["# %cd ..\n","# %pwd"],"metadata":{"id":"19eie9GdJUIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wxxqk6uGWgUG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7392b4ee-5d2f-44ca-ca35-1dedc3dbb20e","executionInfo":{"status":"ok","timestamp":1651333790641,"user_tz":300,"elapsed":4715,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}}},"source":["# %%writefile setup.sh\n","\n","!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","# urllib3 is only required in colab\n","!pip install urllib3==1.25.10\n","\n","# # import hateful-memes\n","# !git clone https://github.com/czh4/hateful-memes.git\n","# %cd hateful-memes/\n","\n","# install mmf\n","# !git clone https://github.com/czh4/mmf-hateful-memes.git\n","# %cd mmf-hateful-memes/\n","# !pip install --editable .\n","# %cd ..\n","\n","# unzip dataset and move to hateful-memes\n","# !unzip datasets.zip\n","# !mv datasets hateful-memes/datasets"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Requirement already satisfied: torch==1.5.0+cu101 in /usr/local/lib/python3.7/dist-packages (1.5.0+cu101)\n","Requirement already satisfied: torchvision==0.6.0+cu101 in /usr/local/lib/python3.7/dist-packages (0.6.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0+cu101) (1.21.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0+cu101) (0.16.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.0+cu101) (7.1.2)\n","Requirement already satisfied: urllib3==1.25.10 in /usr/local/lib/python3.7/dist-packages (1.25.10)\n"]}]},{"cell_type":"code","metadata":{"id":"rp6Vu7bnXJng"},"source":["# !sh setup.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # !pwd\n","# # !unzip datasets.zip\n","# !mv datasets hateful-memes/datasets"],"metadata":{"id":"KIXZE5hDNCxb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install git+https://github.com/facebookresearch/mmf.git\n","# !pip install git+https://github.com/rizavelioglu/mmf.git\n","# !pip uninstall mmf\n","!pip install mmf@https://github.com/facebookresearch/mmf/tarball/master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"REVflQ2Y2IK8","executionInfo":{"status":"ok","timestamp":1651334030324,"user_tz":300,"elapsed":37704,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"c60e8b70-f549-49d0-eaa7-3690780c24d6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mmf@ https://github.com/facebookresearch/mmf/tarball/master\n","  Using cached https://github.com/facebookresearch/mmf/tarball/master\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f\n","  Cloning https://github.com/PyTorchLightning/pytorch-lightning (to revision 9b011606f) to /tmp/pip-install-ouzz41z_/pytorch-lightning_bbacb2d1a6044c8a8829c2fdadd7be82\n","  Running command git clone -q https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-install-ouzz41z_/pytorch-lightning_bbacb2d1a6044c8a8829c2fdadd7be82\n","\u001b[33m  WARNING: Did not find branch or tag '9b011606f', assuming revision or ref.\u001b[0m\n","  Running command git checkout -q 9b011606f\n","  Running command git submodule update --init --recursive -q\n","  From https://github.com/PyTorchLightning/lightning-tutorials\n","   * branch            290fb466de1fcc2ac6025f74b56906592911e856 -> FETCH_HEAD\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy<=1.21.4,>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.21.4)\n","Requirement already satisfied: GitPython==3.1.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.1.0)\n","Requirement already satisfied: fasttext==0.9.1 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.9.1)\n","Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.4.5)\n","Requirement already satisfied: torchvision<=0.10.0,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.10.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (5.4.8)\n","Requirement already satisfied: pillow==9.0.1 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (9.0.1)\n","Requirement already satisfied: transformers<=4.10.1,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (4.10.1)\n","Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.1.0)\n","Requirement already satisfied: pycocotools==2.0.2 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2.0.2)\n","Requirement already satisfied: datasets==1.2.1 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.2.1)\n","Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.5.3)\n","Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.0)\n","Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2.23.0)\n","Requirement already satisfied: omegaconf<=2.1,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2.1.0)\n","Requirement already satisfied: iopath==0.1.8 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.1.8)\n","Requirement already satisfied: matplotlib==3.3.4 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.3.4)\n","Requirement already satisfied: ftfy==5.8 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (5.8)\n","Requirement already satisfied: lmdb==0.98 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.98)\n","Requirement already satisfied: torch<=1.9.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.9.0)\n","Requirement already satisfied: tqdm<4.50.0,>=4.43.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (4.49.0)\n","Requirement already satisfied: torchtext==0.5.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.5.0)\n","Requirement already satisfied: torchaudio<=0.9.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.9.0)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2.8.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (4.2.0)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2022.3.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (21.3)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (6.0)\n","Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.8.1)\n","Requirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.3.2)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (6.0.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.3.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.3.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (4.11.3)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.70.12.2)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (57.4.0)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2.9.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==5.8->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.2.5)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython==3.1.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (4.0.9)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath==0.1.8->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.15.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0.2->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.29.28)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.25.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.0.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.0.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.1.96)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.8.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython==3.1.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (5.0.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from omegaconf<=2.1,>=2.0.6->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (4.8)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.3.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.44.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.0.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.8.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.17.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.4.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.37.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.2.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.0.49)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2019.12.20)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.5.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.6.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2.0.12)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.3.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (21.4.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.7.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (2022.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.1,>=3.4.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.1,>=3.4.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf@ https://github.com/facebookresearch/mmf/tarball/master) (3.1.0)\n"]}]},{"cell_type":"code","source":["# Replace the hm_convert.py file below\n","# %cd /usr/local/lib/python3.7/dist-packages/mmf_cli/hm_convert.py"],"metadata":{"id":"K-gcD_FxyZkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import hateful-memes\n","# !git clone https://github.com/czh4/hateful-memes.git\n","# %cd hateful-memes/\n","# %cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wHPOGhPjP74","executionInfo":{"status":"ok","timestamp":1650592683805,"user_tz":300,"elapsed":2,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"f2902e31-33d9-4dcc-d27e-6dae0c6228ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Project\n","%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"MwGThx_AK07z","executionInfo":{"status":"ok","timestamp":1651334042971,"user_tz":300,"elapsed":244,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"7465fd13-a791-4912-95f5-4b530d0b391d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Project'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["%cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxq4HnqQkmo7","executionInfo":{"status":"ok","timestamp":1651335959482,"user_tz":300,"elapsed":277,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"279ea392-58b8-4ec9-970b-bb4ec0de8b5d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project\n"]}]},{"cell_type":"code","source":["# !mmf_convert_hm --zip_file=\"no_text_50.zip\" --password=\"1\" --bypass_checksum 1\n","!mmf_convert_hm --zip_file=\"hateful_memes.zip\" --password=\"1\" --bypass_checksum 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6WD-iMI8NP8q","outputId":"ae6a7947-094b-4758-9ff0-056429ae06a7","executionInfo":{"status":"ok","timestamp":1651334550109,"user_tz":300,"elapsed":103748,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n","  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","Data folder is /root/.cache/torch/mmf/data\n","Zip path is hateful_memes.zip\n","Copying hateful_memes.zip\n","Unzipping hateful_memes.zip\n","Extracting the zip can take time. Sit back and relax.\n","Moving train.jsonl\n","Moving dev_seen.jsonl\n","Moving test_seen.jsonl\n","Moving dev_unseen.jsonl\n","Moving test_unseen.jsonl\n","Moving img\n"]}]},{"cell_type":"code","source":["%cd hateful-memes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2UQtrgEN_Ni","executionInfo":{"status":"ok","timestamp":1651335961839,"user_tz":300,"elapsed":3,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"55689b68-6c75-4e2f-e882-03f057a3193e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Project/hateful-memes\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7hjiR1Ot6RGW","executionInfo":{"status":"ok","timestamp":1651335963627,"user_tz":300,"elapsed":252,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"b1e1d968-5bd4-4cac-d183-a28519bef994"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["configs  ensemble  mmf-hateful-memes  README.md  save  tools\n"]}]},{"cell_type":"markdown","source":["# **Visual Bert**"],"metadata":{"id":"DPXQ0RsX0HDe"}},{"cell_type":"code","source":["!python tools/run.py config=mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml \\\n","training.batch_size=32 \\\n","model=visual_bert dataset=hateful_memes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIsQpHLz0F99","outputId":"b7715b3f-a43d-4a17-fa61-e32e06b1195f","executionInfo":{"status":"ok","timestamp":1651348147855,"user_tz":300,"elapsed":12077362,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n","  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n","\u001b[32m2022-04-30T16:27:54 | mmf.utils.configuration: \u001b[0mOverriding option config to mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml\n","\u001b[32m2022-04-30T16:27:54 | mmf.utils.configuration: \u001b[0mOverriding option training.batch_size to 32\n","\u001b[32m2022-04-30T16:27:54 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n","\u001b[32m2022-04-30T16:27:54 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","\u001b[32m2022-04-30T16:27:54 | mmf: \u001b[0mLogging to: ./save/train.log\n","\u001b[32m2022-04-30T16:27:54 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml', 'training.batch_size=32', 'model=visual_bert', 'dataset=hateful_memes'])\n","\u001b[32m2022-04-30T16:27:54 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n","\u001b[32m2022-04-30T16:27:54 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla T4\n","\u001b[32m2022-04-30T16:27:54 | mmf_cli.run: \u001b[0mUsing seed 27716496\n","\u001b[32m2022-04-30T16:27:54 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","\u001b[32m2022-04-30T16:28:01 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-30T16:28:01 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-30T16:28:01 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-30T16:28:01 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n","Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bert_model_name\": \"bert-base-uncased\",\n","  \"bypass_transformer\": false,\n","  \"classifier_dropout\": null,\n","  \"embedding_strategy\": \"plain\",\n","  \"finetune_lr_multiplier\": 1,\n","  \"freeze_base\": false,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"losses\": [\n","    \"cross_entropy\"\n","  ],\n","  \"max_position_embeddings\": 512,\n","  \"model\": \"visual_bert\",\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_strategy\": \"default\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"random_initialize\": false,\n","  \"special_visual_initialize\": true,\n","  \"training_head_type\": \"classification\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"visual_embedding_dim\": 2048,\n","  \"vocab_size\": 30522,\n","  \"zerobias\": false\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing VisualBERTBase: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing VisualBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing VisualBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.projection.bias', 'bert.embeddings.projection.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m2022-04-30T16:28:08 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n","\u001b[32m2022-04-30T16:28:08 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n","\u001b[32m2022-04-30T16:28:08 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n","\u001b[32m2022-04-30T16:28:08 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n","  (model): VisualBERTForClassification(\n","    (bert): VisualBERTBase(\n","      (embeddings): BertVisioLinguisticEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (token_type_embeddings_visual): Embedding(2, 768)\n","        (position_embeddings_visual): Embedding(512, 768)\n","        (projection): Linear(in_features=2048, out_features=768, bias=True)\n","      )\n","      (encoder): BertEncoderJit(\n","        (layer): ModuleList(\n","          (0): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayerJit(\n","            (attention): BertAttentionJit(\n","              (self): BertSelfAttentionJit(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Sequential(\n","      (0): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (1): Linear(in_features=768, out_features=2, bias=True)\n","    )\n","  )\n","  (losses): Losses(\n","    (losses): ModuleList(\n","      (0): MMFLoss(\n","        (loss_criterion): CrossEntropyLoss(\n","          (loss_fn): CrossEntropyLoss()\n","        )\n","      )\n","    )\n","  )\n",")\n","\u001b[32m2022-04-30T16:28:08 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n","\u001b[32m2022-04-30T16:28:08 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n","\u001b[32m2022-04-30T16:30:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/22000, train/hateful_memes/cross_entropy: 0.7442, train/hateful_memes/cross_entropy/avg: 0.7442, train/total_loss: 0.7442, train/total_loss/avg: 0.7442, max mem: 9175.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 0.77, time: 02m 10s 336ms, time_since_start: 02m 10s 373ms, eta: 08h 03m 48s 922ms\n","\u001b[32m2022-04-30T16:32:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/22000, train/hateful_memes/cross_entropy: 0.7442, train/hateful_memes/cross_entropy/avg: 0.7917, train/total_loss: 0.7442, train/total_loss/avg: 0.7917, max mem: 9175.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0.00001, ups: 0.72, time: 02m 19s 426ms, time_since_start: 04m 29s 800ms, eta: 08h 35m 11s 720ms\n","\u001b[32m2022-04-30T16:35:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/22000, train/hateful_memes/cross_entropy: 0.7442, train/hateful_memes/cross_entropy/avg: 0.7538, train/total_loss: 0.7442, train/total_loss/avg: 0.7538, max mem: 9175.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 24s 221ms, time_since_start: 06m 54s 022ms, eta: 08h 50m 28s 098ms\n","\u001b[32m2022-04-30T16:37:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/22000, train/hateful_memes/cross_entropy: 0.6780, train/hateful_memes/cross_entropy/avg: 0.7182, train/total_loss: 0.6780, train/total_loss/avg: 0.7182, max mem: 9175.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 24s 943ms, time_since_start: 09m 18s 965ms, eta: 08h 50m 39s 945ms\n","\u001b[32m2022-04-30T16:39:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/22000, train/hateful_memes/cross_entropy: 0.6780, train/hateful_memes/cross_entropy/avg: 0.7066, train/total_loss: 0.6780, train/total_loss/avg: 0.7066, max mem: 9175.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 24s 840ms, time_since_start: 11m 43s 805ms, eta: 08h 47m 50s 117ms\n","\u001b[32m2022-04-30T16:42:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/22000, train/hateful_memes/cross_entropy: 0.6599, train/hateful_memes/cross_entropy/avg: 0.6888, train/total_loss: 0.6599, train/total_loss/avg: 0.6888, max mem: 9175.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 24s 616ms, time_since_start: 14m 08s 422ms, eta: 08h 44m 33s 997ms\n","\u001b[32m2022-04-30T16:44:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/22000, train/hateful_memes/cross_entropy: 0.6599, train/hateful_memes/cross_entropy/avg: 0.6458, train/total_loss: 0.6599, train/total_loss/avg: 0.6458, max mem: 9175.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 042ms, time_since_start: 16m 33s 464ms, eta: 08h 43m 39s 248ms\n","\u001b[32m2022-04-30T16:47:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/22000, train/hateful_memes/cross_entropy: 0.6116, train/hateful_memes/cross_entropy/avg: 0.6188, train/total_loss: 0.6116, train/total_loss/avg: 0.6188, max mem: 9175.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 24s 606ms, time_since_start: 18m 58s 071ms, eta: 08h 39m 37s 805ms\n","\u001b[32m2022-04-30T16:49:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/22000, train/hateful_memes/cross_entropy: 0.6116, train/hateful_memes/cross_entropy/avg: 0.6061, train/total_loss: 0.6116, train/total_loss/avg: 0.6061, max mem: 9175.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 032ms, time_since_start: 21m 23s 103ms, eta: 08h 38m 42s 109ms\n","\u001b[32m2022-04-30T16:51:56 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-30T16:51:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T16:52:22 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T16:52:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T16:52:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/22000, train/hateful_memes/cross_entropy: 0.6000, train/hateful_memes/cross_entropy/avg: 0.5806, train/total_loss: 0.6000, train/total_loss/avg: 0.5806, max mem: 9175.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00003, ups: 0.53, time: 03m 09s 202ms, time_since_start: 24m 32s 306ms, eta: 11h 13m 27s 898ms\n","\u001b[32m2022-04-30T16:52:40 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-30T16:52:40 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-30T16:52:50 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 17\n","\u001b[32m2022-04-30T16:52:50 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-30T16:52:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T16:52:55 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n","\u001b[32m2022-04-30T16:53:03 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T16:53:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T16:53:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/22000, val/hateful_memes/cross_entropy: 0.7062, val/total_loss: 0.7062, val/hateful_memes/accuracy: 0.6648, val/hateful_memes/binary_f1: 0.4396, val/hateful_memes/roc_auc: 0.6894, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 27s 212ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.689353\n","\u001b[32m2022-04-30T16:55:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/22000, train/hateful_memes/cross_entropy: 0.6000, train/hateful_memes/cross_entropy/avg: 0.5475, train/total_loss: 0.6000, train/total_loss/avg: 0.5475, max mem: 9227.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 841ms, time_since_start: 27m 25s 361ms, eta: 08h 36m 39s 051ms\n","\u001b[32m2022-04-30T16:57:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/22000, train/hateful_memes/cross_entropy: 0.5044, train/hateful_memes/cross_entropy/avg: 0.5234, train/total_loss: 0.5044, train/total_loss/avg: 0.5234, max mem: 9227.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 013ms, time_since_start: 29m 49s 375ms, eta: 08h 27m 44s 071ms\n","\u001b[32m2022-04-30T17:00:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/22000, train/hateful_memes/cross_entropy: 0.5044, train/hateful_memes/cross_entropy/avg: 0.4934, train/total_loss: 0.5044, train/total_loss/avg: 0.4934, max mem: 9227.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 536ms, time_since_start: 32m 13s 912ms, eta: 08h 27m 07s 750ms\n","\u001b[32m2022-04-30T17:02:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/22000, train/hateful_memes/cross_entropy: 0.5044, train/hateful_memes/cross_entropy/avg: 0.4982, train/total_loss: 0.5044, train/total_loss/avg: 0.4982, max mem: 9227.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 113ms, time_since_start: 34m 39s 025ms, eta: 08h 26m 41s 536ms\n","\u001b[32m2022-04-30T17:05:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/22000, train/hateful_memes/cross_entropy: 0.5044, train/hateful_memes/cross_entropy/avg: 0.4733, train/total_loss: 0.5044, train/total_loss/avg: 0.4733, max mem: 9227.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 281ms, time_since_start: 37m 04s 307ms, eta: 08h 24m 49s 023ms\n","\u001b[32m2022-04-30T17:07:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/22000, train/hateful_memes/cross_entropy: 0.4295, train/hateful_memes/cross_entropy/avg: 0.4605, train/total_loss: 0.4295, train/total_loss/avg: 0.4605, max mem: 9227.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 904ms, time_since_start: 39m 29s 212ms, eta: 08h 21m 03s 142ms\n","\u001b[32m2022-04-30T17:10:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/22000, train/hateful_memes/cross_entropy: 0.4295, train/hateful_memes/cross_entropy/avg: 0.4506, train/total_loss: 0.4295, train/total_loss/avg: 0.4506, max mem: 9227.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 194ms, time_since_start: 41m 54s 406ms, eta: 08h 19m 35s 552ms\n","\u001b[32m2022-04-30T17:12:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/22000, train/hateful_memes/cross_entropy: 0.3880, train/hateful_memes/cross_entropy/avg: 0.4414, train/total_loss: 0.3880, train/total_loss/avg: 0.4414, max mem: 9227.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 585ms, time_since_start: 44m 19s 992ms, eta: 08h 18m 28s 226ms\n","\u001b[32m2022-04-30T17:14:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/22000, train/hateful_memes/cross_entropy: 0.3880, train/hateful_memes/cross_entropy/avg: 0.4307, train/total_loss: 0.3880, train/total_loss/avg: 0.4307, max mem: 9227.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 592ms, time_since_start: 46m 45s 584ms, eta: 08h 16m 01s 642ms\n","\u001b[32m2022-04-30T17:17:19 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-30T17:17:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T17:17:40 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T17:17:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T17:17:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/22000, train/hateful_memes/cross_entropy: 0.3516, train/hateful_memes/cross_entropy/avg: 0.4139, train/total_loss: 0.3516, train/total_loss/avg: 0.4139, max mem: 9227.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00005, ups: 0.58, time: 02m 53s 216ms, time_since_start: 49m 38s 801ms, eta: 09h 47m 12s 211ms\n","\u001b[32m2022-04-30T17:17:47 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-30T17:17:47 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-30T17:17:55 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 17\n","\u001b[32m2022-04-30T17:17:55 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-30T17:17:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T17:18:02 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n","\u001b[32m2022-04-30T17:18:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T17:18:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T17:18:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 0.8055, val/total_loss: 0.8055, val/hateful_memes/accuracy: 0.7037, val/hateful_memes/binary_f1: 0.4937, val/hateful_memes/roc_auc: 0.7079, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 26s 264ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.707897\n","\u001b[32m2022-04-30T17:20:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/22000, train/hateful_memes/cross_entropy: 0.2937, train/hateful_memes/cross_entropy/avg: 0.3996, train/total_loss: 0.2937, train/total_loss/avg: 0.3996, max mem: 9227.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00005, ups: 0.68, time: 02m 27s 564ms, time_since_start: 52m 32s 632ms, eta: 08h 17m 44s 623ms\n","\u001b[32m2022-04-30T17:23:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/22000, train/hateful_memes/cross_entropy: 0.2846, train/hateful_memes/cross_entropy/avg: 0.3859, train/total_loss: 0.2846, train/total_loss/avg: 0.3859, max mem: 9227.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 259ms, time_since_start: 54m 57s 892ms, eta: 08h 07m 30s 332ms\n","\u001b[32m2022-04-30T17:25:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/22000, train/hateful_memes/cross_entropy: 0.2846, train/hateful_memes/cross_entropy/avg: 0.3939, train/total_loss: 0.2846, train/total_loss/avg: 0.3939, max mem: 9227.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 991ms, time_since_start: 57m 23s 883ms, eta: 08h 07m 29s 297ms\n","\u001b[32m2022-04-30T17:27:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/22000, train/hateful_memes/cross_entropy: 0.2680, train/hateful_memes/cross_entropy/avg: 0.3803, train/total_loss: 0.2680, train/total_loss/avg: 0.3803, max mem: 9227.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 618ms, time_since_start: 59m 49s 502ms, eta: 08h 03m 46s 412ms\n","\u001b[32m2022-04-30T17:30:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/22000, train/hateful_memes/cross_entropy: 0.2580, train/hateful_memes/cross_entropy/avg: 0.3690, train/total_loss: 0.2580, train/total_loss/avg: 0.3690, max mem: 9227.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 24s 695ms, time_since_start: 01h 02m 14s 197ms, eta: 07h 58m 15s 218ms\n","\u001b[32m2022-04-30T17:32:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/22000, train/hateful_memes/cross_entropy: 0.2372, train/hateful_memes/cross_entropy/avg: 0.3633, train/total_loss: 0.2372, train/total_loss/avg: 0.3633, max mem: 9227.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 24s 749ms, time_since_start: 01h 04m 38s 947ms, eta: 07h 55m 58s 871ms\n","\u001b[32m2022-04-30T17:35:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/22000, train/hateful_memes/cross_entropy: 0.2228, train/hateful_memes/cross_entropy/avg: 0.3531, train/total_loss: 0.2228, train/total_loss/avg: 0.3531, max mem: 9227.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 24s 577ms, time_since_start: 01h 07m 03s 524ms, eta: 07h 52m 57s 773ms\n","\u001b[32m2022-04-30T17:37:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/22000, train/hateful_memes/cross_entropy: 0.2161, train/hateful_memes/cross_entropy/avg: 0.3410, train/total_loss: 0.2161, train/total_loss/avg: 0.3410, max mem: 9227.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 606ms, time_since_start: 01h 09m 29s 131ms, eta: 07h 53m 51s 701ms\n","\u001b[32m2022-04-30T17:40:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/22000, train/hateful_memes/cross_entropy: 0.1336, train/hateful_memes/cross_entropy/avg: 0.3309, train/total_loss: 0.1336, train/total_loss/avg: 0.3309, max mem: 9227.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 532ms, time_since_start: 01h 11m 54s 663ms, eta: 07h 51m 09s 286ms\n","\u001b[32m2022-04-30T17:42:28 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-30T17:42:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T17:42:45 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T17:42:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T17:42:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/22000, train/hateful_memes/cross_entropy: 0.1242, train/hateful_memes/cross_entropy/avg: 0.3211, train/total_loss: 0.1242, train/total_loss/avg: 0.3211, max mem: 9227.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00005, ups: 0.60, time: 02m 47s 369ms, time_since_start: 01h 14m 42s 033ms, eta: 08h 59m 840ms\n","\u001b[32m2022-04-30T17:42:50 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-30T17:42:50 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-30T17:43:00 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 17\n","\u001b[32m2022-04-30T17:43:00 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-30T17:43:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T17:43:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T17:43:11 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T17:43:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/22000, val/hateful_memes/cross_entropy: 1.5857, val/total_loss: 1.5857, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4276, val/hateful_memes/roc_auc: 0.6907, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 21s 063ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.707897\n","\u001b[32m2022-04-30T17:45:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3100/22000, train/hateful_memes/cross_entropy: 0.1142, train/hateful_memes/cross_entropy/avg: 0.3124, train/total_loss: 0.1142, train/total_loss/avg: 0.3124, max mem: 9227.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00005, ups: 0.68, time: 02m 27s 321ms, time_since_start: 01h 17m 30s 420ms, eta: 07h 51m 57s 113ms\n","\u001b[32m2022-04-30T17:48:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3200/22000, train/hateful_memes/cross_entropy: 0.0973, train/hateful_memes/cross_entropy/avg: 0.3044, train/total_loss: 0.0973, train/total_loss/avg: 0.3044, max mem: 9227.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 003ms, time_since_start: 01h 19m 55s 424ms, eta: 07h 42m 04s 135ms\n","\u001b[32m2022-04-30T17:50:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3300/22000, train/hateful_memes/cross_entropy: 0.0957, train/hateful_memes/cross_entropy/avg: 0.2974, train/total_loss: 0.0957, train/total_loss/avg: 0.2974, max mem: 9227.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 735ms, time_since_start: 01h 22m 21s 159ms, eta: 07h 41m 55s 821ms\n","\u001b[32m2022-04-30T17:52:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3400/22000, train/hateful_memes/cross_entropy: 0.0957, train/hateful_memes/cross_entropy/avg: 0.2938, train/total_loss: 0.0957, train/total_loss/avg: 0.2938, max mem: 9227.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 976ms, time_since_start: 01h 24m 47s 135ms, eta: 07h 40m 13s 173ms\n","\u001b[32m2022-04-30T17:55:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/22000, train/hateful_memes/cross_entropy: 0.0956, train/hateful_memes/cross_entropy/avg: 0.2855, train/total_loss: 0.0956, train/total_loss/avg: 0.2855, max mem: 9227.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 336ms, time_since_start: 01h 27m 12s 472ms, eta: 07h 35m 44s 281ms\n","\u001b[32m2022-04-30T17:57:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3600/22000, train/hateful_memes/cross_entropy: 0.0880, train/hateful_memes/cross_entropy/avg: 0.2792, train/total_loss: 0.0880, train/total_loss/avg: 0.2792, max mem: 9227.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00005, ups: 0.68, time: 02m 26s 261ms, time_since_start: 01h 29m 38s 734ms, eta: 07h 36m 09s 699ms\n","\u001b[32m2022-04-30T18:00:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3700/22000, train/hateful_memes/cross_entropy: 0.0728, train/hateful_memes/cross_entropy/avg: 0.2723, train/total_loss: 0.0728, train/total_loss/avg: 0.2723, max mem: 9227.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00005, ups: 0.68, time: 02m 26s 388ms, time_since_start: 01h 32m 05s 122ms, eta: 07h 34m 04s 593ms\n","\u001b[32m2022-04-30T18:02:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3800/22000, train/hateful_memes/cross_entropy: 0.0696, train/hateful_memes/cross_entropy/avg: 0.2654, train/total_loss: 0.0696, train/total_loss/avg: 0.2654, max mem: 9227.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 377ms, time_since_start: 01h 34m 30s 500ms, eta: 07h 28m 28s 474ms\n","\u001b[32m2022-04-30T18:05:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3900/22000, train/hateful_memes/cross_entropy: 0.0696, train/hateful_memes/cross_entropy/avg: 0.2621, train/total_loss: 0.0696, train/total_loss/avg: 0.2621, max mem: 9227.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00005, ups: 0.68, time: 02m 26s 199ms, time_since_start: 01h 36m 56s 700ms, eta: 07h 28m 32s 014ms\n","\u001b[32m2022-04-30T18:07:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-30T18:07:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T18:07:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T18:07:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T18:07:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/22000, train/hateful_memes/cross_entropy: 0.0587, train/hateful_memes/cross_entropy/avg: 0.2557, train/total_loss: 0.0587, train/total_loss/avg: 0.2557, max mem: 9227.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00005, ups: 0.59, time: 02m 49s 159ms, time_since_start: 01h 39m 45s 859ms, eta: 08h 36m 06s 385ms\n","\u001b[32m2022-04-30T18:07:54 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-30T18:07:54 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-30T18:08:04 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 17\n","\u001b[32m2022-04-30T18:08:04 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-30T18:08:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T18:08:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T18:08:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T18:08:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/22000, val/hateful_memes/cross_entropy: 1.6693, val/total_loss: 1.6693, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4444, val/hateful_memes/roc_auc: 0.6642, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 21s 784ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.707897\n","\u001b[32m2022-04-30T18:10:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4100/22000, train/hateful_memes/cross_entropy: 0.0567, train/hateful_memes/cross_entropy/avg: 0.2506, train/total_loss: 0.0567, train/total_loss/avg: 0.2506, max mem: 9227.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 26s 955ms, time_since_start: 01h 42m 34s 601ms, eta: 07h 25m 52s 273ms\n","\u001b[32m2022-04-30T18:13:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4200/22000, train/hateful_memes/cross_entropy: 0.0495, train/hateful_memes/cross_entropy/avg: 0.2449, train/total_loss: 0.0495, train/total_loss/avg: 0.2449, max mem: 9227.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 311ms, time_since_start: 01h 44m 59s 912ms, eta: 07h 18m 25s 179ms\n","\u001b[32m2022-04-30T18:15:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4300/22000, train/hateful_memes/cross_entropy: 0.0488, train/hateful_memes/cross_entropy/avg: 0.2393, train/total_loss: 0.0488, train/total_loss/avg: 0.2393, max mem: 9227.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 509ms, time_since_start: 01h 47m 25s 422ms, eta: 07h 16m 32s 990ms\n","\u001b[32m2022-04-30T18:18:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4400/22000, train/hateful_memes/cross_entropy: 0.0446, train/hateful_memes/cross_entropy/avg: 0.2339, train/total_loss: 0.0446, train/total_loss/avg: 0.2339, max mem: 9227.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 26s 402ms, time_since_start: 01h 49m 51s 824ms, eta: 07h 16m 44s 854ms\n","\u001b[32m2022-04-30T18:20:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/22000, train/hateful_memes/cross_entropy: 0.0380, train/hateful_memes/cross_entropy/avg: 0.2294, train/total_loss: 0.0380, train/total_loss/avg: 0.2294, max mem: 9227.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 26s 419ms, time_since_start: 01h 52m 18s 244ms, eta: 07h 14m 18s 988ms\n","\u001b[32m2022-04-30T18:22:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4600/22000, train/hateful_memes/cross_entropy: 0.0380, train/hateful_memes/cross_entropy/avg: 0.2284, train/total_loss: 0.0380, train/total_loss/avg: 0.2284, max mem: 9227.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 524ms, time_since_start: 01h 54m 43s 768ms, eta: 07h 09m 11s 660ms\n","\u001b[32m2022-04-30T18:25:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4700/22000, train/hateful_memes/cross_entropy: 0.0337, train/hateful_memes/cross_entropy/avg: 0.2239, train/total_loss: 0.0337, train/total_loss/avg: 0.2239, max mem: 9227.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 677ms, time_since_start: 01h 57m 09s 445ms, eta: 07h 07m 10s 638ms\n","\u001b[32m2022-04-30T18:27:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4800/22000, train/hateful_memes/cross_entropy: 0.0337, train/hateful_memes/cross_entropy/avg: 0.2195, train/total_loss: 0.0337, train/total_loss/avg: 0.2195, max mem: 9227.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 984ms, time_since_start: 01h 59m 34s 430ms, eta: 07h 02m 41s 347ms\n","\u001b[32m2022-04-30T18:30:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4900/22000, train/hateful_memes/cross_entropy: 0.0307, train/hateful_memes/cross_entropy/avg: 0.2156, train/total_loss: 0.0307, train/total_loss/avg: 0.2156, max mem: 9227.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 629ms, time_since_start: 02h 02m 060ms, eta: 07h 02m 05s 991ms\n","\u001b[32m2022-04-30T18:32:34 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-30T18:32:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T18:32:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T18:32:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T18:32:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/22000, train/hateful_memes/cross_entropy: 0.0248, train/hateful_memes/cross_entropy/avg: 0.2114, train/total_loss: 0.0248, train/total_loss/avg: 0.2114, max mem: 9227.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00004, ups: 0.58, time: 02m 51s 075ms, time_since_start: 02h 04m 51s 135ms, eta: 08h 12m 57s 269ms\n","\u001b[32m2022-04-30T18:32:59 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-30T18:32:59 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-30T18:33:09 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 17\n","\u001b[32m2022-04-30T18:33:09 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-30T18:33:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T18:33:14 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T18:33:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T18:33:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/22000, val/hateful_memes/cross_entropy: 1.8998, val/total_loss: 1.8998, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.3918, val/hateful_memes/roc_auc: 0.6898, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 21s 583ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.707897\n","\u001b[32m2022-04-30T18:35:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5100/22000, train/hateful_memes/cross_entropy: 0.0178, train/hateful_memes/cross_entropy/avg: 0.2073, train/total_loss: 0.0178, train/total_loss/avg: 0.2073, max mem: 9227.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 26s 489ms, time_since_start: 02h 07m 39s 210ms, eta: 06h 59m 37s 617ms\n","\u001b[32m2022-04-30T18:38:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5200/22000, train/hateful_memes/cross_entropy: 0.0121, train/hateful_memes/cross_entropy/avg: 0.2033, train/total_loss: 0.0121, train/total_loss/avg: 0.2033, max mem: 9227.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 174ms, time_since_start: 02h 10m 04s 385ms, eta: 06h 53m 23s 944ms\n","\u001b[32m2022-04-30T18:40:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5300/22000, train/hateful_memes/cross_entropy: 0.0121, train/hateful_memes/cross_entropy/avg: 0.2000, train/total_loss: 0.0121, train/total_loss/avg: 0.2000, max mem: 9227.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 530ms, time_since_start: 02h 12m 29s 915ms, eta: 06h 51m 56s 690ms\n","\u001b[32m2022-04-30T18:43:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5400/22000, train/hateful_memes/cross_entropy: 0.0113, train/hateful_memes/cross_entropy/avg: 0.1964, train/total_loss: 0.0113, train/total_loss/avg: 0.1964, max mem: 9227.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 351ms, time_since_start: 02h 14m 55s 267ms, eta: 06h 48m 58s 527ms\n","\u001b[32m2022-04-30T18:45:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/22000, train/hateful_memes/cross_entropy: 0.0113, train/hateful_memes/cross_entropy/avg: 0.1929, train/total_loss: 0.0113, train/total_loss/avg: 0.1929, max mem: 9227.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 699ms, time_since_start: 02h 17m 20s 966ms, eta: 06h 47m 29s 025ms\n","\u001b[32m2022-04-30T18:47:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5600/22000, train/hateful_memes/cross_entropy: 0.0113, train/hateful_memes/cross_entropy/avg: 0.1899, train/total_loss: 0.0113, train/total_loss/avg: 0.1899, max mem: 9227.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 911ms, time_since_start: 02h 19m 45s 877ms, eta: 06h 42m 49s 482ms\n","\u001b[32m2022-04-30T18:50:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5700/22000, train/hateful_memes/cross_entropy: 0.0111, train/hateful_memes/cross_entropy/avg: 0.1866, train/total_loss: 0.0111, train/total_loss/avg: 0.1866, max mem: 9227.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 187ms, time_since_start: 02h 22m 11s 065ms, eta: 06h 41m 07s 906ms\n","\u001b[32m2022-04-30T18:52:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5800/22000, train/hateful_memes/cross_entropy: 0.0066, train/hateful_memes/cross_entropy/avg: 0.1835, train/total_loss: 0.0066, train/total_loss/avg: 0.1835, max mem: 9227.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 082ms, time_since_start: 02h 24m 36s 148ms, eta: 06h 38m 22s 965ms\n","\u001b[32m2022-04-30T18:55:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5900/22000, train/hateful_memes/cross_entropy: 0.0066, train/hateful_memes/cross_entropy/avg: 0.1841, train/total_loss: 0.0066, train/total_loss/avg: 0.1841, max mem: 9227.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 463ms, time_since_start: 02h 27m 612ms, eta: 06h 34m 14s 103ms\n","\u001b[32m2022-04-30T18:57:34 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-30T18:57:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T18:57:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T18:58:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T18:58:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/22000, train/hateful_memes/cross_entropy: 0.0066, train/hateful_memes/cross_entropy/avg: 0.1811, train/total_loss: 0.0066, train/total_loss/avg: 0.1811, max mem: 9227.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00004, ups: 0.58, time: 02m 53s 195ms, time_since_start: 02h 29m 53s 807ms, eta: 07h 49m 42s 400ms\n","\u001b[32m2022-04-30T18:58:02 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-30T18:58:02 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-30T18:58:12 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 17\n","\u001b[32m2022-04-30T18:58:12 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-30T18:58:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T18:58:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T18:58:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T18:58:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/22000, val/hateful_memes/cross_entropy: 1.8722, val/total_loss: 1.8722, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4695, val/hateful_memes/roc_auc: 0.6601, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 21s 677ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.707897\n","\u001b[32m2022-04-30T19:00:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6100/22000, train/hateful_memes/cross_entropy: 0.0066, train/hateful_memes/cross_entropy/avg: 0.1786, train/total_loss: 0.0066, train/total_loss/avg: 0.1786, max mem: 9227.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 27s 847ms, time_since_start: 02h 32m 43s 334ms, eta: 06h 38m 27s 418ms\n","\u001b[32m2022-04-30T19:03:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6200/22000, train/hateful_memes/cross_entropy: 0.0053, train/hateful_memes/cross_entropy/avg: 0.1757, train/total_loss: 0.0053, train/total_loss/avg: 0.1757, max mem: 9227.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 006ms, time_since_start: 02h 35m 08s 340ms, eta: 06h 28m 20s 469ms\n","\u001b[32m2022-04-30T19:05:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6300/22000, train/hateful_memes/cross_entropy: 0.0066, train/hateful_memes/cross_entropy/avg: 0.1731, train/total_loss: 0.0066, train/total_loss/avg: 0.1731, max mem: 9227.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 139ms, time_since_start: 02h 37m 33s 480ms, eta: 06h 26m 14s 361ms\n","\u001b[32m2022-04-30T19:08:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6400/22000, train/hateful_memes/cross_entropy: 0.0121, train/hateful_memes/cross_entropy/avg: 0.1706, train/total_loss: 0.0121, train/total_loss/avg: 0.1706, max mem: 9227.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 806ms, time_since_start: 02h 39m 58s 287ms, eta: 06h 22m 53s 863ms\n","\u001b[32m2022-04-30T19:10:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6500/22000, train/hateful_memes/cross_entropy: 0.0066, train/hateful_memes/cross_entropy/avg: 0.1680, train/total_loss: 0.0066, train/total_loss/avg: 0.1680, max mem: 9227.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 342ms, time_since_start: 02h 42m 23s 630ms, eta: 06h 21m 51s 134ms\n","\u001b[32m2022-04-30T19:12:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6600/22000, train/hateful_memes/cross_entropy: 0.0053, train/hateful_memes/cross_entropy/avg: 0.1655, train/total_loss: 0.0053, train/total_loss/avg: 0.1655, max mem: 9227.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 243ms, time_since_start: 02h 44m 48s 873ms, eta: 06h 19m 07s 715ms\n","\u001b[32m2022-04-30T19:15:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6700/22000, train/hateful_memes/cross_entropy: 0.0028, train/hateful_memes/cross_entropy/avg: 0.1630, train/total_loss: 0.0028, train/total_loss/avg: 0.1630, max mem: 9227.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 868ms, time_since_start: 02h 47m 13s 742ms, eta: 06h 15m 41s 755ms\n","\u001b[32m2022-04-30T19:17:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6800/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.1607, train/total_loss: 0.0026, train/total_loss/avg: 0.1607, max mem: 9227.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 491ms, time_since_start: 02h 49m 39s 233ms, eta: 06h 14m 50s 632ms\n","\u001b[32m2022-04-30T19:20:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6900/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.1587, train/total_loss: 0.0026, train/total_loss/avg: 0.1587, max mem: 9227.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 553ms, time_since_start: 02h 52m 04s 786ms, eta: 06h 12m 32s 190ms\n","\u001b[32m2022-04-30T19:22:37 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-30T19:22:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T19:22:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T19:23:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T19:23:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7000/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.1567, train/total_loss: 0.0026, train/total_loss/avg: 0.1567, max mem: 9227.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00004, ups: 0.60, time: 02m 48s 838ms, time_since_start: 02h 54m 53s 625ms, eta: 07h 09m 16s 290ms\n","\u001b[32m2022-04-30T19:23:02 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-30T19:23:02 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-30T19:23:11 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 17\n","\u001b[32m2022-04-30T19:23:11 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-30T19:23:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T19:23:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T19:23:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T19:23:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7000/22000, val/hateful_memes/cross_entropy: 1.6918, val/total_loss: 1.6918, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4702, val/hateful_memes/roc_auc: 0.6877, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 21s 941ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.707897\n","\u001b[32m2022-04-30T19:25:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7100/22000, train/hateful_memes/cross_entropy: 0.0053, train/hateful_memes/cross_entropy/avg: 0.1556, train/total_loss: 0.0053, train/total_loss/avg: 0.1556, max mem: 9227.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 26s 079ms, time_since_start: 02h 57m 41s 648ms, eta: 06h 08m 55s 943ms\n","\u001b[32m2022-04-30T19:28:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7200/22000, train/hateful_memes/cross_entropy: 0.0066, train/hateful_memes/cross_entropy/avg: 0.1536, train/total_loss: 0.0066, train/total_loss/avg: 0.1536, max mem: 9227.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 029ms, time_since_start: 03h 05s 677ms, eta: 06h 01m 18s 751ms\n","\u001b[32m2022-04-30T19:30:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7300/22000, train/hateful_memes/cross_entropy: 0.0066, train/hateful_memes/cross_entropy/avg: 0.1516, train/total_loss: 0.0066, train/total_loss/avg: 0.1516, max mem: 9227.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 945ms, time_since_start: 03h 02m 30s 623ms, eta: 06h 01m 09s 227ms\n","\u001b[32m2022-04-30T19:33:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7400/22000, train/hateful_memes/cross_entropy: 0.0066, train/hateful_memes/cross_entropy/avg: 0.1496, train/total_loss: 0.0066, train/total_loss/avg: 0.1496, max mem: 9227.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 830ms, time_since_start: 03h 04m 55s 453ms, eta: 05h 58m 24s 690ms\n","\u001b[32m2022-04-30T19:35:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7500/22000, train/hateful_memes/cross_entropy: 0.0053, train/hateful_memes/cross_entropy/avg: 0.1476, train/total_loss: 0.0053, train/total_loss/avg: 0.1476, max mem: 9227.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 244ms, time_since_start: 03h 07m 19s 697ms, eta: 05h 54m 30s 944ms\n","\u001b[32m2022-04-30T19:37:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7600/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1457, train/total_loss: 0.0023, train/total_loss/avg: 0.1457, max mem: 9227.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 684ms, time_since_start: 03h 09m 44s 382ms, eta: 05h 53m 08s 741ms\n","\u001b[32m2022-04-30T19:40:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7700/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1438, train/total_loss: 0.0023, train/total_loss/avg: 0.1438, max mem: 9227.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 867ms, time_since_start: 03h 12m 09s 250ms, eta: 05h 51m 08s 265ms\n","\u001b[32m2022-04-30T19:42:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7800/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1420, train/total_loss: 0.0023, train/total_loss/avg: 0.1420, max mem: 9227.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 431ms, time_since_start: 03h 14m 33s 681ms, eta: 05h 47m 37s 926ms\n","\u001b[32m2022-04-30T19:45:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7900/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1403, train/total_loss: 0.0023, train/total_loss/avg: 0.1403, max mem: 9227.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 007ms, time_since_start: 03h 16m 58s 688ms, eta: 05h 46m 33s 575ms\n","\u001b[32m2022-04-30T19:47:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-30T19:47:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-30T19:47:54 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-30T19:48:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-30T19:48:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8000/22000, train/hateful_memes/cross_entropy: 0.0023, train/hateful_memes/cross_entropy/avg: 0.1385, train/total_loss: 0.0023, train/total_loss/avg: 0.1385, max mem: 9227.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00003, ups: 0.58, time: 02m 53s 101ms, time_since_start: 03h 19m 51s 790ms, eta: 06h 50m 46s 188ms\n","\u001b[32m2022-04-30T19:48:00 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-30T19:48:00 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-30T19:48:09 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 17\n","\u001b[32m2022-04-30T19:48:09 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-30T19:48:10 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n","\u001b[32m2022-04-30T19:48:10 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","\u001b[32m2022-04-30T19:48:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2022-04-30T19:48:17 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 2000\n","\u001b[32m2022-04-30T19:48:17 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 2000\n","\u001b[32m2022-04-30T19:48:17 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 8\n","\u001b[32m2022-04-30T19:48:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 2.2833, val/total_loss: 2.2833, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4522, val/hateful_memes/roc_auc: 0.6848, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 22s 611ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.707897\n","\u001b[32m2022-04-30T19:48:23 | mmf.trainers.core.training_loop: \u001b[0mEarly stopping activated\n","\u001b[32m2022-04-30T19:48:23 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n","\u001b[32m2022-04-30T19:48:23 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n","\u001b[32m2022-04-30T19:48:23 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","\u001b[32m2022-04-30T19:48:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2022-04-30T19:48:25 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 2000\n","\u001b[32m2022-04-30T19:48:25 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 2000\n","\u001b[32m2022-04-30T19:48:25 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 8\n","\u001b[32m2022-04-30T19:48:27 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n","\u001b[32m2022-04-30T19:48:27 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","100% 63/63 [00:34<00:00,  1.83it/s]\n","\u001b[32m2022-04-30T19:49:01 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished evaluation inference. Loaded 63\n","\u001b[32m2022-04-30T19:49:01 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-30T19:49:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/22000, test/hateful_memes/cross_entropy: 0.7345, test/total_loss: 0.7345, test/hateful_memes/accuracy: 0.7240, test/hateful_memes/binary_f1: 0.5640, test/hateful_memes/roc_auc: 0.7504\n","\u001b[32m2022-04-30T19:49:02 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 03h 20m 53s 527ms\n"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"NNRZeKjLDcxe"}},{"cell_type":"code","source":["!mmf_run config=\"mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml\" \\\n","model=visual_bert \\\n","dataset=hateful_memes \\\n","run_type=val \\\n","checkpoint.resume_file=save/best.ckpt \\\n","checkpoint.resume_pretrained=False"],"metadata":{"id":"46Tk7NxM0GHR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mmf_run config=\"mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml\" \\\n","model=visual_bert \\\n","dataset=hateful_memes \\\n","run_type=test \\\n","checkpoint.resume_file=save/best.ckpt \\\n","checkpoint.resume_pretrained=False"],"metadata":{"id":"yMg__x8Y0vqh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mmf_predict config=\"mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml\" \\\n","model=visual_bert \\\n","dataset=hateful_memes \\\n","run_type=val \\\n","checkpoint.resume_file=save/best.ckpt \\\n","checkpoint.resume_pretrained=False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVgH8QUO0Gmo","executionInfo":{"status":"ok","timestamp":1651335459916,"user_tz":300,"elapsed":778111,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"5dac066b-044b-4328-d472-5260c429de3c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m2022-04-30T16:04:48 | matplotlib.font_manager: \u001b[0mGenerating new fontManager, this may take some time...\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n","  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n","\u001b[32m2022-04-30T16:04:48 | mmf.utils.configuration: \u001b[0mOverriding option config to mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml\n","\u001b[32m2022-04-30T16:04:48 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n","\u001b[32m2022-04-30T16:04:48 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n","\u001b[32m2022-04-30T16:04:48 | mmf.utils.configuration: \u001b[0mOverriding option run_type to val\n","\u001b[32m2022-04-30T16:04:48 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to save/best.ckpt\n","\u001b[32m2022-04-30T16:04:48 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n","\u001b[32m2022-04-30T16:04:48 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","\u001b[32m2022-04-30T16:04:48 | mmf: \u001b[0mLogging to: ./save/train.log\n","\u001b[32m2022-04-30T16:04:48 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])\n","\u001b[32m2022-04-30T16:04:48 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n","\u001b[32m2022-04-30T16:04:48 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla T4\n","\u001b[32m2022-04-30T16:04:48 | mmf_cli.run: \u001b[0mUsing seed 27716496\n","\u001b[32m2022-04-30T16:04:48 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n","[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz ]\n","Downloading features.tar.gz: 100% 10.3G/10.3G [08:47<00:00, 19.5MB/s]\n","[ Starting checksum for features.tar.gz]\n","[ Checksum successful for features.tar.gz]\n","Unpacking features.tar.gz\n","[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n","Downloading extras.tar.gz: 100% 211k/211k [00:01<00:00, 149kB/s] \n","[ Starting checksum for extras.tar.gz]\n","[ Checksum successful for extras.tar.gz]\n","Unpacking extras.tar.gz\n","https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp59jfb4kd\n","Downloading: 100% 28.0/28.0 [00:00<00:00, 25.8kB/s]\n","storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","creating metadata file for /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp6_hml623\n","Downloading: 100% 570/570 [00:00<00:00, 401kB/s]\n","storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpuiaw2m6w\n","Downloading: 100% 232k/232k [00:00<00:00, 321kB/s]\n","storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp9z3bssts\n","Downloading: 100% 466k/466k [00:00<00:00, 646kB/s]\n","storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","\u001b[32m2022-04-30T16:16:55 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-30T16:16:55 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-30T16:16:55 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-30T16:16:55 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n","Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bert_model_name\": \"bert-base-uncased\",\n","  \"bypass_transformer\": false,\n","  \"classifier_dropout\": null,\n","  \"embedding_strategy\": \"plain\",\n","  \"finetune_lr_multiplier\": 1,\n","  \"freeze_base\": false,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"losses\": [\n","    \"cross_entropy\"\n","  ],\n","  \"max_position_embeddings\": 512,\n","  \"model\": \"visual_bert\",\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_strategy\": \"default\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"random_initialize\": false,\n","  \"special_visual_initialize\": true,\n","  \"training_head_type\": \"classification\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"visual_embedding_dim\": 2048,\n","  \"vocab_size\": 30522,\n","  \"zerobias\": false\n","}\n","\n","https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/mmf/distributed_-1/tmp55mb0vpv\n","Downloading: 100% 440M/440M [00:05<00:00, 77.3MB/s]\n","storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","creating metadata file for /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing VisualBERTBase: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing VisualBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing VisualBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.projection.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m2022-04-30T16:17:10 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n","\u001b[32m2022-04-30T16:17:10 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n","\u001b[32m2022-04-30T16:17:10 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-30T16:17:24 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-30T16:17:24 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n","\u001b[32m2022-04-30T16:17:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2022-04-30T16:17:24 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 2000\n","\u001b[32m2022-04-30T16:17:24 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 2000\n","\u001b[32m2022-04-30T16:17:24 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 8\n","\u001b[32m2022-04-30T16:17:24 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting val inference predictions\n","\u001b[32m2022-04-30T16:17:24 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","100% 9/9 [00:10<00:00,  1.16s/it]\n","\u001b[32m2022-04-30T16:17:36 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/drive/MyDrive/Project/hateful-memes/save/hateful_memes_visual_bert_27716496/reports/hateful_memes_run_val_2022-04-30T16:17:35.csv\n","\u001b[32m2022-04-30T16:17:36 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting. Loaded 9\n","\u001b[32m2022-04-30T16:17:36 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n"]}]},{"cell_type":"code","source":["!mmf_predict config=\"mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml\" \\\n","model=visual_bert \\\n","dataset=hateful_memes \\\n","run_type=test \\\n","checkpoint.resume_file=save/best.ckpt \\\n","checkpoint.resume_pretrained=False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NnKOXcYO0wOb","executionInfo":{"status":"ok","timestamp":1651335874306,"user_tz":300,"elapsed":55290,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"60ac3afe-c1fb-4a80-c20f-1bc0a8aedc5e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n","  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n","\u001b[32m2022-04-30T16:23:43 | mmf.utils.configuration: \u001b[0mOverriding option config to mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml\n","\u001b[32m2022-04-30T16:23:43 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n","\u001b[32m2022-04-30T16:23:43 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n","\u001b[32m2022-04-30T16:23:43 | mmf.utils.configuration: \u001b[0mOverriding option run_type to test\n","\u001b[32m2022-04-30T16:23:43 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to save/best.ckpt\n","\u001b[32m2022-04-30T16:23:43 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n","\u001b[32m2022-04-30T16:23:43 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","\u001b[32m2022-04-30T16:23:43 | mmf: \u001b[0mLogging to: ./save/train.log\n","\u001b[32m2022-04-30T16:23:43 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])\n","\u001b[32m2022-04-30T16:23:43 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n","\u001b[32m2022-04-30T16:23:43 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla T4\n","\u001b[32m2022-04-30T16:23:43 | mmf_cli.run: \u001b[0mUsing seed 27716496\n","\u001b[32m2022-04-30T16:23:43 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","\u001b[32m2022-04-30T16:23:50 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-30T16:23:50 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-30T16:23:50 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-30T16:23:50 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n","Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bert_model_name\": \"bert-base-uncased\",\n","  \"bypass_transformer\": false,\n","  \"classifier_dropout\": null,\n","  \"embedding_strategy\": \"plain\",\n","  \"finetune_lr_multiplier\": 1,\n","  \"freeze_base\": false,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"losses\": [\n","    \"cross_entropy\"\n","  ],\n","  \"max_position_embeddings\": 512,\n","  \"model\": \"visual_bert\",\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_strategy\": \"default\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"random_initialize\": false,\n","  \"special_visual_initialize\": true,\n","  \"training_head_type\": \"classification\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"visual_embedding_dim\": 2048,\n","  \"vocab_size\": 30522,\n","  \"zerobias\": false\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing VisualBERTBase: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing VisualBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing VisualBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.projection.weight', 'bert.embeddings.projection.bias', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.token_type_embeddings_visual.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m2022-04-30T16:23:56 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n","\u001b[32m2022-04-30T16:23:56 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n","\u001b[32m2022-04-30T16:23:56 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-30T16:23:58 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-30T16:23:58 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n","\u001b[32m2022-04-30T16:23:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2022-04-30T16:23:58 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 2000\n","\u001b[32m2022-04-30T16:23:58 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 2000\n","\u001b[32m2022-04-30T16:23:58 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 8\n","\u001b[32m2022-04-30T16:23:58 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting test inference predictions\n","\u001b[32m2022-04-30T16:23:58 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","100% 32/32 [00:33<00:00,  1.06s/it]\n","\u001b[32m2022-04-30T16:24:32 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/drive/MyDrive/Project/hateful-memes/save/hateful_memes_visual_bert_27716496/reports/hateful_memes_run_test_2022-04-30T16:24:32.csv\n","\u001b[32m2022-04-30T16:24:32 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting. Loaded 32\n","\u001b[32m2022-04-30T16:24:32 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n"]}]},{"cell_type":"markdown","source":["# **VilBert**"],"metadata":{"id":"aHFcikpzz_Ja"}},{"cell_type":"code","metadata":{"id":"MNPI6gj9kwqa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"971a1029-1d06-4930-af18-79be3cd4936c","executionInfo":{"status":"ok","timestamp":1651002801168,"user_tz":300,"elapsed":21647826,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}}},"source":["!python tools/run.py config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml model=vilbert dataset=hateful_memes"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n","  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n","\u001b[32m2022-04-26T13:34:22 | mmf.utils.configuration: \u001b[0mOverriding option config to mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml\n","\u001b[32m2022-04-26T13:34:22 | mmf.utils.configuration: \u001b[0mOverriding option model to vilbert\n","\u001b[32m2022-04-26T13:34:22 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","\u001b[32m2022-04-26T13:34:22 | mmf: \u001b[0mLogging to: ./save/train.log\n","\u001b[32m2022-04-26T13:34:22 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml', 'model=vilbert', 'dataset=hateful_memes'])\n","\u001b[32m2022-04-26T13:34:22 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n","\u001b[32m2022-04-26T13:34:22 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla P100-PCIE-16GB\n","\u001b[32m2022-04-26T13:34:22 | mmf_cli.run: \u001b[0mUsing seed 55470448\n","\u001b[32m2022-04-26T13:34:22 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","\u001b[32m2022-04-26T13:34:25 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T13:34:25 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T13:34:25 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T13:34:25 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n","Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bert_model_name\": \"bert-base-uncased\",\n","  \"bi_attention_type\": 1,\n","  \"bi_hidden_size\": 1024,\n","  \"bi_intermediate_size\": 1024,\n","  \"bi_num_attention_heads\": 8,\n","  \"bypass_transformer\": false,\n","  \"classifier_dropout\": null,\n","  \"cut_first\": \"text\",\n","  \"dynamic_attention\": false,\n","  \"embedding_strategy\": \"plain\",\n","  \"fast_mode\": false,\n","  \"finetune_lr_multiplier\": 1,\n","  \"fixed_t_layer\": 0,\n","  \"fixed_v_layer\": 0,\n","  \"freeze_base\": false,\n","  \"fusion_method\": \"mul\",\n","  \"gradient_checkpointing\": false,\n","  \"hard_cap_seq_len\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"in_batch_pairs\": false,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"losses\": [\n","    \"cross_entropy\"\n","  ],\n","  \"max_position_embeddings\": 512,\n","  \"model\": \"vilbert\",\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_negative\": 128,\n","  \"objective\": 0,\n","  \"pad_token_id\": 0,\n","  \"pooling_method\": \"mul\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"random_initialize\": false,\n","  \"special_visual_initialize\": true,\n","  \"t_biattention_id\": [\n","    6,\n","    7,\n","    8,\n","    9,\n","    10,\n","    11\n","  ],\n","  \"task_specific_tokens\": false,\n","  \"text_only\": false,\n","  \"training_head_type\": \"classification\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"v_attention_probs_dropout_prob\": 0.1,\n","  \"v_biattention_id\": [\n","    0,\n","    1,\n","    2,\n","    3,\n","    4,\n","    5\n","  ],\n","  \"v_feature_size\": 2048,\n","  \"v_hidden_act\": \"gelu\",\n","  \"v_hidden_dropout_prob\": 0.1,\n","  \"v_hidden_size\": 1024,\n","  \"v_initializer_range\": 0.02,\n","  \"v_intermediate_size\": 1024,\n","  \"v_num_attention_heads\": 8,\n","  \"v_num_hidden_layers\": 6,\n","  \"v_target_size\": 1601,\n","  \"visual_embedding_dim\": 2048,\n","  \"visual_target\": 0,\n","  \"visualization\": false,\n","  \"vocab_size\": 30522,\n","  \"with_coattention\": true\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.v_embeddings.image_embeddings.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.v_pooler.dense.weight', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.t_pooler.dense.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.v_embeddings.image_embeddings.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.v_pooler.dense.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.t_pooler.dense.weight', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m2022-04-26T13:34:31 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n","\u001b[32m2022-04-26T13:34:31 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n","\u001b[32m2022-04-26T13:34:31 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n","\u001b[32m2022-04-26T13:34:31 | mmf.trainers.mmf_trainer: \u001b[0mViLBERT(\n","  (model): ViLBERTForClassification(\n","    (bert): ViLBERTBase(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (v_embeddings): BertImageFeatureEmbeddings(\n","        (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)\n","        (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (v_layer): ModuleList(\n","          (0): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (c_layer): ModuleList(\n","          (0): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (t_pooler): BertTextPooler(\n","        (dense): Linear(in_features=768, out_features=1024, bias=True)\n","        (activation): ReLU()\n","      )\n","      (v_pooler): BertImagePooler(\n","        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","        (activation): ReLU()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Sequential(\n","      (0): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (1): Linear(in_features=1024, out_features=2, bias=True)\n","    )\n","  )\n","  (losses): Losses(\n","    (losses): ModuleList(\n","      (0): MMFLoss(\n","        (loss_criterion): CrossEntropyLoss(\n","          (loss_fn): CrossEntropyLoss()\n","        )\n","      )\n","    )\n","  )\n",")\n","\u001b[32m2022-04-26T13:34:32 | mmf.utils.general: \u001b[0mTotal Parameters: 247780354. Trained Parameters: 247780354\n","\u001b[32m2022-04-26T13:34:32 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n","\u001b[32m2022-04-26T13:36:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/22000, train/hateful_memes/cross_entropy: 0.7207, train/hateful_memes/cross_entropy/avg: 0.7207, train/total_loss: 0.7207, train/total_loss/avg: 0.7207, max mem: 10794.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 1.03, time: 01m 37s 581ms, time_since_start: 01m 37s 671ms, eta: 06h 02m 13s 746ms\n","\u001b[32m2022-04-26T13:37:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/22000, train/hateful_memes/cross_entropy: 0.6750, train/hateful_memes/cross_entropy/avg: 0.6978, train/total_loss: 0.6750, train/total_loss/avg: 0.6978, max mem: 10794.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 459ms, time_since_start: 03m 14s 131ms, eta: 05h 56m 25s 619ms\n","\u001b[32m2022-04-26T13:39:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/22000, train/hateful_memes/cross_entropy: 0.6750, train/hateful_memes/cross_entropy/avg: 0.6762, train/total_loss: 0.6750, train/total_loss/avg: 0.6762, max mem: 10794.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 332ms, time_since_start: 04m 50s 463ms, eta: 05h 54m 19s 591ms\n","\u001b[32m2022-04-26T13:40:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/22000, train/hateful_memes/cross_entropy: 0.6418, train/hateful_memes/cross_entropy/avg: 0.6676, train/total_loss: 0.6418, train/total_loss/avg: 0.6676, max mem: 10794.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 405ms, time_since_start: 06m 26s 869ms, eta: 05h 52m 57s 633ms\n","\u001b[32m2022-04-26T13:42:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/22000, train/hateful_memes/cross_entropy: 0.6430, train/hateful_memes/cross_entropy/avg: 0.6627, train/total_loss: 0.6430, train/total_loss/avg: 0.6627, max mem: 10794.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 448ms, time_since_start: 08m 03s 317ms, eta: 05h 51m 28s 875ms\n","\u001b[32m2022-04-26T13:44:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/22000, train/hateful_memes/cross_entropy: 0.6418, train/hateful_memes/cross_entropy/avg: 0.6535, train/total_loss: 0.6418, train/total_loss/avg: 0.6535, max mem: 10794.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 829ms, time_since_start: 09m 39s 147ms, eta: 05h 47m 36s 109ms\n","\u001b[32m2022-04-26T13:45:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/22000, train/hateful_memes/cross_entropy: 0.6418, train/hateful_memes/cross_entropy/avg: 0.6296, train/total_loss: 0.6418, train/total_loss/avg: 0.6296, max mem: 10794.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 319ms, time_since_start: 11m 15s 466ms, eta: 05h 47m 44s 738ms\n","\u001b[32m2022-04-26T13:47:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/22000, train/hateful_memes/cross_entropy: 0.6328, train/hateful_memes/cross_entropy/avg: 0.6146, train/total_loss: 0.6328, train/total_loss/avg: 0.6146, max mem: 10794.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 091ms, time_since_start: 12m 51s 557ms, eta: 05h 45m 17s 727ms\n","\u001b[32m2022-04-26T13:48:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/22000, train/hateful_memes/cross_entropy: 0.6328, train/hateful_memes/cross_entropy/avg: 0.6087, train/total_loss: 0.6328, train/total_loss/avg: 0.6087, max mem: 10794.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 212ms, time_since_start: 14m 27s 770ms, eta: 05h 44m 06s 055ms\n","\u001b[32m2022-04-26T13:50:35 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T13:50:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T13:50:48 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T13:51:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T13:51:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/22000, train/hateful_memes/cross_entropy: 0.6076, train/hateful_memes/cross_entropy/avg: 0.5951, train/total_loss: 0.6076, train/total_loss/avg: 0.5951, max mem: 10794.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00001, ups: 0.63, time: 02m 39s 636ms, time_since_start: 17m 07s 407ms, eta: 09h 28m 13s 506ms\n","\u001b[32m2022-04-26T13:51:39 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T13:51:39 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T13:51:45 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T13:51:45 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T13:51:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T13:51:58 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n","\u001b[32m2022-04-26T13:52:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T13:53:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T13:53:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/22000, val/hateful_memes/cross_entropy: 0.7161, val/total_loss: 0.7161, val/hateful_memes/accuracy: 0.6463, val/hateful_memes/binary_f1: 0.4527, val/hateful_memes/roc_auc: 0.6235, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 01m 22s 489ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.623485\n","\u001b[32m2022-04-26T13:54:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/22000, train/hateful_memes/cross_entropy: 0.6076, train/hateful_memes/cross_entropy/avg: 0.5811, train/total_loss: 0.6076, train/total_loss/avg: 0.5811, max mem: 10794.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00001, ups: 1.01, time: 01m 39s 500ms, time_since_start: 20m 09s 398ms, eta: 05h 52m 29s 039ms\n","\u001b[32m2022-04-26T13:56:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/22000, train/hateful_memes/cross_entropy: 0.5612, train/hateful_memes/cross_entropy/avg: 0.5701, train/total_loss: 0.5612, train/total_loss/avg: 0.5701, max mem: 10794.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 024ms, time_since_start: 21m 45s 422ms, eta: 05h 38m 32s 688ms\n","\u001b[32m2022-04-26T13:57:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/22000, train/hateful_memes/cross_entropy: 0.5612, train/hateful_memes/cross_entropy/avg: 0.5607, train/total_loss: 0.5612, train/total_loss/avg: 0.5607, max mem: 10794.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 213ms, time_since_start: 23m 21s 636ms, eta: 05h 37m 34s 762ms\n","\u001b[32m2022-04-26T13:59:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/22000, train/hateful_memes/cross_entropy: 0.5612, train/hateful_memes/cross_entropy/avg: 0.5618, train/total_loss: 0.5612, train/total_loss/avg: 0.5618, max mem: 10794.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 772ms, time_since_start: 24m 57s 409ms, eta: 05h 34m 24s 590ms\n","\u001b[32m2022-04-26T14:01:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/22000, train/hateful_memes/cross_entropy: 0.5612, train/hateful_memes/cross_entropy/avg: 0.5387, train/total_loss: 0.5612, train/total_loss/avg: 0.5387, max mem: 10794.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 879ms, time_since_start: 26m 33s 288ms, eta: 05h 33m 09s 362ms\n","\u001b[32m2022-04-26T14:02:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/22000, train/hateful_memes/cross_entropy: 0.5092, train/hateful_memes/cross_entropy/avg: 0.5333, train/total_loss: 0.5092, train/total_loss/avg: 0.5333, max mem: 10794.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 482ms, time_since_start: 28m 08s 770ms, eta: 05h 30m 09s 589ms\n","\u001b[32m2022-04-26T14:04:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/22000, train/hateful_memes/cross_entropy: 0.5092, train/hateful_memes/cross_entropy/avg: 0.5177, train/total_loss: 0.5092, train/total_loss/avg: 0.5177, max mem: 10794.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 809ms, time_since_start: 29m 44s 580ms, eta: 05h 29m 39s 874ms\n","\u001b[32m2022-04-26T14:05:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/22000, train/hateful_memes/cross_entropy: 0.4866, train/hateful_memes/cross_entropy/avg: 0.5017, train/total_loss: 0.4866, train/total_loss/avg: 0.5017, max mem: 10794.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 810ms, time_since_start: 31m 20s 390ms, eta: 05h 28m 02s 728ms\n","\u001b[32m2022-04-26T14:07:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/22000, train/hateful_memes/cross_entropy: 0.4866, train/hateful_memes/cross_entropy/avg: 0.4863, train/total_loss: 0.4866, train/total_loss/avg: 0.4863, max mem: 10794.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 606ms, time_since_start: 32m 55s 996ms, eta: 05h 25m 43s 522ms\n","\u001b[32m2022-04-26T14:09:03 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T14:09:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T14:09:16 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T14:09:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T14:09:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/22000, train/hateful_memes/cross_entropy: 0.4732, train/hateful_memes/cross_entropy/avg: 0.4680, train/total_loss: 0.4732, train/total_loss/avg: 0.4680, max mem: 10794.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00001, ups: 0.82, time: 02m 02s 289ms, time_since_start: 34m 58s 286ms, eta: 06h 54m 33s 787ms\n","\u001b[32m2022-04-26T14:09:30 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T14:09:30 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T14:09:36 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T14:09:36 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T14:09:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T14:09:50 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n","\u001b[32m2022-04-26T14:10:03 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T14:10:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T14:10:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/22000, val/hateful_memes/cross_entropy: 0.9333, val/total_loss: 0.9333, val/hateful_memes/accuracy: 0.6796, val/hateful_memes/binary_f1: 0.4290, val/hateful_memes/roc_auc: 0.6928, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 47s 543ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.692765\n","\u001b[32m2022-04-26T14:11:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/22000, train/hateful_memes/cross_entropy: 0.4528, train/hateful_memes/cross_entropy/avg: 0.4659, train/total_loss: 0.4528, train/total_loss/avg: 0.4659, max mem: 10794.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00001, ups: 1.01, time: 01m 39s 232ms, time_since_start: 37m 25s 064ms, eta: 05h 34m 42s 991ms\n","\u001b[32m2022-04-26T14:13:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/22000, train/hateful_memes/cross_entropy: 0.4495, train/hateful_memes/cross_entropy/avg: 0.4525, train/total_loss: 0.4495, train/total_loss/avg: 0.4525, max mem: 10794.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 869ms, time_since_start: 39m 933ms, eta: 05h 21m 44s 923ms\n","\u001b[32m2022-04-26T14:15:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/22000, train/hateful_memes/cross_entropy: 0.4469, train/hateful_memes/cross_entropy/avg: 0.4425, train/total_loss: 0.4469, train/total_loss/avg: 0.4425, max mem: 10794.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 910ms, time_since_start: 40m 36s 844ms, eta: 05h 20m 15s 636ms\n","\u001b[32m2022-04-26T14:16:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/22000, train/hateful_memes/cross_entropy: 0.4410, train/hateful_memes/cross_entropy/avg: 0.4351, train/total_loss: 0.4410, train/total_loss/avg: 0.4351, max mem: 10794.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 780ms, time_since_start: 42m 12s 625ms, eta: 05h 18m 12s 114ms\n","\u001b[32m2022-04-26T14:18:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/22000, train/hateful_memes/cross_entropy: 0.4243, train/hateful_memes/cross_entropy/avg: 0.4218, train/total_loss: 0.4243, train/total_loss/avg: 0.4218, max mem: 10794.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 709ms, time_since_start: 43m 48s 334ms, eta: 05h 16m 20s 567ms\n","\u001b[32m2022-04-26T14:19:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/22000, train/hateful_memes/cross_entropy: 0.2686, train/hateful_memes/cross_entropy/avg: 0.4137, train/total_loss: 0.2686, train/total_loss/avg: 0.4137, max mem: 10794.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 704ms, time_since_start: 45m 24s 038ms, eta: 05h 14m 42s 255ms\n","\u001b[32m2022-04-26T14:21:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/22000, train/hateful_memes/cross_entropy: 0.2642, train/hateful_memes/cross_entropy/avg: 0.4007, train/total_loss: 0.2642, train/total_loss/avg: 0.4007, max mem: 10794.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 237ms, time_since_start: 46m 59s 276ms, eta: 05h 11m 33s 386ms\n","\u001b[32m2022-04-26T14:23:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/22000, train/hateful_memes/cross_entropy: 0.2282, train/hateful_memes/cross_entropy/avg: 0.3900, train/total_loss: 0.2282, train/total_loss/avg: 0.3900, max mem: 10794.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 536ms, time_since_start: 48m 34s 813ms, eta: 05h 10m 54s 842ms\n","\u001b[32m2022-04-26T14:24:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/22000, train/hateful_memes/cross_entropy: 0.2224, train/hateful_memes/cross_entropy/avg: 0.3782, train/total_loss: 0.2224, train/total_loss/avg: 0.3782, max mem: 10794.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 653ms, time_since_start: 50m 10s 466ms, eta: 05h 09m 40s 422ms\n","\u001b[32m2022-04-26T14:26:17 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T14:26:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T14:26:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T14:26:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T14:26:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/22000, train/hateful_memes/cross_entropy: 0.2150, train/hateful_memes/cross_entropy/avg: 0.3691, train/total_loss: 0.2150, train/total_loss/avg: 0.3691, max mem: 10794.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00001, ups: 0.83, time: 02m 730ms, time_since_start: 52m 11s 203ms, eta: 06h 28m 49s 912ms\n","\u001b[32m2022-04-26T14:26:43 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T14:26:43 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T14:26:49 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T14:26:49 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T14:26:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T14:27:03 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n","\u001b[32m2022-04-26T14:27:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T14:27:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T14:27:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/22000, val/hateful_memes/cross_entropy: 1.2545, val/total_loss: 1.2545, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.4699, val/hateful_memes/roc_auc: 0.7004, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 47s 142ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T14:29:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3100/22000, train/hateful_memes/cross_entropy: 0.2110, train/hateful_memes/cross_entropy/avg: 0.3582, train/total_loss: 0.2110, train/total_loss/avg: 0.3582, max mem: 10794.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 306ms, time_since_start: 54m 36s 653ms, eta: 05h 14m 55s 765ms\n","\u001b[32m2022-04-26T14:30:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3200/22000, train/hateful_memes/cross_entropy: 0.2104, train/hateful_memes/cross_entropy/avg: 0.3479, train/total_loss: 0.2104, train/total_loss/avg: 0.3479, max mem: 10794.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 889ms, time_since_start: 56m 12s 542ms, eta: 05h 05m 33s 640ms\n","\u001b[32m2022-04-26T14:32:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3300/22000, train/hateful_memes/cross_entropy: 0.1717, train/hateful_memes/cross_entropy/avg: 0.3382, train/total_loss: 0.1717, train/total_loss/avg: 0.3382, max mem: 10794.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 092ms, time_since_start: 57m 48s 635ms, eta: 05h 04m 34s 783ms\n","\u001b[32m2022-04-26T14:33:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3400/22000, train/hateful_memes/cross_entropy: 0.1189, train/hateful_memes/cross_entropy/avg: 0.3292, train/total_loss: 0.1189, train/total_loss/avg: 0.3292, max mem: 10794.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 912ms, time_since_start: 59m 24s 547ms, eta: 05h 02m 23s 030ms\n","\u001b[32m2022-04-26T14:35:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3500/22000, train/hateful_memes/cross_entropy: 0.1043, train/hateful_memes/cross_entropy/avg: 0.3199, train/total_loss: 0.1043, train/total_loss/avg: 0.3199, max mem: 10794.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 668ms, time_since_start: 01h 01m 216ms, eta: 04h 59m 59s 614ms\n","\u001b[32m2022-04-26T14:37:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3600/22000, train/hateful_memes/cross_entropy: 0.1040, train/hateful_memes/cross_entropy/avg: 0.3117, train/total_loss: 0.1040, train/total_loss/avg: 0.3117, max mem: 10794.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 650ms, time_since_start: 01h 02m 35s 867ms, eta: 04h 58m 18s 949ms\n","\u001b[32m2022-04-26T14:38:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3700/22000, train/hateful_memes/cross_entropy: 0.1020, train/hateful_memes/cross_entropy/avg: 0.3042, train/total_loss: 0.1020, train/total_loss/avg: 0.3042, max mem: 10794.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 612ms, time_since_start: 01h 04m 11s 479ms, eta: 04h 56m 34s 490ms\n","\u001b[32m2022-04-26T14:40:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3800/22000, train/hateful_memes/cross_entropy: 0.0960, train/hateful_memes/cross_entropy/avg: 0.2987, train/total_loss: 0.0960, train/total_loss/avg: 0.2987, max mem: 10794.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 132ms, time_since_start: 01h 05m 46s 612ms, eta: 04h 53m 28s 522ms\n","\u001b[32m2022-04-26T14:41:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3900/22000, train/hateful_memes/cross_entropy: 0.0606, train/hateful_memes/cross_entropy/avg: 0.2912, train/total_loss: 0.0606, train/total_loss/avg: 0.2912, max mem: 10794.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 706ms, time_since_start: 01h 07m 22s 318ms, eta: 04h 53m 37s 277ms\n","\u001b[32m2022-04-26T14:43:29 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T14:43:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T14:43:41 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T14:43:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T14:43:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/22000, train/hateful_memes/cross_entropy: 0.0490, train/hateful_memes/cross_entropy/avg: 0.2852, train/total_loss: 0.0490, train/total_loss/avg: 0.2852, max mem: 10794.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00001, ups: 0.85, time: 01m 58s 991ms, time_since_start: 01h 09m 21s 310ms, eta: 06h 03m 02s 662ms\n","\u001b[32m2022-04-26T14:43:53 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T14:43:53 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T14:43:59 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T14:43:59 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T14:44:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T14:44:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T14:44:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T14:44:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4000/22000, val/hateful_memes/cross_entropy: 1.6924, val/total_loss: 1.6924, val/hateful_memes/accuracy: 0.6926, val/hateful_memes/binary_f1: 0.5060, val/hateful_memes/roc_auc: 0.6766, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 31s 599ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T14:46:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4100/22000, train/hateful_memes/cross_entropy: 0.0483, train/hateful_memes/cross_entropy/avg: 0.2785, train/total_loss: 0.0483, train/total_loss/avg: 0.2785, max mem: 10794.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 654ms, time_since_start: 01h 11m 31s 574ms, eta: 04h 59m 19s 327ms\n","\u001b[32m2022-04-26T14:47:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4200/22000, train/hateful_memes/cross_entropy: 0.0483, train/hateful_memes/cross_entropy/avg: 0.2733, train/total_loss: 0.0483, train/total_loss/avg: 0.2733, max mem: 10794.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 234ms, time_since_start: 01h 13m 07s 808ms, eta: 04h 50m 20s 860ms\n","\u001b[32m2022-04-26T14:49:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4300/22000, train/hateful_memes/cross_entropy: 0.0483, train/hateful_memes/cross_entropy/avg: 0.2696, train/total_loss: 0.0483, train/total_loss/avg: 0.2696, max mem: 10794.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 690ms, time_since_start: 01h 14m 43s 499ms, eta: 04h 47m 05s 236ms\n","\u001b[32m2022-04-26T14:50:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4400/22000, train/hateful_memes/cross_entropy: 0.0356, train/hateful_memes/cross_entropy/avg: 0.2638, train/total_loss: 0.0356, train/total_loss/avg: 0.2638, max mem: 10794.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 186ms, time_since_start: 01h 16m 19s 686ms, eta: 04h 46m 56s 681ms\n","\u001b[32m2022-04-26T14:52:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4500/22000, train/hateful_memes/cross_entropy: 0.0331, train/hateful_memes/cross_entropy/avg: 0.2580, train/total_loss: 0.0331, train/total_loss/avg: 0.2580, max mem: 10794.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 220ms, time_since_start: 01h 17m 55s 906ms, eta: 04h 45m 24s 823ms\n","\u001b[32m2022-04-26T14:54:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4600/22000, train/hateful_memes/cross_entropy: 0.0331, train/hateful_memes/cross_entropy/avg: 0.2531, train/total_loss: 0.0331, train/total_loss/avg: 0.2531, max mem: 10794.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 854ms, time_since_start: 01h 19m 31s 761ms, eta: 04h 42m 42s 266ms\n","\u001b[32m2022-04-26T14:55:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4700/22000, train/hateful_memes/cross_entropy: 0.0331, train/hateful_memes/cross_entropy/avg: 0.2491, train/total_loss: 0.0331, train/total_loss/avg: 0.2491, max mem: 10794.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 868ms, time_since_start: 01h 21m 07s 630ms, eta: 04h 41m 07s 213ms\n","\u001b[32m2022-04-26T14:57:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4800/22000, train/hateful_memes/cross_entropy: 0.0306, train/hateful_memes/cross_entropy/avg: 0.2444, train/total_loss: 0.0306, train/total_loss/avg: 0.2444, max mem: 10794.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 455ms, time_since_start: 01h 22m 43s 085ms, eta: 04h 38m 17s 493ms\n","\u001b[32m2022-04-26T14:58:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 4900/22000, train/hateful_memes/cross_entropy: 0.0299, train/hateful_memes/cross_entropy/avg: 0.2395, train/total_loss: 0.0299, train/total_loss/avg: 0.2395, max mem: 10794.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 941ms, time_since_start: 01h 24m 19s 027ms, eta: 04h 38m 04s 862ms\n","\u001b[32m2022-04-26T15:00:26 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T15:00:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T15:00:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T15:00:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T15:00:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/22000, train/hateful_memes/cross_entropy: 0.0268, train/hateful_memes/cross_entropy/avg: 0.2352, train/total_loss: 0.0268, train/total_loss/avg: 0.2352, max mem: 10794.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00001, ups: 0.83, time: 02m 668ms, time_since_start: 01h 26m 19s 696ms, eta: 05h 47m 42s 435ms\n","\u001b[32m2022-04-26T15:00:51 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T15:00:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T15:00:59 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T15:00:59 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T15:00:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T15:01:12 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T15:01:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T15:01:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5000/22000, val/hateful_memes/cross_entropy: 1.8863, val/total_loss: 1.8863, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.4854, val/hateful_memes/roc_auc: 0.6959, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 32s 518ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T15:03:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5100/22000, train/hateful_memes/cross_entropy: 0.0266, train/hateful_memes/cross_entropy/avg: 0.2308, train/total_loss: 0.0266, train/total_loss/avg: 0.2308, max mem: 10794.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 275ms, time_since_start: 01h 28m 30s 492ms, eta: 04h 41m 30s 974ms\n","\u001b[32m2022-04-26T15:04:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5200/22000, train/hateful_memes/cross_entropy: 0.0256, train/hateful_memes/cross_entropy/avg: 0.2267, train/total_loss: 0.0256, train/total_loss/avg: 0.2267, max mem: 10794.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 098ms, time_since_start: 01h 30m 06s 591ms, eta: 04h 33m 39s 026ms\n","\u001b[32m2022-04-26T15:06:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5300/22000, train/hateful_memes/cross_entropy: 0.0256, train/hateful_memes/cross_entropy/avg: 0.2231, train/total_loss: 0.0256, train/total_loss/avg: 0.2231, max mem: 10794.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 152ms, time_since_start: 01h 31m 42s 743ms, eta: 04h 32m 10s 417ms\n","\u001b[32m2022-04-26T15:07:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5400/22000, train/hateful_memes/cross_entropy: 0.0248, train/hateful_memes/cross_entropy/avg: 0.2190, train/total_loss: 0.0248, train/total_loss/avg: 0.2190, max mem: 10794.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 568ms, time_since_start: 01h 33m 18s 312ms, eta: 04h 28m 54s 021ms\n","\u001b[32m2022-04-26T15:09:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5500/22000, train/hateful_memes/cross_entropy: 0.0256, train/hateful_memes/cross_entropy/avg: 0.2177, train/total_loss: 0.0256, train/total_loss/avg: 0.2177, max mem: 10794.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 071ms, time_since_start: 01h 34m 54s 383ms, eta: 04h 28m 41s 296ms\n","\u001b[32m2022-04-26T15:11:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5600/22000, train/hateful_memes/cross_entropy: 0.0248, train/hateful_memes/cross_entropy/avg: 0.2139, train/total_loss: 0.0248, train/total_loss/avg: 0.2139, max mem: 10794.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 004ms, time_since_start: 01h 36m 30s 388ms, eta: 04h 26m 52s 406ms\n","\u001b[32m2022-04-26T15:12:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5700/22000, train/hateful_memes/cross_entropy: 0.0218, train/hateful_memes/cross_entropy/avg: 0.2105, train/total_loss: 0.0218, train/total_loss/avg: 0.2105, max mem: 10794.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 026ms, time_since_start: 01h 38m 06s 414ms, eta: 04h 25m 18s 431ms\n","\u001b[32m2022-04-26T15:14:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5800/22000, train/hateful_memes/cross_entropy: 0.0184, train/hateful_memes/cross_entropy/avg: 0.2070, train/total_loss: 0.0184, train/total_loss/avg: 0.2070, max mem: 10794.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 022ms, time_since_start: 01h 39m 42s 437ms, eta: 04h 23m 40s 059ms\n","\u001b[32m2022-04-26T15:15:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 5900/22000, train/hateful_memes/cross_entropy: 0.0184, train/hateful_memes/cross_entropy/avg: 0.2035, train/total_loss: 0.0184, train/total_loss/avg: 0.2035, max mem: 10794.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 626ms, time_since_start: 01h 41m 18s 064ms, eta: 04h 20m 57s 656ms\n","\u001b[32m2022-04-26T15:17:25 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T15:17:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T15:17:37 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T15:17:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T15:17:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/22000, train/hateful_memes/cross_entropy: 0.0184, train/hateful_memes/cross_entropy/avg: 0.2016, train/total_loss: 0.0184, train/total_loss/avg: 0.2016, max mem: 10794.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00001, ups: 0.84, time: 01m 59s 669ms, time_since_start: 01h 43m 17s 733ms, eta: 05h 24m 32s 620ms\n","\u001b[32m2022-04-26T15:17:49 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T15:17:49 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T15:17:56 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T15:17:56 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T15:17:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T15:18:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T15:18:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T15:18:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6000/22000, val/hateful_memes/cross_entropy: 2.2198, val/total_loss: 2.2198, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.4545, val/hateful_memes/roc_auc: 0.6853, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 31s 930ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T15:20:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6100/22000, train/hateful_memes/cross_entropy: 0.0218, train/hateful_memes/cross_entropy/avg: 0.1990, train/total_loss: 0.0218, train/total_loss/avg: 0.1990, max mem: 10794.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 777ms, time_since_start: 01h 45m 28s 444ms, eta: 04h 26m 12s 701ms\n","\u001b[32m2022-04-26T15:21:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6200/22000, train/hateful_memes/cross_entropy: 0.0184, train/hateful_memes/cross_entropy/avg: 0.1958, train/total_loss: 0.0184, train/total_loss/avg: 0.1958, max mem: 10794.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 362ms, time_since_start: 01h 47m 04s 807ms, eta: 04h 18m 04s 144ms\n","\u001b[32m2022-04-26T15:23:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6300/22000, train/hateful_memes/cross_entropy: 0.0110, train/hateful_memes/cross_entropy/avg: 0.1928, train/total_loss: 0.0110, train/total_loss/avg: 0.1928, max mem: 10794.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 421ms, time_since_start: 01h 48m 41s 229ms, eta: 04h 16m 35s 559ms\n","\u001b[32m2022-04-26T15:24:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6400/22000, train/hateful_memes/cross_entropy: 0.0079, train/hateful_memes/cross_entropy/avg: 0.1898, train/total_loss: 0.0079, train/total_loss/avg: 0.1898, max mem: 10794.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 851ms, time_since_start: 01h 50m 17s 080ms, eta: 04h 13m 27s 058ms\n","\u001b[32m2022-04-26T15:26:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6500/22000, train/hateful_memes/cross_entropy: 0.0079, train/hateful_memes/cross_entropy/avg: 0.1869, train/total_loss: 0.0079, train/total_loss/avg: 0.1869, max mem: 10794.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 855ms, time_since_start: 01h 51m 52s 935ms, eta: 04h 11m 50s 120ms\n","\u001b[32m2022-04-26T15:28:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6600/22000, train/hateful_memes/cross_entropy: 0.0062, train/hateful_memes/cross_entropy/avg: 0.1841, train/total_loss: 0.0062, train/total_loss/avg: 0.1841, max mem: 10794.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 168ms, time_since_start: 01h 53m 29s 104ms, eta: 04h 11m 01s 758ms\n","\u001b[32m2022-04-26T15:29:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6700/22000, train/hateful_memes/cross_entropy: 0.0062, train/hateful_memes/cross_entropy/avg: 0.1815, train/total_loss: 0.0062, train/total_loss/avg: 0.1815, max mem: 10794.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 734ms, time_since_start: 01h 55m 04s 839ms, eta: 04h 08m 16s 378ms\n","\u001b[32m2022-04-26T15:31:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6800/22000, train/hateful_memes/cross_entropy: 0.0062, train/hateful_memes/cross_entropy/avg: 0.1791, train/total_loss: 0.0062, train/total_loss/avg: 0.1791, max mem: 10794.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 122ms, time_since_start: 01h 56m 40s 961ms, eta: 04h 07m 38s 989ms\n","\u001b[32m2022-04-26T15:32:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 6900/22000, train/hateful_memes/cross_entropy: 0.0062, train/hateful_memes/cross_entropy/avg: 0.1765, train/total_loss: 0.0062, train/total_loss/avg: 0.1765, max mem: 10794.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 195ms, time_since_start: 01h 58m 17s 157ms, eta: 04h 06m 12s 489ms\n","\u001b[32m2022-04-26T15:34:24 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T15:34:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T15:34:36 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T15:34:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T15:34:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7000/22000, train/hateful_memes/cross_entropy: 0.0062, train/hateful_memes/cross_entropy/avg: 0.1740, train/total_loss: 0.0062, train/total_loss/avg: 0.1740, max mem: 10794.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00001, ups: 0.83, time: 02m 01s 905ms, time_since_start: 02h 19s 062ms, eta: 05h 09m 56s 651ms\n","\u001b[32m2022-04-26T15:34:50 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T15:34:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T15:34:57 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T15:34:57 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T15:34:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T15:35:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T15:35:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T15:35:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7000/22000, val/hateful_memes/cross_entropy: 2.2910, val/total_loss: 2.2910, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4342, val/hateful_memes/roc_auc: 0.6891, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 32s 496ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T15:37:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7100/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1716, train/total_loss: 0.0055, train/total_loss/avg: 0.1716, max mem: 10794.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 334ms, time_since_start: 02h 02m 29s 904ms, eta: 04h 08m 20s 999ms\n","\u001b[32m2022-04-26T15:38:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7200/22000, train/hateful_memes/cross_entropy: 0.0055, train/hateful_memes/cross_entropy/avg: 0.1696, train/total_loss: 0.0055, train/total_loss/avg: 0.1696, max mem: 10794.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 201ms, time_since_start: 02h 04m 06s 105ms, eta: 04h 01m 19s 813ms\n","\u001b[32m2022-04-26T15:40:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7300/22000, train/hateful_memes/cross_entropy: 0.0040, train/hateful_memes/cross_entropy/avg: 0.1673, train/total_loss: 0.0040, train/total_loss/avg: 0.1673, max mem: 10794.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 502ms, time_since_start: 02h 05m 42s 608ms, eta: 04h 27s 064ms\n","\u001b[32m2022-04-26T15:41:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7400/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1651, train/total_loss: 0.0041, train/total_loss/avg: 0.1651, max mem: 10794.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 425ms, time_since_start: 02h 07m 19s 033ms, eta: 03h 58m 37s 502ms\n","\u001b[32m2022-04-26T15:43:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7500/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1631, train/total_loss: 0.0041, train/total_loss/avg: 0.1631, max mem: 10794.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 873ms, time_since_start: 02h 08m 54s 907ms, eta: 03h 55m 38s 042ms\n","\u001b[32m2022-04-26T15:45:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7600/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1609, train/total_loss: 0.0041, train/total_loss/avg: 0.1609, max mem: 10794.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 851ms, time_since_start: 02h 10m 30s 758ms, eta: 03h 53m 57s 202ms\n","\u001b[32m2022-04-26T15:46:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7700/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1593, train/total_loss: 0.0041, train/total_loss/avg: 0.1593, max mem: 10794.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 817ms, time_since_start: 02h 12m 06s 576ms, eta: 03h 52m 14s 883ms\n","\u001b[32m2022-04-26T15:48:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7800/22000, train/hateful_memes/cross_entropy: 0.0040, train/hateful_memes/cross_entropy/avg: 0.1572, train/total_loss: 0.0040, train/total_loss/avg: 0.1572, max mem: 10794.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 520ms, time_since_start: 02h 13m 42s 096ms, eta: 03h 49m 54s 447ms\n","\u001b[32m2022-04-26T15:49:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 7900/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1553, train/total_loss: 0.0041, train/total_loss/avg: 0.1553, max mem: 10794.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 982ms, time_since_start: 02h 15m 18s 079ms, eta: 03h 49m 23s 545ms\n","\u001b[32m2022-04-26T15:51:25 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T15:51:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T15:51:37 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T15:51:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T15:51:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8000/22000, train/hateful_memes/cross_entropy: 0.0040, train/hateful_memes/cross_entropy/avg: 0.1534, train/total_loss: 0.0040, train/total_loss/avg: 0.1534, max mem: 10794.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00001, ups: 0.85, time: 01m 58s 768ms, time_since_start: 02h 17m 16s 847ms, eta: 04h 41m 50s 206ms\n","\u001b[32m2022-04-26T15:51:48 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T15:51:48 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T15:51:56 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T15:51:56 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T15:51:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T15:52:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T15:52:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T15:52:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8000/22000, val/hateful_memes/cross_entropy: 2.1508, val/total_loss: 2.1508, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4817, val/hateful_memes/roc_auc: 0.6972, num_updates: 8000, epoch: 31, iterations: 8000, max_updates: 22000, val_time: 34s 266ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T15:54:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8100/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1515, train/total_loss: 0.0037, train/total_loss/avg: 0.1515, max mem: 10794.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 220ms, time_since_start: 02h 19m 29s 335ms, eta: 03h 51m 24s 678ms\n","\u001b[32m2022-04-26T15:55:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8200/22000, train/hateful_memes/cross_entropy: 0.0040, train/hateful_memes/cross_entropy/avg: 0.1500, train/total_loss: 0.0040, train/total_loss/avg: 0.1500, max mem: 10794.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 405ms, time_since_start: 02h 21m 05s 741ms, eta: 03h 45m 30s 163ms\n","\u001b[32m2022-04-26T15:57:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8300/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1482, train/total_loss: 0.0037, train/total_loss/avg: 0.1482, max mem: 10794.0, experiment: run, epoch: 32, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 073ms, time_since_start: 02h 22m 41s 815ms, eta: 03h 43m 05s 888ms\n","\u001b[32m2022-04-26T15:58:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8400/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1464, train/total_loss: 0.0037, train/total_loss/avg: 0.1464, max mem: 10794.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 436ms, time_since_start: 02h 24m 18s 252ms, eta: 03h 42m 18s 325ms\n","\u001b[32m2022-04-26T16:00:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8500/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1447, train/total_loss: 0.0037, train/total_loss/avg: 0.1447, max mem: 10794.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 418ms, time_since_start: 02h 25m 54s 670ms, eta: 03h 40m 37s 770ms\n","\u001b[32m2022-04-26T16:02:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8600/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1430, train/total_loss: 0.0021, train/total_loss/avg: 0.1430, max mem: 10794.0, experiment: run, epoch: 33, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 984ms, time_since_start: 02h 27m 30s 655ms, eta: 03h 38m 614ms\n","\u001b[32m2022-04-26T16:03:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8700/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.1414, train/total_loss: 0.0018, train/total_loss/avg: 0.1414, max mem: 10794.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 072ms, time_since_start: 02h 29m 06s 727ms, eta: 03h 36m 34s 831ms\n","\u001b[32m2022-04-26T16:05:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8800/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.1405, train/total_loss: 0.0018, train/total_loss/avg: 0.1405, max mem: 10794.0, experiment: run, epoch: 34, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 884ms, time_since_start: 02h 30m 42s 611ms, eta: 03h 34m 31s 902ms\n","\u001b[32m2022-04-26T16:06:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 8900/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.1389, train/total_loss: 0.0018, train/total_loss/avg: 0.1389, max mem: 10794.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 309ms, time_since_start: 02h 32m 18s 921ms, eta: 03h 33m 51s 018ms\n","\u001b[32m2022-04-26T16:08:27 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T16:08:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T16:08:40 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T16:08:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T16:08:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9000/22000, train/hateful_memes/cross_entropy: 0.0018, train/hateful_memes/cross_entropy/avg: 0.1376, train/total_loss: 0.0018, train/total_loss/avg: 0.1376, max mem: 10794.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00001, ups: 0.83, time: 02m 01s 532ms, time_since_start: 02h 34m 20s 454ms, eta: 04h 27m 47s 864ms\n","\u001b[32m2022-04-26T16:08:52 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T16:08:52 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T16:08:59 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T16:08:59 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T16:08:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T16:09:12 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T16:09:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T16:09:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9000/22000, val/hateful_memes/cross_entropy: 2.3687, val/total_loss: 2.3687, val/hateful_memes/accuracy: 0.6685, val/hateful_memes/binary_f1: 0.4492, val/hateful_memes/roc_auc: 0.6793, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 22000, val_time: 34s 154ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T16:11:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9100/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1361, train/total_loss: 0.0014, train/total_loss/avg: 0.1361, max mem: 10794.0, experiment: run, epoch: 35, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 322ms, time_since_start: 02h 36m 32s 933ms, eta: 03h 34m 59s 212ms\n","\u001b[32m2022-04-26T16:12:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9200/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1346, train/total_loss: 0.0013, train/total_loss/avg: 0.1346, max mem: 10794.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00001, ups: 1.03, time: 01m 37s 337ms, time_since_start: 02h 38m 10s 270ms, eta: 03h 31m 10s 960ms\n","\u001b[32m2022-04-26T16:14:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9300/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1332, train/total_loss: 0.0013, train/total_loss/avg: 0.1332, max mem: 10794.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 996ms, time_since_start: 02h 39m 47s 267ms, eta: 03h 28m 48s 034ms\n","\u001b[32m2022-04-26T16:15:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9400/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1318, train/total_loss: 0.0009, train/total_loss/avg: 0.1318, max mem: 10794.0, experiment: run, epoch: 36, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 738ms, time_since_start: 02h 41m 24s 006ms, eta: 03h 26m 36s 310ms\n","\u001b[32m2022-04-26T16:17:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9500/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1304, train/total_loss: 0.0009, train/total_loss/avg: 0.1304, max mem: 10794.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 776ms, time_since_start: 02h 43m 02s 783ms, eta: 03h 29m 16s 995ms\n","\u001b[32m2022-04-26T16:19:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9600/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1292, train/total_loss: 0.0009, train/total_loss/avg: 0.1292, max mem: 10794.0, experiment: run, epoch: 37, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 968ms, time_since_start: 02h 44m 41s 751ms, eta: 03h 28m 679ms\n","\u001b[32m2022-04-26T16:20:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9700/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1279, train/total_loss: 0.0009, train/total_loss/avg: 0.1279, max mem: 10794.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00001, ups: 1.01, time: 01m 39s 166ms, time_since_start: 02h 46m 20s 917ms, eta: 03h 26m 44s 817ms\n","\u001b[32m2022-04-26T16:22:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9800/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1266, train/total_loss: 0.0014, train/total_loss/avg: 0.1266, max mem: 10794.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00001, ups: 1.01, time: 01m 39s 217ms, time_since_start: 02h 48m 135ms, eta: 03h 25m 10s 289ms\n","\u001b[32m2022-04-26T16:24:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 9900/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1254, train/total_loss: 0.0014, train/total_loss/avg: 0.1254, max mem: 10794.0, experiment: run, epoch: 38, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 659ms, time_since_start: 02h 49m 38s 794ms, eta: 03h 22m 20s 718ms\n","\u001b[32m2022-04-26T16:25:49 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T16:25:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T16:26:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T16:26:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T16:26:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10000/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.1242, train/total_loss: 0.0021, train/total_loss/avg: 0.1242, max mem: 10794.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00001, ups: 0.81, time: 02m 04s 843ms, time_since_start: 02h 51m 43s 638ms, eta: 04h 13m 55s 934ms\n","\u001b[32m2022-04-26T16:26:15 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T16:26:15 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T16:26:23 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T16:26:23 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T16:26:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T16:26:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T16:26:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T16:26:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10000/22000, val/hateful_memes/cross_entropy: 2.0602, val/total_loss: 2.0602, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.5073, val/hateful_memes/roc_auc: 0.6932, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 22000, val_time: 35s 770ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T16:28:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10100/22000, train/hateful_memes/cross_entropy: 0.0030, train/hateful_memes/cross_entropy/avg: 0.1230, train/total_loss: 0.0030, train/total_loss/avg: 0.1230, max mem: 10794.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00001, ups: 0.99, time: 01m 41s 368ms, time_since_start: 02h 54m 779ms, eta: 03h 24m 27s 899ms\n","\u001b[32m2022-04-26T16:30:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10200/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1218, train/total_loss: 0.0014, train/total_loss/avg: 0.1218, max mem: 10794.0, experiment: run, epoch: 39, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 749ms, time_since_start: 02h 55m 39s 528ms, eta: 03h 17m 30s 515ms\n","\u001b[32m2022-04-26T16:31:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10300/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1206, train/total_loss: 0.0014, train/total_loss/avg: 0.1206, max mem: 10794.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00001, ups: 1.01, time: 01m 39s 145ms, time_since_start: 02h 57m 18s 674ms, eta: 03h 16m 37s 231ms\n","\u001b[32m2022-04-26T16:33:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10400/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1194, train/total_loss: 0.0014, train/total_loss/avg: 0.1194, max mem: 10794.0, experiment: run, epoch: 40, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 668ms, time_since_start: 02h 58m 57s 342ms, eta: 03h 14m 067ms\n","\u001b[32m2022-04-26T16:35:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10500/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1183, train/total_loss: 0.0014, train/total_loss/avg: 0.1183, max mem: 10794.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 312ms, time_since_start: 03h 35s 654ms, eta: 03h 11m 38s 142ms\n","\u001b[32m2022-04-26T16:36:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10600/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1172, train/total_loss: 0.0006, train/total_loss/avg: 0.1172, max mem: 10794.0, experiment: run, epoch: 40, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 201ms, time_since_start: 03h 02m 11s 856ms, eta: 03h 05m 53s 459ms\n","\u001b[32m2022-04-26T16:38:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10700/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1161, train/total_loss: 0.0006, train/total_loss/avg: 0.1161, max mem: 10794.0, experiment: run, epoch: 41, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 670ms, time_since_start: 03h 03m 47s 527ms, eta: 03h 03m 14s 515ms\n","\u001b[32m2022-04-26T16:39:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10800/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1150, train/total_loss: 0.0006, train/total_loss/avg: 0.1150, max mem: 10794.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 018ms, time_since_start: 03h 05m 23s 545ms, eta: 03h 02m 16s 893ms\n","\u001b[32m2022-04-26T16:41:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 10900/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1140, train/total_loss: 0.0005, train/total_loss/avg: 0.1140, max mem: 10794.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 980ms, time_since_start: 03h 06m 59s 526ms, eta: 03h 34s 991ms\n","\u001b[32m2022-04-26T16:43:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T16:43:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T16:43:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T16:43:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T16:43:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11000/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1130, train/total_loss: 0.0005, train/total_loss/avg: 0.1130, max mem: 10794.0, experiment: run, epoch: 42, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00001, ups: 0.83, time: 02m 01s 358ms, time_since_start: 03h 09m 884ms, eta: 03h 46m 16s 373ms\n","\u001b[32m2022-04-26T16:43:32 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T16:43:32 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T16:43:39 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T16:43:39 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T16:43:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T16:43:52 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T16:44:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T16:44:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11000/22000, val/hateful_memes/cross_entropy: 2.2607, val/total_loss: 2.2607, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4720, val/hateful_memes/roc_auc: 0.6915, num_updates: 11000, epoch: 42, iterations: 11000, max_updates: 22000, val_time: 32s 220ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T16:45:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11100/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1120, train/total_loss: 0.0020, train/total_loss/avg: 0.1120, max mem: 10794.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00001, ups: 1.02, time: 01m 38s 376ms, time_since_start: 03h 11m 11s 482ms, eta: 03h 01m 45s 279ms\n","\u001b[32m2022-04-26T16:47:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11200/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1110, train/total_loss: 0.0020, train/total_loss/avg: 0.1110, max mem: 10794.0, experiment: run, epoch: 43, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 803ms, time_since_start: 03h 12m 47s 286ms, eta: 02h 55m 22s 682ms\n","\u001b[32m2022-04-26T16:48:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11300/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1101, train/total_loss: 0.0015, train/total_loss/avg: 0.1101, max mem: 10794.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 073ms, time_since_start: 03h 14m 23s 359ms, eta: 02h 54m 14s 592ms\n","\u001b[32m2022-04-26T16:50:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11400/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1091, train/total_loss: 0.0020, train/total_loss/avg: 0.1091, max mem: 10794.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 146ms, time_since_start: 03h 15m 59s 506ms, eta: 02h 52m 44s 821ms\n","\u001b[32m2022-04-26T16:52:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11500/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1082, train/total_loss: 0.0015, train/total_loss/avg: 0.1082, max mem: 10794.0, experiment: run, epoch: 44, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 777ms, time_since_start: 03h 17m 35s 284ms, eta: 02h 50m 27s 620ms\n","\u001b[32m2022-04-26T16:53:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11600/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1073, train/total_loss: 0.0005, train/total_loss/avg: 0.1073, max mem: 10794.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 986ms, time_since_start: 03h 19m 11s 270ms, eta: 02h 49m 12s 296ms\n","\u001b[32m2022-04-26T16:55:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11700/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1063, train/total_loss: 0.0005, train/total_loss/avg: 0.1063, max mem: 10794.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 900ms, time_since_start: 03h 20m 47s 171ms, eta: 02h 47m 25s 716ms\n","\u001b[32m2022-04-26T16:56:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11800/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1055, train/total_loss: 0.0005, train/total_loss/avg: 0.1055, max mem: 10794.0, experiment: run, epoch: 45, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 715ms, time_since_start: 03h 22m 22s 887ms, eta: 02h 45m 28s 978ms\n","\u001b[32m2022-04-26T16:58:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 11900/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.1046, train/total_loss: 0.0004, train/total_loss/avg: 0.1046, max mem: 10794.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 968ms, time_since_start: 03h 23m 58s 856ms, eta: 02h 44m 17s 600ms\n","\u001b[32m2022-04-26T17:00:06 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T17:00:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T17:00:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T17:00:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T17:00:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12000/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.1037, train/total_loss: 0.0004, train/total_loss/avg: 0.1037, max mem: 10794.0, experiment: run, epoch: 46, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00001, ups: 0.82, time: 02m 02s 326ms, time_since_start: 03h 26m 01s 182ms, eta: 03h 27m 20s 558ms\n","\u001b[32m2022-04-26T17:00:33 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T17:00:33 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T17:00:40 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T17:00:40 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T17:00:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T17:00:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T17:01:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T17:01:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12000/22000, val/hateful_memes/cross_entropy: 2.7229, val/total_loss: 2.7229, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4295, val/hateful_memes/roc_auc: 0.6829, num_updates: 12000, epoch: 46, iterations: 12000, max_updates: 22000, val_time: 32s 536ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.700426\n","\u001b[32m2022-04-26T17:02:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.1029, train/total_loss: 0.0003, train/total_loss/avg: 0.1029, max mem: 10794.0, experiment: run, epoch: 46, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0., ups: 1.03, time: 01m 37s 849ms, time_since_start: 03h 28m 11s 569ms, eta: 02h 44m 11s 755ms\n","\u001b[32m2022-04-26T17:04:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.1020, train/total_loss: 0.0003, train/total_loss/avg: 0.1020, max mem: 10794.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 072ms, time_since_start: 03h 29m 47s 642ms, eta: 02h 39m 35s 186ms\n","\u001b[32m2022-04-26T17:05:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1012, train/total_loss: 0.0002, train/total_loss/avg: 0.1012, max mem: 10794.0, experiment: run, epoch: 47, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 433ms, time_since_start: 03h 31m 23s 075ms, eta: 02h 36m 54s 413ms\n","\u001b[32m2022-04-26T17:07:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1004, train/total_loss: 0.0002, train/total_loss/avg: 0.1004, max mem: 10794.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 010ms, time_since_start: 03h 32m 59s 086ms, eta: 02h 36m 13s 713ms\n","\u001b[32m2022-04-26T17:09:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0996, train/total_loss: 0.0002, train/total_loss/avg: 0.0996, max mem: 10794.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 882ms, time_since_start: 03h 34m 34s 969ms, eta: 02h 34m 23s 695ms\n","\u001b[32m2022-04-26T17:10:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0988, train/total_loss: 0.0002, train/total_loss/avg: 0.0988, max mem: 10794.0, experiment: run, epoch: 48, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 938ms, time_since_start: 03h 36m 10s 907ms, eta: 02h 32m 51s 485ms\n","\u001b[32m2022-04-26T17:12:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0980, train/total_loss: 0.0002, train/total_loss/avg: 0.0980, max mem: 10794.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 639ms, time_since_start: 03h 37m 46s 546ms, eta: 02h 30m 45s 665ms\n","\u001b[32m2022-04-26T17:13:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0978, train/total_loss: 0.0002, train/total_loss/avg: 0.0978, max mem: 10794.0, experiment: run, epoch: 49, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 206ms, time_since_start: 03h 39m 21s 752ms, eta: 02h 28m 27s 887ms\n","\u001b[32m2022-04-26T17:15:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 12900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0970, train/total_loss: 0.0003, train/total_loss/avg: 0.0970, max mem: 10794.0, experiment: run, epoch: 49, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 653ms, time_since_start: 03h 40m 57s 406ms, eta: 02h 27m 32s 460ms\n","\u001b[32m2022-04-26T17:17:04 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T17:17:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T17:17:16 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T17:17:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T17:17:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0962, train/total_loss: 0.0002, train/total_loss/avg: 0.0962, max mem: 10794.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0., ups: 0.84, time: 01m 59s 833ms, time_since_start: 03h 42m 57s 239ms, eta: 03h 02m 48s 318ms\n","\u001b[32m2022-04-26T17:17:29 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T17:17:29 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T17:17:35 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T17:17:35 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T17:17:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T17:17:48 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n","\u001b[32m2022-04-26T17:18:29 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T17:18:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T17:18:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13000/22000, val/hateful_memes/cross_entropy: 2.5704, val/total_loss: 2.5704, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4669, val/hateful_memes/roc_auc: 0.7009, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 22000, val_time: 01m 14s 461ms, best_update: 13000, best_iteration: 13000, best_val/hateful_memes/roc_auc: 0.700926\n","\u001b[32m2022-04-26T17:20:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0955, train/total_loss: 0.0002, train/total_loss/avg: 0.0955, max mem: 10794.0, experiment: run, epoch: 50, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0., ups: 1.02, time: 01m 38s 454ms, time_since_start: 03h 45m 50s 156ms, eta: 02h 28m 31s 408ms\n","\u001b[32m2022-04-26T17:21:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0948, train/total_loss: 0.0002, train/total_loss/avg: 0.0948, max mem: 10794.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 319ms, time_since_start: 03h 47m 26s 476ms, eta: 02h 23m 40s 195ms\n","\u001b[32m2022-04-26T17:23:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0944, train/total_loss: 0.0002, train/total_loss/avg: 0.0944, max mem: 10794.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 908ms, time_since_start: 03h 49m 02s 384ms, eta: 02h 21m 25s 898ms\n","\u001b[32m2022-04-26T17:25:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0937, train/total_loss: 0.0002, train/total_loss/avg: 0.0937, max mem: 10794.0, experiment: run, epoch: 51, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 145ms, time_since_start: 03h 50m 38s 530ms, eta: 02h 20m 09s 080ms\n","\u001b[32m2022-04-26T17:26:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0930, train/total_loss: 0.0002, train/total_loss/avg: 0.0930, max mem: 10794.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 073ms, time_since_start: 03h 52m 14s 604ms, eta: 02h 18m 25s 111ms\n","\u001b[32m2022-04-26T17:28:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0923, train/total_loss: 0.0002, train/total_loss/avg: 0.0923, max mem: 10794.0, experiment: run, epoch: 52, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 986ms, time_since_start: 03h 53m 50s 590ms, eta: 02h 16m 39s 936ms\n","\u001b[32m2022-04-26T17:29:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0916, train/total_loss: 0.0002, train/total_loss/avg: 0.0916, max mem: 10794.0, experiment: run, epoch: 52, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 817ms, time_since_start: 03h 55m 26s 408ms, eta: 02h 14m 48s 031ms\n","\u001b[32m2022-04-26T17:31:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0909, train/total_loss: 0.0002, train/total_loss/avg: 0.0909, max mem: 10794.0, experiment: run, epoch: 52, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 825ms, time_since_start: 03h 57m 02s 234ms, eta: 02h 13m 11s 311ms\n","\u001b[32m2022-04-26T17:33:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 13900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0903, train/total_loss: 0.0002, train/total_loss/avg: 0.0903, max mem: 10794.0, experiment: run, epoch: 53, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 305ms, time_since_start: 03h 58m 37s 539ms, eta: 02h 10m 50s 973ms\n","\u001b[32m2022-04-26T17:34:45 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T17:34:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T17:34:57 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T17:35:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T17:35:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0897, train/total_loss: 0.0002, train/total_loss/avg: 0.0897, max mem: 10794.0, experiment: run, epoch: 53, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0., ups: 0.83, time: 02m 01s 455ms, time_since_start: 04h 38s 995ms, eta: 02h 44m 41s 650ms\n","\u001b[32m2022-04-26T17:35:10 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T17:35:10 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T17:35:18 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T17:35:18 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T17:35:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T17:35:32 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T17:35:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T17:35:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14000/22000, val/hateful_memes/cross_entropy: 2.7183, val/total_loss: 2.7183, val/hateful_memes/accuracy: 0.6759, val/hateful_memes/binary_f1: 0.4262, val/hateful_memes/roc_auc: 0.6839, num_updates: 14000, epoch: 53, iterations: 14000, max_updates: 22000, val_time: 32s 277ms, best_update: 13000, best_iteration: 13000, best_val/hateful_memes/roc_auc: 0.700926\n","\u001b[32m2022-04-26T17:37:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0890, train/total_loss: 0.0002, train/total_loss/avg: 0.0890, max mem: 10794.0, experiment: run, epoch: 54, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0., ups: 1.02, time: 01m 38s 420ms, time_since_start: 04h 02m 49s 695ms, eta: 02h 11m 47s 435ms\n","\u001b[32m2022-04-26T17:38:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0884, train/total_loss: 0.0003, train/total_loss/avg: 0.0884, max mem: 10794.0, experiment: run, epoch: 54, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 246ms, time_since_start: 04h 04m 25s 942ms, eta: 02h 07m 14s 851ms\n","\u001b[32m2022-04-26T17:40:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0878, train/total_loss: 0.0003, train/total_loss/avg: 0.0878, max mem: 10794.0, experiment: run, epoch: 54, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 306ms, time_since_start: 04h 06m 02s 248ms, eta: 02h 05m 41s 686ms\n","\u001b[32m2022-04-26T17:42:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14400/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0873, train/total_loss: 0.0003, train/total_loss/avg: 0.0873, max mem: 10794.0, experiment: run, epoch: 55, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 892ms, time_since_start: 04h 07m 38s 141ms, eta: 02h 03m 31s 758ms\n","\u001b[32m2022-04-26T17:43:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14500/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0867, train/total_loss: 0.0003, train/total_loss/avg: 0.0867, max mem: 10794.0, experiment: run, epoch: 55, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 035ms, time_since_start: 04h 09m 14s 177ms, eta: 02h 02m 05s 096ms\n","\u001b[32m2022-04-26T17:45:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0861, train/total_loss: 0.0003, train/total_loss/avg: 0.0861, max mem: 10794.0, experiment: run, epoch: 55, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 076ms, time_since_start: 04h 10m 50s 253ms, eta: 02h 30s 508ms\n","\u001b[32m2022-04-26T17:46:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14700/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0855, train/total_loss: 0.0003, train/total_loss/avg: 0.0855, max mem: 10794.0, experiment: run, epoch: 56, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 804ms, time_since_start: 04h 12m 26s 057ms, eta: 01h 58m 32s 613ms\n","\u001b[32m2022-04-26T17:48:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0849, train/total_loss: 0.0002, train/total_loss/avg: 0.0849, max mem: 10794.0, experiment: run, epoch: 56, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 078ms, time_since_start: 04h 14m 02s 136ms, eta: 01h 57m 15s 237ms\n","\u001b[32m2022-04-26T17:50:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 14900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0843, train/total_loss: 0.0002, train/total_loss/avg: 0.0843, max mem: 10794.0, experiment: run, epoch: 57, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 564ms, time_since_start: 04h 15m 37s 700ms, eta: 01h 55m 399ms\n","\u001b[32m2022-04-26T17:51:45 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T17:51:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T17:51:57 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T17:52:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T17:52:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0838, train/total_loss: 0.0002, train/total_loss/avg: 0.0838, max mem: 10794.0, experiment: run, epoch: 57, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0., ups: 0.84, time: 01m 59s 792ms, time_since_start: 04h 17m 37s 493ms, eta: 02h 22m 08s 064ms\n","\u001b[32m2022-04-26T17:52:09 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T17:52:09 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T17:52:16 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T17:52:16 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T17:52:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T17:52:29 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T17:52:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T17:52:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15000/22000, val/hateful_memes/cross_entropy: 2.6949, val/total_loss: 2.6949, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4606, val/hateful_memes/roc_auc: 0.6950, num_updates: 15000, epoch: 57, iterations: 15000, max_updates: 22000, val_time: 31s 903ms, best_update: 13000, best_iteration: 13000, best_val/hateful_memes/roc_auc: 0.700926\n","\u001b[32m2022-04-26T17:54:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0832, train/total_loss: 0.0002, train/total_loss/avg: 0.0832, max mem: 10794.0, experiment: run, epoch: 57, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0., ups: 1.02, time: 01m 38s 582ms, time_since_start: 04h 19m 47s 980ms, eta: 01h 55m 17s 845ms\n","\u001b[32m2022-04-26T17:55:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0827, train/total_loss: 0.0001, train/total_loss/avg: 0.0827, max mem: 10794.0, experiment: run, epoch: 58, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 076ms, time_since_start: 04h 21m 24s 056ms, eta: 01h 50m 44s 240ms\n","\u001b[32m2022-04-26T17:57:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0821, train/total_loss: 0.0001, train/total_loss/avg: 0.0821, max mem: 10794.0, experiment: run, epoch: 58, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 339ms, time_since_start: 04h 23m 396ms, eta: 01h 49m 24s 474ms\n","\u001b[32m2022-04-26T17:59:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0816, train/total_loss: 0.0001, train/total_loss/avg: 0.0816, max mem: 10794.0, experiment: run, epoch: 58, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 473ms, time_since_start: 04h 24m 36s 869ms, eta: 01h 47m 55s 484ms\n","\u001b[32m2022-04-26T18:00:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0811, train/total_loss: 0.0001, train/total_loss/avg: 0.0811, max mem: 10794.0, experiment: run, epoch: 59, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 882ms, time_since_start: 04h 26m 12s 752ms, eta: 01h 45m 38s 316ms\n","\u001b[32m2022-04-26T18:02:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0805, train/total_loss: 0.0001, train/total_loss/avg: 0.0805, max mem: 10794.0, experiment: run, epoch: 59, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 023ms, time_since_start: 04h 27m 48s 775ms, eta: 01h 44m 09s 967ms\n","\u001b[32m2022-04-26T18:03:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0800, train/total_loss: 0.0001, train/total_loss/avg: 0.0800, max mem: 10794.0, experiment: run, epoch: 60, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 774ms, time_since_start: 04h 29m 24s 550ms, eta: 01h 42m 16s 389ms\n","\u001b[32m2022-04-26T18:05:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0795, train/total_loss: 0.0001, train/total_loss/avg: 0.0795, max mem: 10794.0, experiment: run, epoch: 60, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 975ms, time_since_start: 04h 31m 526ms, eta: 01h 40m 51s 667ms\n","\u001b[32m2022-04-26T18:07:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 15900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0790, train/total_loss: 0.0001, train/total_loss/avg: 0.0790, max mem: 10794.0, experiment: run, epoch: 60, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 010ms, time_since_start: 04h 32m 36s 536ms, eta: 01h 39m 16s 177ms\n","\u001b[32m2022-04-26T18:08:44 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T18:08:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T18:08:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T18:09:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T18:09:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0785, train/total_loss: 0.0001, train/total_loss/avg: 0.0785, max mem: 10794.0, experiment: run, epoch: 61, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0., ups: 0.84, time: 01m 59s 992ms, time_since_start: 04h 34m 36s 529ms, eta: 02h 02m 01s 969ms\n","\u001b[32m2022-04-26T18:09:08 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T18:09:08 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T18:09:15 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T18:09:15 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T18:09:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T18:09:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T18:09:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T18:09:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16000/22000, val/hateful_memes/cross_entropy: 2.9344, val/total_loss: 2.9344, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4452, val/hateful_memes/roc_auc: 0.6924, num_updates: 16000, epoch: 61, iterations: 16000, max_updates: 22000, val_time: 32s 446ms, best_update: 13000, best_iteration: 13000, best_val/hateful_memes/roc_auc: 0.700926\n","\u001b[32m2022-04-26T18:11:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0780, train/total_loss: 0.0001, train/total_loss/avg: 0.0780, max mem: 10794.0, experiment: run, epoch: 61, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0., ups: 1.02, time: 01m 38s 270ms, time_since_start: 04h 36m 47s 247ms, eta: 01h 38m 16s 500ms\n","\u001b[32m2022-04-26T18:12:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0776, train/total_loss: 0.0001, train/total_loss/avg: 0.0776, max mem: 10794.0, experiment: run, epoch: 61, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 275ms, time_since_start: 04h 38m 23s 523ms, eta: 01h 34m 38s 897ms\n","\u001b[32m2022-04-26T18:14:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0771, train/total_loss: 0.0001, train/total_loss/avg: 0.0771, max mem: 10794.0, experiment: run, epoch: 62, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 035ms, time_since_start: 04h 39m 59s 558ms, eta: 01h 32m 47s 084ms\n","\u001b[32m2022-04-26T18:16:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0766, train/total_loss: 0.0001, train/total_loss/avg: 0.0766, max mem: 10794.0, experiment: run, epoch: 62, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 140ms, time_since_start: 04h 41m 35s 699ms, eta: 01h 31m 15s 399ms\n","\u001b[32m2022-04-26T18:17:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0762, train/total_loss: 0.0001, train/total_loss/avg: 0.0762, max mem: 10794.0, experiment: run, epoch: 63, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 696ms, time_since_start: 04h 43m 11s 395ms, eta: 01h 29m 12s 772ms\n","\u001b[32m2022-04-26T18:19:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0757, train/total_loss: 0.0001, train/total_loss/avg: 0.0757, max mem: 10794.0, experiment: run, epoch: 63, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 917ms, time_since_start: 04h 44m 47s 312ms, eta: 01h 27m 47s 577ms\n","\u001b[32m2022-04-26T18:20:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0753, train/total_loss: 0.0001, train/total_loss/avg: 0.0753, max mem: 10794.0, experiment: run, epoch: 63, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 956ms, time_since_start: 04h 46m 23s 269ms, eta: 01h 26m 12s 171ms\n","\u001b[32m2022-04-26T18:22:30 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0748, train/total_loss: 0.0001, train/total_loss/avg: 0.0748, max mem: 10794.0, experiment: run, epoch: 64, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 782ms, time_since_start: 04h 47m 59s 052ms, eta: 01h 24m 25s 380ms\n","\u001b[32m2022-04-26T18:24:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 16900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0744, train/total_loss: 0.0001, train/total_loss/avg: 0.0744, max mem: 10794.0, experiment: run, epoch: 64, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 119ms, time_since_start: 04h 49m 35s 172ms, eta: 01h 23m 05s 452ms\n","\u001b[32m2022-04-26T18:25:43 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T18:25:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T18:25:57 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T18:26:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T18:26:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0739, train/total_loss: 0.0001, train/total_loss/avg: 0.0739, max mem: 10794.0, experiment: run, epoch: 64, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0., ups: 0.81, time: 02m 03s 665ms, time_since_start: 04h 51m 38s 838ms, eta: 01h 44m 48s 415ms\n","\u001b[32m2022-04-26T18:26:10 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T18:26:10 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T18:26:18 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T18:26:18 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T18:26:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T18:26:31 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n","\u001b[32m2022-04-26T18:26:44 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T18:26:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T18:26:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17000/22000, val/hateful_memes/cross_entropy: 2.6510, val/total_loss: 2.6510, val/hateful_memes/accuracy: 0.7056, val/hateful_memes/binary_f1: 0.4920, val/hateful_memes/roc_auc: 0.7029, num_updates: 17000, epoch: 64, iterations: 17000, max_updates: 22000, val_time: 47s 332ms, best_update: 17000, best_iteration: 17000, best_val/hateful_memes/roc_auc: 0.702915\n","\u001b[32m2022-04-26T18:28:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0735, train/total_loss: 0.0001, train/total_loss/avg: 0.0735, max mem: 10794.0, experiment: run, epoch: 65, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0., ups: 1.02, time: 01m 38s 659ms, time_since_start: 04h 54m 04s 833ms, eta: 01h 21m 56s 489ms\n","\u001b[32m2022-04-26T18:30:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0731, train/total_loss: 0.0001, train/total_loss/avg: 0.0731, max mem: 10794.0, experiment: run, epoch: 65, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 474ms, time_since_start: 04h 55m 41s 308ms, eta: 01h 18m 29s 497ms\n","\u001b[32m2022-04-26T18:31:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0726, train/total_loss: 0.0001, train/total_loss/avg: 0.0726, max mem: 10794.0, experiment: run, epoch: 66, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 293ms, time_since_start: 04h 57m 17s 601ms, eta: 01h 16m 42s 736ms\n","\u001b[32m2022-04-26T18:33:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0722, train/total_loss: 0.0001, train/total_loss/avg: 0.0722, max mem: 10794.0, experiment: run, epoch: 66, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 293ms, time_since_start: 04h 58m 53s 895ms, eta: 01h 15m 04s 825ms\n","\u001b[32m2022-04-26T18:35:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0718, train/total_loss: 0.0001, train/total_loss/avg: 0.0718, max mem: 10794.0, experiment: run, epoch: 66, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 321ms, time_since_start: 05h 30s 217ms, eta: 01h 13m 28s 155ms\n","\u001b[32m2022-04-26T18:36:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0714, train/total_loss: 0.0001, train/total_loss/avg: 0.0714, max mem: 10794.0, experiment: run, epoch: 67, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 767ms, time_since_start: 05h 02m 05s 984ms, eta: 01h 11m 25s 410ms\n","\u001b[32m2022-04-26T18:38:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0710, train/total_loss: 0.0001, train/total_loss/avg: 0.0710, max mem: 10794.0, experiment: run, epoch: 67, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 899ms, time_since_start: 05h 03m 41s 883ms, eta: 01h 09m 53s 761ms\n","\u001b[32m2022-04-26T18:39:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0706, train/total_loss: 0.0001, train/total_loss/avg: 0.0706, max mem: 10794.0, experiment: run, epoch: 67, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 990ms, time_since_start: 05h 05m 17s 874ms, eta: 01h 08m 20s 156ms\n","\u001b[32m2022-04-26T18:41:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0702, train/total_loss: 0.0000, train/total_loss/avg: 0.0702, max mem: 10794.0, experiment: run, epoch: 68, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 756ms, time_since_start: 05h 06m 53s 631ms, eta: 01h 06m 32s 751ms\n","\u001b[32m2022-04-26T18:43:01 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T18:43:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T18:43:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T18:43:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T18:43:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0698, train/total_loss: 0.0000, train/total_loss/avg: 0.0698, max mem: 10794.0, experiment: run, epoch: 68, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0., ups: 0.82, time: 02m 02s 350ms, time_since_start: 05h 08m 55s 981ms, eta: 01h 22m 57s 200ms\n","\u001b[32m2022-04-26T18:43:27 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T18:43:27 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T18:43:34 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T18:43:34 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T18:43:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T18:43:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T18:44:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T18:44:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18000/22000, val/hateful_memes/cross_entropy: 2.7257, val/total_loss: 2.7257, val/hateful_memes/accuracy: 0.6796, val/hateful_memes/binary_f1: 0.4365, val/hateful_memes/roc_auc: 0.6980, num_updates: 18000, epoch: 68, iterations: 18000, max_updates: 22000, val_time: 33s 109ms, best_update: 17000, best_iteration: 17000, best_val/hateful_memes/roc_auc: 0.702915\n","\u001b[32m2022-04-26T18:45:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0694, train/total_loss: 0.0000, train/total_loss/avg: 0.0694, max mem: 10794.0, experiment: run, epoch: 69, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0., ups: 1.02, time: 01m 38s 185ms, time_since_start: 05h 11m 07s 278ms, eta: 01h 04m 54s 333ms\n","\u001b[32m2022-04-26T18:47:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0690, train/total_loss: 0.0000, train/total_loss/avg: 0.0690, max mem: 10794.0, experiment: run, epoch: 69, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 553ms, time_since_start: 05h 12m 43s 831ms, eta: 01h 02m 11s 388ms\n","\u001b[32m2022-04-26T18:48:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0687, train/total_loss: 0.0000, train/total_loss/avg: 0.0687, max mem: 10794.0, experiment: run, epoch: 69, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 589ms, time_since_start: 05h 14m 20s 420ms, eta: 01h 34s 560ms\n","\u001b[32m2022-04-26T18:50:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0683, train/total_loss: 0.0000, train/total_loss/avg: 0.0683, max mem: 10794.0, experiment: run, epoch: 70, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 041ms, time_since_start: 05h 15m 56s 462ms, eta: 58m 36s 255ms\n","\u001b[32m2022-04-26T18:52:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0679, train/total_loss: 0.0000, train/total_loss/avg: 0.0679, max mem: 10794.0, experiment: run, epoch: 70, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 277ms, time_since_start: 05h 17m 32s 739ms, eta: 57m 07s 009ms\n","\u001b[32m2022-04-26T18:53:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0676, train/total_loss: 0.0000, train/total_loss/avg: 0.0676, max mem: 10794.0, experiment: run, epoch: 70, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 333ms, time_since_start: 05h 19m 09s 073ms, eta: 55m 31s 037ms\n","\u001b[32m2022-04-26T18:55:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0672, train/total_loss: 0.0000, train/total_loss/avg: 0.0672, max mem: 10794.0, experiment: run, epoch: 71, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 974ms, time_since_start: 05h 20m 45s 048ms, eta: 53m 41s 008ms\n","\u001b[32m2022-04-26T18:56:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0668, train/total_loss: 0.0000, train/total_loss/avg: 0.0668, max mem: 10794.0, experiment: run, epoch: 71, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 116ms, time_since_start: 05h 22m 21s 164ms, eta: 52m 08s 003ms\n","\u001b[32m2022-04-26T18:58:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 18900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0665, train/total_loss: 0.0000, train/total_loss/avg: 0.0665, max mem: 10794.0, experiment: run, epoch: 72, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 726ms, time_since_start: 05h 23m 56s 891ms, eta: 50m 17s 965ms\n","\u001b[32m2022-04-26T19:00:04 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T19:00:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T19:00:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T19:00:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T19:00:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0661, train/total_loss: 0.0000, train/total_loss/avg: 0.0661, max mem: 10794.0, experiment: run, epoch: 72, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0., ups: 0.83, time: 02m 070ms, time_since_start: 05h 25m 56s 961ms, eta: 01h 01m 03s 352ms\n","\u001b[32m2022-04-26T19:00:28 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T19:00:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T19:00:35 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T19:00:35 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T19:00:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T19:00:50 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T19:01:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T19:01:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19000/22000, val/hateful_memes/cross_entropy: 2.8369, val/total_loss: 2.8369, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4525, val/hateful_memes/roc_auc: 0.6985, num_updates: 19000, epoch: 72, iterations: 19000, max_updates: 22000, val_time: 33s 249ms, best_update: 17000, best_iteration: 17000, best_val/hateful_memes/roc_auc: 0.702915\n","\u001b[32m2022-04-26T19:02:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0658, train/total_loss: 0.0000, train/total_loss/avg: 0.0658, max mem: 10794.0, experiment: run, epoch: 72, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0., ups: 1.01, time: 01m 39s 030ms, time_since_start: 05h 28m 09s 243ms, eta: 48m 40s 708ms\n","\u001b[32m2022-04-26T19:04:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0654, train/total_loss: 0.0000, train/total_loss/avg: 0.0654, max mem: 10794.0, experiment: run, epoch: 73, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 721ms, time_since_start: 05h 29m 45s 964ms, eta: 45m 54s 237ms\n","\u001b[32m2022-04-26T19:05:54 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0651, train/total_loss: 0.0000, train/total_loss/avg: 0.0651, max mem: 10794.0, experiment: run, epoch: 73, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 665ms, time_since_start: 05h 31m 22s 629ms, eta: 44m 14s 332ms\n","\u001b[32m2022-04-26T19:07:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0648, train/total_loss: 0.0000, train/total_loss/avg: 0.0648, max mem: 10794.0, experiment: run, epoch: 73, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 468ms, time_since_start: 05h 32m 59s 098ms, eta: 42m 30s 808ms\n","\u001b[32m2022-04-26T19:09:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0644, train/total_loss: 0.0000, train/total_loss/avg: 0.0644, max mem: 10794.0, experiment: run, epoch: 74, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 058ms, time_since_start: 05h 34m 35s 156ms, eta: 40m 42s 288ms\n","\u001b[32m2022-04-26T19:10:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0641, train/total_loss: 0.0000, train/total_loss/avg: 0.0641, max mem: 10794.0, experiment: run, epoch: 74, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 171ms, time_since_start: 05h 36m 11s 328ms, eta: 39m 07s 357ms\n","\u001b[32m2022-04-26T19:12:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0638, train/total_loss: 0.0000, train/total_loss/avg: 0.0638, max mem: 10794.0, experiment: run, epoch: 75, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 816ms, time_since_start: 05h 37m 47s 144ms, eta: 37m 21s 248ms\n","\u001b[32m2022-04-26T19:13:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0635, train/total_loss: 0.0000, train/total_loss/avg: 0.0635, max mem: 10794.0, experiment: run, epoch: 75, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 212ms, time_since_start: 05h 39m 23s 357ms, eta: 35m 52s 669ms\n","\u001b[32m2022-04-26T19:15:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0631, train/total_loss: 0.0000, train/total_loss/avg: 0.0631, max mem: 10794.0, experiment: run, epoch: 75, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 097ms, time_since_start: 05h 40m 59s 455ms, eta: 34m 12s 347ms\n","\u001b[32m2022-04-26T19:17:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T19:17:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T19:17:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T19:17:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T19:17:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0628, train/total_loss: 0.0000, train/total_loss/avg: 0.0628, max mem: 10794.0, experiment: run, epoch: 76, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0., ups: 0.83, time: 02m 296ms, time_since_start: 05h 42m 59s 751ms, eta: 40m 46s 831ms\n","\u001b[32m2022-04-26T19:17:31 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T19:17:31 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T19:17:38 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T19:17:38 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T19:17:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T19:17:51 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T19:18:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T19:18:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20000/22000, val/hateful_memes/cross_entropy: 2.9171, val/total_loss: 2.9171, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.4545, val/hateful_memes/roc_auc: 0.6914, num_updates: 20000, epoch: 76, iterations: 20000, max_updates: 22000, val_time: 31s 609ms, best_update: 17000, best_iteration: 17000, best_val/hateful_memes/roc_auc: 0.702915\n","\u001b[32m2022-04-26T19:19:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0625, train/total_loss: 0.0000, train/total_loss/avg: 0.0625, max mem: 10794.0, experiment: run, epoch: 76, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 1.01, time: 01m 39s 221ms, time_since_start: 05h 45m 10s 584ms, eta: 31m 57s 250ms\n","\u001b[32m2022-04-26T19:21:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0622, train/total_loss: 0.0000, train/total_loss/avg: 0.0622, max mem: 10794.0, experiment: run, epoch: 76, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 595ms, time_since_start: 05h 46m 47s 179ms, eta: 29m 28s 277ms\n","\u001b[32m2022-04-26T19:22:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0619, train/total_loss: 0.0000, train/total_loss/avg: 0.0619, max mem: 10794.0, experiment: run, epoch: 77, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 959ms, time_since_start: 05h 48m 23s 139ms, eta: 27m 39s 045ms\n","\u001b[32m2022-04-26T19:24:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0616, train/total_loss: 0.0000, train/total_loss/avg: 0.0616, max mem: 10794.0, experiment: run, epoch: 77, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 496ms, time_since_start: 05h 49m 59s 635ms, eta: 26m 10s 187ms\n","\u001b[32m2022-04-26T19:26:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0613, train/total_loss: 0.0000, train/total_loss/avg: 0.0613, max mem: 10794.0, experiment: run, epoch: 78, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 252ms, time_since_start: 05h 51m 35s 888ms, eta: 24m 28s 331ms\n","\u001b[32m2022-04-26T19:27:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0610, train/total_loss: 0.0000, train/total_loss/avg: 0.0610, max mem: 10794.0, experiment: run, epoch: 78, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 113ms, time_since_start: 05h 53m 12s 002ms, eta: 22m 48s 469ms\n","\u001b[32m2022-04-26T19:29:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0607, train/total_loss: 0.0000, train/total_loss/avg: 0.0607, max mem: 10794.0, experiment: run, epoch: 78, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 058ms, time_since_start: 05h 54m 48s 060ms, eta: 21m 09s 989ms\n","\u001b[32m2022-04-26T19:30:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0604, train/total_loss: 0.0000, train/total_loss/avg: 0.0604, max mem: 10794.0, experiment: run, epoch: 79, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 763ms, time_since_start: 05h 56m 23s 823ms, eta: 19m 28s 697ms\n","\u001b[32m2022-04-26T19:32:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0601, train/total_loss: 0.0000, train/total_loss/avg: 0.0601, max mem: 10794.0, experiment: run, epoch: 79, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 092ms, time_since_start: 05h 57m 59s 916ms, eta: 17m 54s 985ms\n","\u001b[32m2022-04-26T19:34:08 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T19:34:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T19:34:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T19:34:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T19:34:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0598, train/total_loss: 0.0000, train/total_loss/avg: 0.0598, max mem: 10794.0, experiment: run, epoch: 79, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 0.83, time: 02m 01s 485ms, time_since_start: 06h 01s 402ms, eta: 20m 35s 510ms\n","\u001b[32m2022-04-26T19:34:33 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T19:34:33 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T19:34:40 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T19:34:40 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T19:34:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T19:34:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T19:35:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T19:35:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21000/22000, val/hateful_memes/cross_entropy: 2.9577, val/total_loss: 2.9577, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.4362, val/hateful_memes/roc_auc: 0.6932, num_updates: 21000, epoch: 79, iterations: 21000, max_updates: 22000, val_time: 32s 933ms, best_update: 17000, best_iteration: 17000, best_val/hateful_memes/roc_auc: 0.702915\n","\u001b[32m2022-04-26T19:36:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0596, train/total_loss: 0.0000, train/total_loss/avg: 0.0596, max mem: 10794.0, experiment: run, epoch: 80, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 1.03, time: 01m 37s 877ms, time_since_start: 06h 02m 12s 215ms, eta: 14m 55s 876ms\n","\u001b[32m2022-04-26T19:38:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0593, train/total_loss: 0.0000, train/total_loss/avg: 0.0593, max mem: 10794.0, experiment: run, epoch: 80, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 316ms, time_since_start: 06h 03m 48s 532ms, eta: 13m 03s 634ms\n","\u001b[32m2022-04-26T19:39:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0590, train/total_loss: 0.0000, train/total_loss/avg: 0.0590, max mem: 10794.0, experiment: run, epoch: 81, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 797ms, time_since_start: 06h 05m 24s 329ms, eta: 11m 21s 981ms\n","\u001b[32m2022-04-26T19:41:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0587, train/total_loss: 0.0000, train/total_loss/avg: 0.0587, max mem: 10794.0, experiment: run, epoch: 81, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 043ms, time_since_start: 06h 07m 373ms, eta: 09m 46s 057ms\n","\u001b[32m2022-04-26T19:43:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0584, train/total_loss: 0.0000, train/total_loss/avg: 0.0584, max mem: 10794.0, experiment: run, epoch: 81, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 066ms, time_since_start: 06h 08m 36s 440ms, eta: 08m 08s 498ms\n","\u001b[32m2022-04-26T19:44:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0582, train/total_loss: 0.0000, train/total_loss/avg: 0.0582, max mem: 10794.0, experiment: run, epoch: 82, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 752ms, time_since_start: 06h 10m 12s 193ms, eta: 06m 29s 523ms\n","\u001b[32m2022-04-26T19:46:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0579, train/total_loss: 0.0000, train/total_loss/avg: 0.0579, max mem: 10794.0, experiment: run, epoch: 82, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 820ms, time_since_start: 06h 11m 48s 013ms, eta: 04m 52s 346ms\n","\u001b[32m2022-04-26T19:47:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0576, train/total_loss: 0.0000, train/total_loss/avg: 0.0576, max mem: 10794.0, experiment: run, epoch: 82, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 952ms, time_since_start: 06h 13m 23s 965ms, eta: 03m 15s 167ms\n","\u001b[32m2022-04-26T19:49:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0574, train/total_loss: 0.0000, train/total_loss/avg: 0.0574, max mem: 10794.0, experiment: run, epoch: 83, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 448ms, time_since_start: 06h 14m 59s 414ms, eta: 01m 37s 070ms\n","\u001b[32m2022-04-26T19:51:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n","\u001b[32m2022-04-26T19:51:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T19:51:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T19:51:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T19:51:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0571, train/total_loss: 0.0000, train/total_loss/avg: 0.0571, max mem: 10794.0, experiment: run, epoch: 83, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 0.83, time: 02m 01s 087ms, time_since_start: 06h 17m 501ms, eta: 0ms\n","\u001b[32m2022-04-26T19:51:32 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n","\u001b[32m2022-04-26T19:51:32 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","\u001b[32m2022-04-26T19:51:39 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 17\n","\u001b[32m2022-04-26T19:51:39 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T19:51:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n","\u001b[32m2022-04-26T19:51:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n","\u001b[32m2022-04-26T19:52:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n","\u001b[32m2022-04-26T19:52:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 22000/22000, val/hateful_memes/cross_entropy: 2.9054, val/total_loss: 2.9054, val/hateful_memes/accuracy: 0.6926, val/hateful_memes/binary_f1: 0.4539, val/hateful_memes/roc_auc: 0.6948, num_updates: 22000, epoch: 83, iterations: 22000, max_updates: 22000, val_time: 33s 816ms, best_update: 17000, best_iteration: 17000, best_val/hateful_memes/roc_auc: 0.702915\n","\u001b[32m2022-04-26T19:52:07 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n","\u001b[32m2022-04-26T19:52:07 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n","\u001b[32m2022-04-26T19:52:07 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","\u001b[32m2022-04-26T19:52:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2022-04-26T19:52:34 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 17000\n","\u001b[32m2022-04-26T19:52:34 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 17000\n","\u001b[32m2022-04-26T19:52:34 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 64\n","\u001b[32m2022-04-26T19:52:54 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n","\u001b[32m2022-04-26T19:52:54 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","100% 63/63 [00:20<00:00,  3.04it/s]\n","\u001b[32m2022-04-26T19:53:15 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 63\n","\u001b[32m2022-04-26T19:53:15 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T19:53:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 17000/22000, test/hateful_memes/cross_entropy: 2.7605, test/total_loss: 2.7605, test/hateful_memes/accuracy: 0.6955, test/hateful_memes/binary_f1: 0.4606, test/hateful_memes/roc_auc: 0.7381\n","\u001b[32m2022-04-26T19:53:15 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 06h 18m 43s 761ms\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"CTWqK7RQFVuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"Vpb05LA7OQjI","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1650940068196,"user_tz":300,"elapsed":155,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"fe4b4616-e523-43c6-ff77-23f857f5115e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Project/hateful-memes'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["!mmf_run config=\"mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml\" \\\n","model=vilbert \\\n","dataset=hateful_memes \\\n","run_type=test \\\n","checkpoint.resume_file=save/best.ckpt \\\n","checkpoint.resume_pretrained=False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQ3lmwL85WfL","executionInfo":{"status":"ok","timestamp":1650941294567,"user_tz":300,"elapsed":43111,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"c0261566-90cd-4adc-9399-701e686484d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n","  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n","\u001b[32m2022-04-26T02:47:37 | mmf.utils.configuration: \u001b[0mOverriding option config to mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml\n","\u001b[32m2022-04-26T02:47:37 | mmf.utils.configuration: \u001b[0mOverriding option model to vilbert\n","\u001b[32m2022-04-26T02:47:37 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n","\u001b[32m2022-04-26T02:47:37 | mmf.utils.configuration: \u001b[0mOverriding option run_type to test\n","\u001b[32m2022-04-26T02:47:37 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to save/best.ckpt\n","\u001b[32m2022-04-26T02:47:37 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","\u001b[32m2022-04-26T02:47:37 | mmf: \u001b[0mLogging to: ./save/train.log\n","\u001b[32m2022-04-26T02:47:37 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False'])\n","\u001b[32m2022-04-26T02:47:37 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n","\u001b[32m2022-04-26T02:47:37 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla P100-PCIE-16GB\n","\u001b[32m2022-04-26T02:47:37 | mmf_cli.run: \u001b[0mUsing seed 37966181\n","\u001b[32m2022-04-26T02:47:37 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","\u001b[32m2022-04-26T02:47:39 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T02:47:39 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T02:47:39 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T02:47:39 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n","Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bert_model_name\": \"bert-base-uncased\",\n","  \"bi_attention_type\": 1,\n","  \"bi_hidden_size\": 1024,\n","  \"bi_intermediate_size\": 1024,\n","  \"bi_num_attention_heads\": 8,\n","  \"bypass_transformer\": false,\n","  \"classifier_dropout\": null,\n","  \"cut_first\": \"text\",\n","  \"dynamic_attention\": false,\n","  \"embedding_strategy\": \"plain\",\n","  \"fast_mode\": false,\n","  \"finetune_lr_multiplier\": 1,\n","  \"fixed_t_layer\": 0,\n","  \"fixed_v_layer\": 0,\n","  \"freeze_base\": false,\n","  \"fusion_method\": \"mul\",\n","  \"gradient_checkpointing\": false,\n","  \"hard_cap_seq_len\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"in_batch_pairs\": false,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"losses\": [\n","    \"cross_entropy\"\n","  ],\n","  \"max_position_embeddings\": 512,\n","  \"model\": \"vilbert\",\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_negative\": 128,\n","  \"objective\": 0,\n","  \"pad_token_id\": 0,\n","  \"pooling_method\": \"mul\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"random_initialize\": false,\n","  \"special_visual_initialize\": true,\n","  \"t_biattention_id\": [\n","    6,\n","    7,\n","    8,\n","    9,\n","    10,\n","    11\n","  ],\n","  \"task_specific_tokens\": false,\n","  \"text_only\": false,\n","  \"training_head_type\": \"classification\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"v_attention_probs_dropout_prob\": 0.1,\n","  \"v_biattention_id\": [\n","    0,\n","    1,\n","    2,\n","    3,\n","    4,\n","    5\n","  ],\n","  \"v_feature_size\": 2048,\n","  \"v_hidden_act\": \"gelu\",\n","  \"v_hidden_dropout_prob\": 0.1,\n","  \"v_hidden_size\": 1024,\n","  \"v_initializer_range\": 0.02,\n","  \"v_intermediate_size\": 1024,\n","  \"v_num_attention_heads\": 8,\n","  \"v_num_hidden_layers\": 6,\n","  \"v_target_size\": 1601,\n","  \"visual_embedding_dim\": 2048,\n","  \"visual_target\": 0,\n","  \"visualization\": false,\n","  \"vocab_size\": 30522,\n","  \"with_coattention\": true\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['cls.predictions.transform.dense.weight', 'bert.pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.t_pooler.dense.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.v_embeddings.image_embeddings.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.t_pooler.dense.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.v_pooler.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.v_pooler.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.output.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m2022-04-26T02:47:46 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n","\u001b[32m2022-04-26T02:47:46 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n","\u001b[32m2022-04-26T02:47:46 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-26T02:47:51 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-26T02:47:51 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n","\u001b[32m2022-04-26T02:47:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2022-04-26T02:47:51 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 14000\n","\u001b[32m2022-04-26T02:47:51 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 14000\n","\u001b[32m2022-04-26T02:47:51 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 53\n","\u001b[32m2022-04-26T02:47:51 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n","\u001b[32m2022-04-26T02:47:51 | mmf.trainers.mmf_trainer: \u001b[0mViLBERT(\n","  (model): ViLBERTForClassification(\n","    (bert): ViLBERTBase(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (v_embeddings): BertImageFeatureEmbeddings(\n","        (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)\n","        (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (v_layer): ModuleList(\n","          (0): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertImageLayer(\n","            (attention): BertImageAttention(\n","              (self): BertImageSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertImageSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","        (c_layer): ModuleList(\n","          (0): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertConnectionLayer(\n","            (biattention): BertBiAttention(\n","              (query1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (query2): Linear(in_features=768, out_features=1024, bias=True)\n","              (key2): Linear(in_features=768, out_features=1024, bias=True)\n","              (value2): Linear(in_features=768, out_features=1024, bias=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (biOutput): BertBiOutput(\n","              (dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout1): Dropout(p=0.1, inplace=False)\n","              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)\n","              (q_dropout1): Dropout(p=0.1, inplace=False)\n","              (dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout2): Dropout(p=0.1, inplace=False)\n","              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)\n","              (q_dropout2): Dropout(p=0.1, inplace=False)\n","            )\n","            (v_intermediate): BertImageIntermediate(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            )\n","            (v_output): BertImageOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (t_intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (t_output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (t_pooler): BertTextPooler(\n","        (dense): Linear(in_features=768, out_features=1024, bias=True)\n","        (activation): ReLU()\n","      )\n","      (v_pooler): BertImagePooler(\n","        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","        (activation): ReLU()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Sequential(\n","      (0): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (1): Linear(in_features=1024, out_features=2, bias=True)\n","    )\n","  )\n","  (losses): Losses(\n","    (losses): ModuleList(\n","      (0): MMFLoss(\n","        (loss_criterion): CrossEntropyLoss(\n","          (loss_fn): CrossEntropyLoss()\n","        )\n","      )\n","    )\n","  )\n",")\n","\u001b[32m2022-04-26T02:47:51 | mmf.utils.general: \u001b[0mTotal Parameters: 247780354. Trained Parameters: 247780354\n","\u001b[32m2022-04-26T02:47:51 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n","\u001b[32m2022-04-26T02:47:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","100% 63/63 [00:20<00:00,  3.09it/s]\n","\u001b[32m2022-04-26T02:48:12 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 63\n","\u001b[32m2022-04-26T02:48:12 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n","\u001b[32m2022-04-26T02:48:12 | mmf.trainers.callbacks.logistics: \u001b[0mtest/hateful_memes/cross_entropy: 2.7303, test/total_loss: 2.7303, test/hateful_memes/accuracy: 0.7050, test/hateful_memes/binary_f1: 0.4788, test/hateful_memes/roc_auc: 0.7236\n","\u001b[32m2022-04-26T02:48:12 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 26s 190ms\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"pde3jQE06IkW","executionInfo":{"status":"ok","timestamp":1650810230993,"user_tz":300,"elapsed":205,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"2215289b-8a49-487d-c4f2-a5d9e01ab0fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Project'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["!find -type f -name '*.json' \n","# -printf '.' | wc -c"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IUYvnSLyUn8","executionInfo":{"status":"ok","timestamp":1649904691457,"user_tz":300,"elapsed":267,"user":{"displayName":"Tianyao Wang","userId":"02589710995949182080"}},"outputId":"0626f1eb-dadc-44ac-e37e-119372938b02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["./mmf-hateful-memes/website/package.json\n","./datasets/.built.json\n","./datasets/features/.built.json\n","./datasets/models/vilbert.pretrained.cc.original/.built.json\n"]}]},{"cell_type":"code","source":["!mmf_predict config=\"mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml\" \\\n","model=vilbert \\\n","dataset=hateful_memes \\\n","run_type=test \\\n","checkpoint.resume_file=save/best.ckpt \\\n","checkpoint.resume_pretrained=False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2okQRfxiyWg2","executionInfo":{"status":"ok","timestamp":1650941345652,"user_tz":300,"elapsed":51091,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"7919fe64-3b3a-447e-f31f-50202c84ede3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n","  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n","\u001b[32m2022-04-26T02:48:21 | mmf.utils.configuration: \u001b[0mOverriding option config to mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml\n","\u001b[32m2022-04-26T02:48:21 | mmf.utils.configuration: \u001b[0mOverriding option model to vilbert\n","\u001b[32m2022-04-26T02:48:21 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n","\u001b[32m2022-04-26T02:48:21 | mmf.utils.configuration: \u001b[0mOverriding option run_type to test\n","\u001b[32m2022-04-26T02:48:21 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to save/best.ckpt\n","\u001b[32m2022-04-26T02:48:21 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n","\u001b[32m2022-04-26T02:48:21 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","\u001b[32m2022-04-26T02:48:21 | mmf: \u001b[0mLogging to: ./save/train.log\n","\u001b[32m2022-04-26T02:48:21 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])\n","\u001b[32m2022-04-26T02:48:21 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n","\u001b[32m2022-04-26T02:48:21 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla P100-PCIE-16GB\n","\u001b[32m2022-04-26T02:48:21 | mmf_cli.run: \u001b[0mUsing seed 21439143\n","\u001b[32m2022-04-26T02:48:21 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","\u001b[32m2022-04-26T02:48:23 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T02:48:23 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T02:48:23 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T02:48:23 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n","Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bert_model_name\": \"bert-base-uncased\",\n","  \"bi_attention_type\": 1,\n","  \"bi_hidden_size\": 1024,\n","  \"bi_intermediate_size\": 1024,\n","  \"bi_num_attention_heads\": 8,\n","  \"bypass_transformer\": false,\n","  \"classifier_dropout\": null,\n","  \"cut_first\": \"text\",\n","  \"dynamic_attention\": false,\n","  \"embedding_strategy\": \"plain\",\n","  \"fast_mode\": false,\n","  \"finetune_lr_multiplier\": 1,\n","  \"fixed_t_layer\": 0,\n","  \"fixed_v_layer\": 0,\n","  \"freeze_base\": false,\n","  \"fusion_method\": \"mul\",\n","  \"gradient_checkpointing\": false,\n","  \"hard_cap_seq_len\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"in_batch_pairs\": false,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"losses\": [\n","    \"cross_entropy\"\n","  ],\n","  \"max_position_embeddings\": 512,\n","  \"model\": \"vilbert\",\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_negative\": 128,\n","  \"objective\": 0,\n","  \"pad_token_id\": 0,\n","  \"pooling_method\": \"mul\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"random_initialize\": false,\n","  \"special_visual_initialize\": true,\n","  \"t_biattention_id\": [\n","    6,\n","    7,\n","    8,\n","    9,\n","    10,\n","    11\n","  ],\n","  \"task_specific_tokens\": false,\n","  \"text_only\": false,\n","  \"training_head_type\": \"classification\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"v_attention_probs_dropout_prob\": 0.1,\n","  \"v_biattention_id\": [\n","    0,\n","    1,\n","    2,\n","    3,\n","    4,\n","    5\n","  ],\n","  \"v_feature_size\": 2048,\n","  \"v_hidden_act\": \"gelu\",\n","  \"v_hidden_dropout_prob\": 0.1,\n","  \"v_hidden_size\": 1024,\n","  \"v_initializer_range\": 0.02,\n","  \"v_intermediate_size\": 1024,\n","  \"v_num_attention_heads\": 8,\n","  \"v_num_hidden_layers\": 6,\n","  \"v_target_size\": 1601,\n","  \"visual_embedding_dim\": 2048,\n","  \"visual_target\": 0,\n","  \"visualization\": false,\n","  \"vocab_size\": 30522,\n","  \"with_coattention\": true\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.v_pooler.dense.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.t_pooler.dense.weight', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.v_pooler.dense.weight', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.t_pooler.dense.bias', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.v_embeddings.image_embeddings.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m2022-04-26T02:48:29 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n","\u001b[32m2022-04-26T02:48:29 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n","\u001b[32m2022-04-26T02:48:29 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-26T02:48:36 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-26T02:48:36 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n","\u001b[32m2022-04-26T02:48:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2022-04-26T02:48:36 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 14000\n","\u001b[32m2022-04-26T02:48:36 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 14000\n","\u001b[32m2022-04-26T02:48:36 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 53\n","\u001b[32m2022-04-26T02:48:36 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting test inference predictions\n","\u001b[32m2022-04-26T02:48:36 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","100% 63/63 [00:27<00:00,  2.33it/s]\n","\u001b[32m2022-04-26T02:49:03 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/drive/MyDrive/Project/hateful-memes/save/hateful_memes_vilbert_21439143/reports/hateful_memes_run_test_2022-04-26T02:49:03.csv\n","\u001b[32m2022-04-26T02:49:03 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting. Loaded 63\n","\u001b[32m2022-04-26T02:49:03 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"QrGKwIy7qSye","executionInfo":{"status":"ok","timestamp":1649916066153,"user_tz":300,"elapsed":146,"user":{"displayName":"Tianyao Wang","userId":"02589710995949182080"}},"outputId":"c20b8173-9614-43f8-bf14-090983eab5e5","colab":{"base_uri":"https://localhost:8080/","height":35}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/DL7643_Group_project/vilbert/hateful-memes'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!mmf_predict config=\"mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml\" \\\n","model=vilbert \\\n","dataset=hateful_memes \\\n","run_type=val \\\n","checkpoint.resume_file=save/best.ckpt \\\n","checkpoint.resume_pretrained=False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYcrwAfSDbHe","executionInfo":{"status":"ok","timestamp":1650941374433,"user_tz":300,"elapsed":28790,"user":{"displayName":"Frank Wen","userId":"09102209459925731860"}},"outputId":"19b615f8-25d1-40b2-8d4f-bc7e4a31985c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n","  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n","\u001b[32m2022-04-26T02:49:11 | mmf.utils.configuration: \u001b[0mOverriding option config to mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml\n","\u001b[32m2022-04-26T02:49:11 | mmf.utils.configuration: \u001b[0mOverriding option model to vilbert\n","\u001b[32m2022-04-26T02:49:11 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n","\u001b[32m2022-04-26T02:49:11 | mmf.utils.configuration: \u001b[0mOverriding option run_type to val\n","\u001b[32m2022-04-26T02:49:11 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to save/best.ckpt\n","\u001b[32m2022-04-26T02:49:11 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n","\u001b[32m2022-04-26T02:49:11 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n","  category=UserWarning,\n","\u001b[32m2022-04-26T02:49:11 | mmf: \u001b[0mLogging to: ./save/train.log\n","\u001b[32m2022-04-26T02:49:11 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])\n","\u001b[32m2022-04-26T02:49:11 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n","\u001b[32m2022-04-26T02:49:11 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla P100-PCIE-16GB\n","\u001b[32m2022-04-26T02:49:11 | mmf_cli.run: \u001b[0mUsing seed 11855439\n","\u001b[32m2022-04-26T02:49:11 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","\u001b[32m2022-04-26T02:49:13 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T02:49:13 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T02:49:13 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2022-04-26T02:49:13 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n","Model config BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bert_model_name\": \"bert-base-uncased\",\n","  \"bi_attention_type\": 1,\n","  \"bi_hidden_size\": 1024,\n","  \"bi_intermediate_size\": 1024,\n","  \"bi_num_attention_heads\": 8,\n","  \"bypass_transformer\": false,\n","  \"classifier_dropout\": null,\n","  \"cut_first\": \"text\",\n","  \"dynamic_attention\": false,\n","  \"embedding_strategy\": \"plain\",\n","  \"fast_mode\": false,\n","  \"finetune_lr_multiplier\": 1,\n","  \"fixed_t_layer\": 0,\n","  \"fixed_v_layer\": 0,\n","  \"freeze_base\": false,\n","  \"fusion_method\": \"mul\",\n","  \"gradient_checkpointing\": false,\n","  \"hard_cap_seq_len\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"in_batch_pairs\": false,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"losses\": [\n","    \"cross_entropy\"\n","  ],\n","  \"max_position_embeddings\": 512,\n","  \"model\": \"vilbert\",\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_negative\": 128,\n","  \"objective\": 0,\n","  \"pad_token_id\": 0,\n","  \"pooling_method\": \"mul\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"random_initialize\": false,\n","  \"special_visual_initialize\": true,\n","  \"t_biattention_id\": [\n","    6,\n","    7,\n","    8,\n","    9,\n","    10,\n","    11\n","  ],\n","  \"task_specific_tokens\": false,\n","  \"text_only\": false,\n","  \"training_head_type\": \"classification\",\n","  \"transformers_version\": \"4.10.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"v_attention_probs_dropout_prob\": 0.1,\n","  \"v_biattention_id\": [\n","    0,\n","    1,\n","    2,\n","    3,\n","    4,\n","    5\n","  ],\n","  \"v_feature_size\": 2048,\n","  \"v_hidden_act\": \"gelu\",\n","  \"v_hidden_dropout_prob\": 0.1,\n","  \"v_hidden_size\": 1024,\n","  \"v_initializer_range\": 0.02,\n","  \"v_intermediate_size\": 1024,\n","  \"v_num_attention_heads\": 8,\n","  \"v_num_hidden_layers\": 6,\n","  \"v_target_size\": 1601,\n","  \"visual_embedding_dim\": 2048,\n","  \"visual_target\": 0,\n","  \"visualization\": false,\n","  \"vocab_size\": 30522,\n","  \"with_coattention\": true\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.predictions.decoder.weight', 'bert.pooler.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.t_pooler.dense.bias', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.v_pooler.dense.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.v_pooler.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.v_embeddings.image_embeddings.weight', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.1.t_output.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m2022-04-26T02:49:19 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n","\u001b[32m2022-04-26T02:49:19 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n","\u001b[32m2022-04-26T02:49:19 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-26T02:49:24 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-04-26T02:49:24 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n","\u001b[32m2022-04-26T02:49:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2022-04-26T02:49:24 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 14000\n","\u001b[32m2022-04-26T02:49:24 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 14000\n","\u001b[32m2022-04-26T02:49:24 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 53\n","\u001b[32m2022-04-26T02:49:24 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting val inference predictions\n","\u001b[32m2022-04-26T02:49:24 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","100% 17/17 [00:07<00:00,  2.17it/s]\n","\u001b[32m2022-04-26T02:49:32 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/drive/MyDrive/Project/hateful-memes/save/hateful_memes_vilbert_11855439/reports/hateful_memes_run_val_2022-04-26T02:49:32.csv\n","\u001b[32m2022-04-26T02:49:32 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting. Loaded 17\n","\u001b[32m2022-04-26T02:49:32 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"pnQU7yMqEJun"},"execution_count":null,"outputs":[]}]}