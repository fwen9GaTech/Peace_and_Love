2022-04-21T14:26:52 | INFO | mmf : Logging to: ./save/train.log
2022-04-21T14:26:52 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/from_cc.yaml', 'model=vilbert', 'dataset=hateful_memes'])
2022-04-21T14:26:52 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-04-21T14:26:52 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla P100-PCIE-16GB
2022-04-21T14:26:52 | INFO | mmf_cli.run : Using seed 52146428
2022-04-21T14:26:52 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-04-21T14:35:32 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-21T14:35:32 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-21T14:35:32 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-21T14:35:32 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-04-21T14:35:46 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-04-21T14:35:46 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-04-21T14:35:46 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-04-21T14:36:17 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-04-21T14:36:17 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-04-21T14:36:17 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-04-21T14:36:17 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.v_embeddings.image_embeddings.weight from model.bert.v_embeddings.image_embeddings.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.v_embeddings.image_embeddings.bias from model.bert.v_embeddings.image_embeddings.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.v_embeddings.image_location_embeddings.weight from model.bert.v_embeddings.image_location_embeddings.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.v_embeddings.image_location_embeddings.bias from model.bert.v_embeddings.image_location_embeddings.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.v_embeddings.LayerNorm.weight from model.bert.v_embeddings.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.v_embeddings.LayerNorm.bias from model.bert.v_embeddings.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight
2022-04-21T14:36:17 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.self.query.weight from model.bert.encoder.v_layer.0.attention.self.query.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.self.query.bias from model.bert.encoder.v_layer.0.attention.self.query.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.self.key.weight from model.bert.encoder.v_layer.0.attention.self.key.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.self.key.bias from model.bert.encoder.v_layer.0.attention.self.key.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.self.value.weight from model.bert.encoder.v_layer.0.attention.self.value.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.self.value.bias from model.bert.encoder.v_layer.0.attention.self.value.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.output.dense.weight from model.bert.encoder.v_layer.0.attention.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.output.dense.bias from model.bert.encoder.v_layer.0.attention.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.0.attention.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.0.attention.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.intermediate.dense.weight from model.bert.encoder.v_layer.0.intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.intermediate.dense.bias from model.bert.encoder.v_layer.0.intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.output.dense.weight from model.bert.encoder.v_layer.0.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.output.dense.bias from model.bert.encoder.v_layer.0.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.output.LayerNorm.weight from model.bert.encoder.v_layer.0.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.0.output.LayerNorm.bias from model.bert.encoder.v_layer.0.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.self.query.weight from model.bert.encoder.v_layer.1.attention.self.query.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.self.query.bias from model.bert.encoder.v_layer.1.attention.self.query.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.self.key.weight from model.bert.encoder.v_layer.1.attention.self.key.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.self.key.bias from model.bert.encoder.v_layer.1.attention.self.key.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.self.value.weight from model.bert.encoder.v_layer.1.attention.self.value.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.self.value.bias from model.bert.encoder.v_layer.1.attention.self.value.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.output.dense.weight from model.bert.encoder.v_layer.1.attention.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.output.dense.bias from model.bert.encoder.v_layer.1.attention.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.1.attention.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.1.attention.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.intermediate.dense.weight from model.bert.encoder.v_layer.1.intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.intermediate.dense.bias from model.bert.encoder.v_layer.1.intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.output.dense.weight from model.bert.encoder.v_layer.1.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.output.dense.bias from model.bert.encoder.v_layer.1.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.output.LayerNorm.weight from model.bert.encoder.v_layer.1.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.1.output.LayerNorm.bias from model.bert.encoder.v_layer.1.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.self.query.weight from model.bert.encoder.v_layer.2.attention.self.query.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.self.query.bias from model.bert.encoder.v_layer.2.attention.self.query.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.self.key.weight from model.bert.encoder.v_layer.2.attention.self.key.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.self.key.bias from model.bert.encoder.v_layer.2.attention.self.key.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.self.value.weight from model.bert.encoder.v_layer.2.attention.self.value.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.self.value.bias from model.bert.encoder.v_layer.2.attention.self.value.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.output.dense.weight from model.bert.encoder.v_layer.2.attention.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.output.dense.bias from model.bert.encoder.v_layer.2.attention.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.2.attention.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.2.attention.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.intermediate.dense.weight from model.bert.encoder.v_layer.2.intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.intermediate.dense.bias from model.bert.encoder.v_layer.2.intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.output.dense.weight from model.bert.encoder.v_layer.2.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.output.dense.bias from model.bert.encoder.v_layer.2.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.output.LayerNorm.weight from model.bert.encoder.v_layer.2.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.2.output.LayerNorm.bias from model.bert.encoder.v_layer.2.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.self.query.weight from model.bert.encoder.v_layer.3.attention.self.query.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.self.query.bias from model.bert.encoder.v_layer.3.attention.self.query.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.self.key.weight from model.bert.encoder.v_layer.3.attention.self.key.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.self.key.bias from model.bert.encoder.v_layer.3.attention.self.key.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.self.value.weight from model.bert.encoder.v_layer.3.attention.self.value.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.self.value.bias from model.bert.encoder.v_layer.3.attention.self.value.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.output.dense.weight from model.bert.encoder.v_layer.3.attention.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.output.dense.bias from model.bert.encoder.v_layer.3.attention.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.3.attention.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.3.attention.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.intermediate.dense.weight from model.bert.encoder.v_layer.3.intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.intermediate.dense.bias from model.bert.encoder.v_layer.3.intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.output.dense.weight from model.bert.encoder.v_layer.3.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.output.dense.bias from model.bert.encoder.v_layer.3.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.output.LayerNorm.weight from model.bert.encoder.v_layer.3.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.3.output.LayerNorm.bias from model.bert.encoder.v_layer.3.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.self.query.weight from model.bert.encoder.v_layer.4.attention.self.query.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.self.query.bias from model.bert.encoder.v_layer.4.attention.self.query.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.self.key.weight from model.bert.encoder.v_layer.4.attention.self.key.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.self.key.bias from model.bert.encoder.v_layer.4.attention.self.key.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.self.value.weight from model.bert.encoder.v_layer.4.attention.self.value.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.self.value.bias from model.bert.encoder.v_layer.4.attention.self.value.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.output.dense.weight from model.bert.encoder.v_layer.4.attention.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.output.dense.bias from model.bert.encoder.v_layer.4.attention.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.4.attention.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.4.attention.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.intermediate.dense.weight from model.bert.encoder.v_layer.4.intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.intermediate.dense.bias from model.bert.encoder.v_layer.4.intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.output.dense.weight from model.bert.encoder.v_layer.4.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.output.dense.bias from model.bert.encoder.v_layer.4.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.output.LayerNorm.weight from model.bert.encoder.v_layer.4.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.4.output.LayerNorm.bias from model.bert.encoder.v_layer.4.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.self.query.weight from model.bert.encoder.v_layer.5.attention.self.query.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.self.query.bias from model.bert.encoder.v_layer.5.attention.self.query.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.self.key.weight from model.bert.encoder.v_layer.5.attention.self.key.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.self.key.bias from model.bert.encoder.v_layer.5.attention.self.key.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.self.value.weight from model.bert.encoder.v_layer.5.attention.self.value.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.self.value.bias from model.bert.encoder.v_layer.5.attention.self.value.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.output.dense.weight from model.bert.encoder.v_layer.5.attention.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.output.dense.bias from model.bert.encoder.v_layer.5.attention.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight from model.bert.encoder.v_layer.5.attention.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias from model.bert.encoder.v_layer.5.attention.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.intermediate.dense.weight from model.bert.encoder.v_layer.5.intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.intermediate.dense.bias from model.bert.encoder.v_layer.5.intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.output.dense.weight from model.bert.encoder.v_layer.5.output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.output.dense.bias from model.bert.encoder.v_layer.5.output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.output.LayerNorm.weight from model.bert.encoder.v_layer.5.output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.v_layer.5.output.LayerNorm.bias from model.bert.encoder.v_layer.5.output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.query1.weight from model.bert.encoder.c_layer.0.biattention.query1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.query1.bias from model.bert.encoder.c_layer.0.biattention.query1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.key1.weight from model.bert.encoder.c_layer.0.biattention.key1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.key1.bias from model.bert.encoder.c_layer.0.biattention.key1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.value1.weight from model.bert.encoder.c_layer.0.biattention.value1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.value1.bias from model.bert.encoder.c_layer.0.biattention.value1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.query2.weight from model.bert.encoder.c_layer.0.biattention.query2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.query2.bias from model.bert.encoder.c_layer.0.biattention.query2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.key2.weight from model.bert.encoder.c_layer.0.biattention.key2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.key2.bias from model.bert.encoder.c_layer.0.biattention.key2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.value2.weight from model.bert.encoder.c_layer.0.biattention.value2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biattention.value2.bias from model.bert.encoder.c_layer.0.biattention.value2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.dense1.weight from model.bert.encoder.c_layer.0.biOutput.dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.dense1.bias from model.bert.encoder.c_layer.0.biOutput.dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.q_dense1.weight from model.bert.encoder.c_layer.0.biOutput.q_dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.q_dense1.bias from model.bert.encoder.c_layer.0.biOutput.q_dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.dense2.weight from model.bert.encoder.c_layer.0.biOutput.dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.dense2.bias from model.bert.encoder.c_layer.0.biOutput.dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.0.biOutput.LayerNorm2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.q_dense2.weight from model.bert.encoder.c_layer.0.biOutput.q_dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.biOutput.q_dense2.bias from model.bert.encoder.c_layer.0.biOutput.q_dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.v_intermediate.dense.weight from model.bert.encoder.c_layer.0.v_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.v_intermediate.dense.bias from model.bert.encoder.c_layer.0.v_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.v_output.dense.weight from model.bert.encoder.c_layer.0.v_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.v_output.dense.bias from model.bert.encoder.c_layer.0.v_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.v_output.LayerNorm.weight from model.bert.encoder.c_layer.0.v_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.v_output.LayerNorm.bias from model.bert.encoder.c_layer.0.v_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.t_intermediate.dense.weight from model.bert.encoder.c_layer.0.t_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.t_intermediate.dense.bias from model.bert.encoder.c_layer.0.t_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.t_output.dense.weight from model.bert.encoder.c_layer.0.t_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.t_output.dense.bias from model.bert.encoder.c_layer.0.t_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.t_output.LayerNorm.weight from model.bert.encoder.c_layer.0.t_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.0.t_output.LayerNorm.bias from model.bert.encoder.c_layer.0.t_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.query1.weight from model.bert.encoder.c_layer.1.biattention.query1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.query1.bias from model.bert.encoder.c_layer.1.biattention.query1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.key1.weight from model.bert.encoder.c_layer.1.biattention.key1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.key1.bias from model.bert.encoder.c_layer.1.biattention.key1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.value1.weight from model.bert.encoder.c_layer.1.biattention.value1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.value1.bias from model.bert.encoder.c_layer.1.biattention.value1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.query2.weight from model.bert.encoder.c_layer.1.biattention.query2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.query2.bias from model.bert.encoder.c_layer.1.biattention.query2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.key2.weight from model.bert.encoder.c_layer.1.biattention.key2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.key2.bias from model.bert.encoder.c_layer.1.biattention.key2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.value2.weight from model.bert.encoder.c_layer.1.biattention.value2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biattention.value2.bias from model.bert.encoder.c_layer.1.biattention.value2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.dense1.weight from model.bert.encoder.c_layer.1.biOutput.dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.dense1.bias from model.bert.encoder.c_layer.1.biOutput.dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.q_dense1.weight from model.bert.encoder.c_layer.1.biOutput.q_dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.q_dense1.bias from model.bert.encoder.c_layer.1.biOutput.q_dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.dense2.weight from model.bert.encoder.c_layer.1.biOutput.dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.dense2.bias from model.bert.encoder.c_layer.1.biOutput.dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.1.biOutput.LayerNorm2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.q_dense2.weight from model.bert.encoder.c_layer.1.biOutput.q_dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.biOutput.q_dense2.bias from model.bert.encoder.c_layer.1.biOutput.q_dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.v_intermediate.dense.weight from model.bert.encoder.c_layer.1.v_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.v_intermediate.dense.bias from model.bert.encoder.c_layer.1.v_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.v_output.dense.weight from model.bert.encoder.c_layer.1.v_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.v_output.dense.bias from model.bert.encoder.c_layer.1.v_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.v_output.LayerNorm.weight from model.bert.encoder.c_layer.1.v_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.v_output.LayerNorm.bias from model.bert.encoder.c_layer.1.v_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.t_intermediate.dense.weight from model.bert.encoder.c_layer.1.t_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.t_intermediate.dense.bias from model.bert.encoder.c_layer.1.t_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.t_output.dense.weight from model.bert.encoder.c_layer.1.t_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.t_output.dense.bias from model.bert.encoder.c_layer.1.t_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.t_output.LayerNorm.weight from model.bert.encoder.c_layer.1.t_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.1.t_output.LayerNorm.bias from model.bert.encoder.c_layer.1.t_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.query1.weight from model.bert.encoder.c_layer.2.biattention.query1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.query1.bias from model.bert.encoder.c_layer.2.biattention.query1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.key1.weight from model.bert.encoder.c_layer.2.biattention.key1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.key1.bias from model.bert.encoder.c_layer.2.biattention.key1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.value1.weight from model.bert.encoder.c_layer.2.biattention.value1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.value1.bias from model.bert.encoder.c_layer.2.biattention.value1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.query2.weight from model.bert.encoder.c_layer.2.biattention.query2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.query2.bias from model.bert.encoder.c_layer.2.biattention.query2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.key2.weight from model.bert.encoder.c_layer.2.biattention.key2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.key2.bias from model.bert.encoder.c_layer.2.biattention.key2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.value2.weight from model.bert.encoder.c_layer.2.biattention.value2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biattention.value2.bias from model.bert.encoder.c_layer.2.biattention.value2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.dense1.weight from model.bert.encoder.c_layer.2.biOutput.dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.dense1.bias from model.bert.encoder.c_layer.2.biOutput.dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.q_dense1.weight from model.bert.encoder.c_layer.2.biOutput.q_dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.q_dense1.bias from model.bert.encoder.c_layer.2.biOutput.q_dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.dense2.weight from model.bert.encoder.c_layer.2.biOutput.dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.dense2.bias from model.bert.encoder.c_layer.2.biOutput.dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.2.biOutput.LayerNorm2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.q_dense2.weight from model.bert.encoder.c_layer.2.biOutput.q_dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.biOutput.q_dense2.bias from model.bert.encoder.c_layer.2.biOutput.q_dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.v_intermediate.dense.weight from model.bert.encoder.c_layer.2.v_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.v_intermediate.dense.bias from model.bert.encoder.c_layer.2.v_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.v_output.dense.weight from model.bert.encoder.c_layer.2.v_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.v_output.dense.bias from model.bert.encoder.c_layer.2.v_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.v_output.LayerNorm.weight from model.bert.encoder.c_layer.2.v_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.v_output.LayerNorm.bias from model.bert.encoder.c_layer.2.v_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.t_intermediate.dense.weight from model.bert.encoder.c_layer.2.t_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.t_intermediate.dense.bias from model.bert.encoder.c_layer.2.t_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.t_output.dense.weight from model.bert.encoder.c_layer.2.t_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.t_output.dense.bias from model.bert.encoder.c_layer.2.t_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.t_output.LayerNorm.weight from model.bert.encoder.c_layer.2.t_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.2.t_output.LayerNorm.bias from model.bert.encoder.c_layer.2.t_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.query1.weight from model.bert.encoder.c_layer.3.biattention.query1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.query1.bias from model.bert.encoder.c_layer.3.biattention.query1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.key1.weight from model.bert.encoder.c_layer.3.biattention.key1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.key1.bias from model.bert.encoder.c_layer.3.biattention.key1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.value1.weight from model.bert.encoder.c_layer.3.biattention.value1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.value1.bias from model.bert.encoder.c_layer.3.biattention.value1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.query2.weight from model.bert.encoder.c_layer.3.biattention.query2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.query2.bias from model.bert.encoder.c_layer.3.biattention.query2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.key2.weight from model.bert.encoder.c_layer.3.biattention.key2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.key2.bias from model.bert.encoder.c_layer.3.biattention.key2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.value2.weight from model.bert.encoder.c_layer.3.biattention.value2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biattention.value2.bias from model.bert.encoder.c_layer.3.biattention.value2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.dense1.weight from model.bert.encoder.c_layer.3.biOutput.dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.dense1.bias from model.bert.encoder.c_layer.3.biOutput.dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.q_dense1.weight from model.bert.encoder.c_layer.3.biOutput.q_dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.q_dense1.bias from model.bert.encoder.c_layer.3.biOutput.q_dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.dense2.weight from model.bert.encoder.c_layer.3.biOutput.dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.dense2.bias from model.bert.encoder.c_layer.3.biOutput.dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.3.biOutput.LayerNorm2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.q_dense2.weight from model.bert.encoder.c_layer.3.biOutput.q_dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.biOutput.q_dense2.bias from model.bert.encoder.c_layer.3.biOutput.q_dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.v_intermediate.dense.weight from model.bert.encoder.c_layer.3.v_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.v_intermediate.dense.bias from model.bert.encoder.c_layer.3.v_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.v_output.dense.weight from model.bert.encoder.c_layer.3.v_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.v_output.dense.bias from model.bert.encoder.c_layer.3.v_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.v_output.LayerNorm.weight from model.bert.encoder.c_layer.3.v_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.v_output.LayerNorm.bias from model.bert.encoder.c_layer.3.v_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.t_intermediate.dense.weight from model.bert.encoder.c_layer.3.t_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.t_intermediate.dense.bias from model.bert.encoder.c_layer.3.t_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.t_output.dense.weight from model.bert.encoder.c_layer.3.t_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.t_output.dense.bias from model.bert.encoder.c_layer.3.t_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.t_output.LayerNorm.weight from model.bert.encoder.c_layer.3.t_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.3.t_output.LayerNorm.bias from model.bert.encoder.c_layer.3.t_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.query1.weight from model.bert.encoder.c_layer.4.biattention.query1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.query1.bias from model.bert.encoder.c_layer.4.biattention.query1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.key1.weight from model.bert.encoder.c_layer.4.biattention.key1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.key1.bias from model.bert.encoder.c_layer.4.biattention.key1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.value1.weight from model.bert.encoder.c_layer.4.biattention.value1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.value1.bias from model.bert.encoder.c_layer.4.biattention.value1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.query2.weight from model.bert.encoder.c_layer.4.biattention.query2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.query2.bias from model.bert.encoder.c_layer.4.biattention.query2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.key2.weight from model.bert.encoder.c_layer.4.biattention.key2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.key2.bias from model.bert.encoder.c_layer.4.biattention.key2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.value2.weight from model.bert.encoder.c_layer.4.biattention.value2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biattention.value2.bias from model.bert.encoder.c_layer.4.biattention.value2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.dense1.weight from model.bert.encoder.c_layer.4.biOutput.dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.dense1.bias from model.bert.encoder.c_layer.4.biOutput.dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.q_dense1.weight from model.bert.encoder.c_layer.4.biOutput.q_dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.q_dense1.bias from model.bert.encoder.c_layer.4.biOutput.q_dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.dense2.weight from model.bert.encoder.c_layer.4.biOutput.dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.dense2.bias from model.bert.encoder.c_layer.4.biOutput.dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.4.biOutput.LayerNorm2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.q_dense2.weight from model.bert.encoder.c_layer.4.biOutput.q_dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.biOutput.q_dense2.bias from model.bert.encoder.c_layer.4.biOutput.q_dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.v_intermediate.dense.weight from model.bert.encoder.c_layer.4.v_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.v_intermediate.dense.bias from model.bert.encoder.c_layer.4.v_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.v_output.dense.weight from model.bert.encoder.c_layer.4.v_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.v_output.dense.bias from model.bert.encoder.c_layer.4.v_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.v_output.LayerNorm.weight from model.bert.encoder.c_layer.4.v_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.v_output.LayerNorm.bias from model.bert.encoder.c_layer.4.v_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.t_intermediate.dense.weight from model.bert.encoder.c_layer.4.t_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.t_intermediate.dense.bias from model.bert.encoder.c_layer.4.t_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.t_output.dense.weight from model.bert.encoder.c_layer.4.t_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.t_output.dense.bias from model.bert.encoder.c_layer.4.t_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.t_output.LayerNorm.weight from model.bert.encoder.c_layer.4.t_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.4.t_output.LayerNorm.bias from model.bert.encoder.c_layer.4.t_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.query1.weight from model.bert.encoder.c_layer.5.biattention.query1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.query1.bias from model.bert.encoder.c_layer.5.biattention.query1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.key1.weight from model.bert.encoder.c_layer.5.biattention.key1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.key1.bias from model.bert.encoder.c_layer.5.biattention.key1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.value1.weight from model.bert.encoder.c_layer.5.biattention.value1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.value1.bias from model.bert.encoder.c_layer.5.biattention.value1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.query2.weight from model.bert.encoder.c_layer.5.biattention.query2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.query2.bias from model.bert.encoder.c_layer.5.biattention.query2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.key2.weight from model.bert.encoder.c_layer.5.biattention.key2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.key2.bias from model.bert.encoder.c_layer.5.biattention.key2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.value2.weight from model.bert.encoder.c_layer.5.biattention.value2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biattention.value2.bias from model.bert.encoder.c_layer.5.biattention.value2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.dense1.weight from model.bert.encoder.c_layer.5.biOutput.dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.dense1.bias from model.bert.encoder.c_layer.5.biOutput.dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.q_dense1.weight from model.bert.encoder.c_layer.5.biOutput.q_dense1.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.q_dense1.bias from model.bert.encoder.c_layer.5.biOutput.q_dense1.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.dense2.weight from model.bert.encoder.c_layer.5.biOutput.dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.dense2.bias from model.bert.encoder.c_layer.5.biOutput.dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias from model.bert.encoder.c_layer.5.biOutput.LayerNorm2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.q_dense2.weight from model.bert.encoder.c_layer.5.biOutput.q_dense2.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.biOutput.q_dense2.bias from model.bert.encoder.c_layer.5.biOutput.q_dense2.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.v_intermediate.dense.weight from model.bert.encoder.c_layer.5.v_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.v_intermediate.dense.bias from model.bert.encoder.c_layer.5.v_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.v_output.dense.weight from model.bert.encoder.c_layer.5.v_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.v_output.dense.bias from model.bert.encoder.c_layer.5.v_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.v_output.LayerNorm.weight from model.bert.encoder.c_layer.5.v_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.v_output.LayerNorm.bias from model.bert.encoder.c_layer.5.v_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.t_intermediate.dense.weight from model.bert.encoder.c_layer.5.t_intermediate.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.t_intermediate.dense.bias from model.bert.encoder.c_layer.5.t_intermediate.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.t_output.dense.weight from model.bert.encoder.c_layer.5.t_output.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.t_output.dense.bias from model.bert.encoder.c_layer.5.t_output.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.t_output.LayerNorm.weight from model.bert.encoder.c_layer.5.t_output.LayerNorm.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.encoder.c_layer.5.t_output.LayerNorm.bias from model.bert.encoder.c_layer.5.t_output.LayerNorm.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.t_pooler.dense.weight from model.bert.t_pooler.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.t_pooler.dense.bias from model.bert.t_pooler.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.v_pooler.dense.weight from model.bert.v_pooler.dense.weight
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Copying model.bert.v_pooler.dense.bias from model.bert.v_pooler.dense.bias
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Pretrained model loaded
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Current num updates: 0
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Current iteration: 0
2022-04-21T14:36:18 | INFO | mmf.utils.checkpoint : Current epoch: 0
2022-04-21T14:36:18 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2022-04-21T14:36:18 | INFO | mmf.trainers.mmf_trainer : ViLBERT(
  (model): ViLBERTForClassification(
    (bert): ViLBERTBase(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (v_embeddings): BertImageFeatureEmbeddings(
        (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)
        (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (v_layer): ModuleList(
          (0): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (c_layer): ModuleList(
          (0): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (t_pooler): BertTextPooler(
        (dense): Linear(in_features=768, out_features=1024, bias=True)
        (activation): ReLU()
      )
      (v_pooler): BertImagePooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): ReLU()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2022-04-21T14:36:18 | INFO | mmf.utils.general : Total Parameters: 247780354. Trained Parameters: 247780354
2022-04-21T14:36:18 | INFO | mmf.trainers.core.training_loop : Starting training...
2022-04-21T14:37:55 | INFO | mmf.trainers.callbacks.logistics : progress: 100/22000, train/hateful_memes/cross_entropy: 0.5797, train/hateful_memes/cross_entropy/avg: 0.5797, train/total_loss: 0.5797, train/total_loss/avg: 0.5797, max mem: 10794.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 628ms, time_since_start: 02m 08s 437ms, eta: 05h 58m 41s 480ms
2022-04-21T14:39:30 | INFO | mmf.trainers.callbacks.logistics : progress: 200/22000, train/hateful_memes/cross_entropy: 0.5797, train/hateful_memes/cross_entropy/avg: 0.6082, train/total_loss: 0.5797, train/total_loss/avg: 0.6082, max mem: 10794.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 312ms, time_since_start: 03m 43s 749ms, eta: 05h 52m 11s 402ms
2022-04-21T14:41:05 | INFO | mmf.trainers.callbacks.logistics : progress: 300/22000, train/hateful_memes/cross_entropy: 0.6337, train/hateful_memes/cross_entropy/avg: 0.6167, train/total_loss: 0.6337, train/total_loss/avg: 0.6167, max mem: 10794.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 107ms, time_since_start: 05m 18s 857ms, eta: 05h 49m 49s 153ms
2022-04-21T14:42:40 | INFO | mmf.trainers.callbacks.logistics : progress: 400/22000, train/hateful_memes/cross_entropy: 0.5797, train/hateful_memes/cross_entropy/avg: 0.6056, train/total_loss: 0.5797, train/total_loss/avg: 0.6056, max mem: 10794.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 291ms, time_since_start: 06m 54s 148ms, eta: 05h 48m 52s 822ms
2022-04-21T14:44:16 | INFO | mmf.trainers.callbacks.logistics : progress: 500/22000, train/hateful_memes/cross_entropy: 0.5797, train/hateful_memes/cross_entropy/avg: 0.5959, train/total_loss: 0.5797, train/total_loss/avg: 0.5959, max mem: 10794.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 279ms, time_since_start: 08m 29s 427ms, eta: 05h 47m 13s 246ms
2022-04-21T14:45:50 | INFO | mmf.trainers.callbacks.logistics : progress: 600/22000, train/hateful_memes/cross_entropy: 0.5797, train/hateful_memes/cross_entropy/avg: 0.5953, train/total_loss: 0.5797, train/total_loss/avg: 0.5953, max mem: 10794.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 752ms, time_since_start: 10m 04s 180ms, eta: 05h 43m 41s 710ms
2022-04-21T14:47:26 | INFO | mmf.trainers.callbacks.logistics : progress: 700/22000, train/hateful_memes/cross_entropy: 0.5797, train/hateful_memes/cross_entropy/avg: 0.5871, train/total_loss: 0.5797, train/total_loss/avg: 0.5871, max mem: 10794.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 319ms, time_since_start: 11m 39s 499ms, eta: 05h 44m 08s 102ms
2022-04-21T14:49:01 | INFO | mmf.trainers.callbacks.logistics : progress: 800/22000, train/hateful_memes/cross_entropy: 0.5797, train/hateful_memes/cross_entropy/avg: 0.5911, train/total_loss: 0.5797, train/total_loss/avg: 0.5911, max mem: 10794.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 948ms, time_since_start: 13m 14s 447ms, eta: 05h 41m 11s 220ms
2022-04-21T14:50:36 | INFO | mmf.trainers.callbacks.logistics : progress: 900/22000, train/hateful_memes/cross_entropy: 0.5797, train/hateful_memes/cross_entropy/avg: 0.5658, train/total_loss: 0.5797, train/total_loss/avg: 0.5658, max mem: 10794.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 178ms, time_since_start: 14m 49s 626ms, eta: 05h 40m 24s 156ms
2022-04-21T14:52:11 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T14:52:11 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T14:52:21 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T14:52:31 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T14:52:31 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, train/hateful_memes/cross_entropy: 0.5724, train/hateful_memes/cross_entropy/avg: 0.5449, train/total_loss: 0.5724, train/total_loss/avg: 0.5449, max mem: 10794.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00001, ups: 0.87, time: 01m 55s 545ms, time_since_start: 16m 45s 171ms, eta: 06h 51m 17s 008ms
2022-04-21T14:52:31 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T14:52:33 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T14:52:40 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T14:52:40 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T14:52:41 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T14:52:51 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-04-21T14:53:03 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T14:53:14 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T14:53:15 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, val/hateful_memes/cross_entropy: 0.7676, val/total_loss: 0.7676, val/hateful_memes/accuracy: 0.6407, val/hateful_memes/binary_f1: 0.3310, val/hateful_memes/roc_auc: 0.6465, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 43s 114ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.646471
2022-04-21T14:54:55 | INFO | mmf.trainers.callbacks.logistics : progress: 1100/22000, train/hateful_memes/cross_entropy: 0.5724, train/hateful_memes/cross_entropy/avg: 0.5183, train/total_loss: 0.5724, train/total_loss/avg: 0.5183, max mem: 10794.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00001, ups: 1.00, time: 01m 40s 044ms, time_since_start: 19m 08s 331ms, eta: 05h 54m 24s 680ms
2022-04-21T14:56:30 | INFO | mmf.trainers.callbacks.logistics : progress: 1200/22000, train/hateful_memes/cross_entropy: 0.5572, train/hateful_memes/cross_entropy/avg: 0.4998, train/total_loss: 0.5572, train/total_loss/avg: 0.4998, max mem: 10794.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 541ms, time_since_start: 20m 43s 873ms, eta: 05h 36m 50s 497ms
2022-04-21T14:58:05 | INFO | mmf.trainers.callbacks.logistics : progress: 1300/22000, train/hateful_memes/cross_entropy: 0.5572, train/hateful_memes/cross_entropy/avg: 0.4816, train/total_loss: 0.5572, train/total_loss/avg: 0.4816, max mem: 10794.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 395ms, time_since_start: 22m 19s 268ms, eta: 05h 34m 42s 510ms
2022-04-21T14:59:41 | INFO | mmf.trainers.callbacks.logistics : progress: 1400/22000, train/hateful_memes/cross_entropy: 0.5382, train/hateful_memes/cross_entropy/avg: 0.4642, train/total_loss: 0.5382, train/total_loss/avg: 0.4642, max mem: 10794.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 183ms, time_since_start: 23m 54s 452ms, eta: 05h 32m 21s 129ms
2022-04-21T15:01:16 | INFO | mmf.trainers.callbacks.logistics : progress: 1500/22000, train/hateful_memes/cross_entropy: 0.5382, train/hateful_memes/cross_entropy/avg: 0.4666, train/total_loss: 0.5382, train/total_loss/avg: 0.4666, max mem: 10794.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 433ms, time_since_start: 25m 29s 885ms, eta: 05h 31m 36s 506ms
2022-04-21T15:02:51 | INFO | mmf.trainers.callbacks.logistics : progress: 1600/22000, train/hateful_memes/cross_entropy: 0.5002, train/hateful_memes/cross_entropy/avg: 0.4530, train/total_loss: 0.5002, train/total_loss/avg: 0.4530, max mem: 10794.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 887ms, time_since_start: 27m 04s 773ms, eta: 05h 28m 06s 199ms
2022-04-21T15:04:27 | INFO | mmf.trainers.callbacks.logistics : progress: 1700/22000, train/hateful_memes/cross_entropy: 0.5002, train/hateful_memes/cross_entropy/avg: 0.4411, train/total_loss: 0.5002, train/total_loss/avg: 0.4411, max mem: 10794.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 518ms, time_since_start: 28m 40s 292ms, eta: 05h 28m 39s 916ms
2022-04-21T15:06:02 | INFO | mmf.trainers.callbacks.logistics : progress: 1800/22000, train/hateful_memes/cross_entropy: 0.3637, train/hateful_memes/cross_entropy/avg: 0.4224, train/total_loss: 0.3637, train/total_loss/avg: 0.4224, max mem: 10794.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 356ms, time_since_start: 30m 15s 648ms, eta: 05h 26m 29s 415ms
2022-04-21T15:07:37 | INFO | mmf.trainers.callbacks.logistics : progress: 1900/22000, train/hateful_memes/cross_entropy: 0.3637, train/hateful_memes/cross_entropy/avg: 0.4044, train/total_loss: 0.3637, train/total_loss/avg: 0.4044, max mem: 10794.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 987ms, time_since_start: 31m 50s 635ms, eta: 05h 23m 36s 985ms
2022-04-21T15:09:12 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T15:09:12 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T15:09:21 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T15:09:33 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T15:09:33 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, train/hateful_memes/cross_entropy: 0.3563, train/hateful_memes/cross_entropy/avg: 0.3884, train/total_loss: 0.3563, train/total_loss/avg: 0.3884, max mem: 10794.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00001, ups: 0.86, time: 01m 56s 296ms, time_since_start: 33m 46s 932ms, eta: 06h 34m 14s 692ms
2022-04-21T15:09:33 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T15:09:33 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T15:09:39 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T15:09:39 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T15:09:39 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T15:09:48 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-04-21T15:10:02 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T15:10:17 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T15:10:17 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, val/hateful_memes/cross_entropy: 0.9934, val/total_loss: 0.9934, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4971, val/hateful_memes/roc_auc: 0.6865, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 44s 084ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.686471
2022-04-21T15:11:54 | INFO | mmf.trainers.callbacks.logistics : progress: 2100/22000, train/hateful_memes/cross_entropy: 0.2961, train/hateful_memes/cross_entropy/avg: 0.3767, train/total_loss: 0.2961, train/total_loss/avg: 0.3767, max mem: 10794.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 748ms, time_since_start: 36m 07s 766ms, eta: 05h 26m 20s 169ms
2022-04-21T15:13:29 | INFO | mmf.trainers.callbacks.logistics : progress: 2200/22000, train/hateful_memes/cross_entropy: 0.2633, train/hateful_memes/cross_entropy/avg: 0.3611, train/total_loss: 0.2633, train/total_loss/avg: 0.3611, max mem: 10794.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 319ms, time_since_start: 37m 43s 085ms, eta: 05h 19m 54s 085ms
2022-04-21T15:15:05 | INFO | mmf.trainers.callbacks.logistics : progress: 2300/22000, train/hateful_memes/cross_entropy: 0.2529, train/hateful_memes/cross_entropy/avg: 0.3469, train/total_loss: 0.2529, train/total_loss/avg: 0.3469, max mem: 10794.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 489ms, time_since_start: 39m 18s 575ms, eta: 05h 18m 51s 197ms
2022-04-21T15:16:40 | INFO | mmf.trainers.callbacks.logistics : progress: 2400/22000, train/hateful_memes/cross_entropy: 0.2511, train/hateful_memes/cross_entropy/avg: 0.3343, train/total_loss: 0.2511, train/total_loss/avg: 0.3343, max mem: 10794.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 256ms, time_since_start: 40m 53s 831ms, eta: 05h 16m 27s 592ms
2022-04-21T15:18:16 | INFO | mmf.trainers.callbacks.logistics : progress: 2500/22000, train/hateful_memes/cross_entropy: 0.2490, train/hateful_memes/cross_entropy/avg: 0.3227, train/total_loss: 0.2490, train/total_loss/avg: 0.3227, max mem: 10794.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 573ms, time_since_start: 42m 29s 404ms, eta: 05h 15m 53s 635ms
2022-04-21T15:19:51 | INFO | mmf.trainers.callbacks.logistics : progress: 2600/22000, train/hateful_memes/cross_entropy: 0.2379, train/hateful_memes/cross_entropy/avg: 0.3113, train/total_loss: 0.2379, train/total_loss/avg: 0.3113, max mem: 10794.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 493ms, time_since_start: 44m 04s 898ms, eta: 05h 14m 733ms
2022-04-21T15:21:26 | INFO | mmf.trainers.callbacks.logistics : progress: 2700/22000, train/hateful_memes/cross_entropy: 0.1432, train/hateful_memes/cross_entropy/avg: 0.3019, train/total_loss: 0.1432, train/total_loss/avg: 0.3019, max mem: 10794.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 083ms, time_since_start: 45m 39s 981ms, eta: 05h 11m 03s 009ms
2022-04-21T15:23:02 | INFO | mmf.trainers.callbacks.logistics : progress: 2800/22000, train/hateful_memes/cross_entropy: 0.1043, train/hateful_memes/cross_entropy/avg: 0.2921, train/total_loss: 0.1043, train/total_loss/avg: 0.2921, max mem: 10794.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 545ms, time_since_start: 47m 15s 526ms, eta: 05h 10m 56s 507ms
2022-04-21T15:24:37 | INFO | mmf.trainers.callbacks.logistics : progress: 2900/22000, train/hateful_memes/cross_entropy: 0.0838, train/hateful_memes/cross_entropy/avg: 0.2828, train/total_loss: 0.0838, train/total_loss/avg: 0.2828, max mem: 10794.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 643ms, time_since_start: 48m 51s 170ms, eta: 05h 09m 38s 519ms
2022-04-21T15:26:13 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T15:26:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T15:26:26 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T15:26:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T15:26:36 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, train/hateful_memes/cross_entropy: 0.0811, train/hateful_memes/cross_entropy/avg: 0.2739, train/total_loss: 0.0811, train/total_loss/avg: 0.2739, max mem: 10794.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00001, ups: 0.85, time: 01m 58s 280ms, time_since_start: 50m 49s 451ms, eta: 06h 20m 55s 389ms
2022-04-21T15:26:36 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T15:26:36 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T15:26:41 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T15:26:41 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T15:26:42 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T15:26:51 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-04-21T15:27:03 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T15:27:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T15:27:18 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, val/hateful_memes/cross_entropy: 1.2964, val/total_loss: 1.2964, val/hateful_memes/accuracy: 0.6981, val/hateful_memes/binary_f1: 0.4890, val/hateful_memes/roc_auc: 0.7039, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 41s 944ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.703941
2022-04-21T15:28:54 | INFO | mmf.trainers.callbacks.logistics : progress: 3100/22000, train/hateful_memes/cross_entropy: 0.0558, train/hateful_memes/cross_entropy/avg: 0.2654, train/total_loss: 0.0558, train/total_loss/avg: 0.2654, max mem: 10794.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 648ms, time_since_start: 53m 08s 046ms, eta: 05h 09m 37s 137ms
2022-04-21T15:30:29 | INFO | mmf.trainers.callbacks.logistics : progress: 3200/22000, train/hateful_memes/cross_entropy: 0.0449, train/hateful_memes/cross_entropy/avg: 0.2580, train/total_loss: 0.0449, train/total_loss/avg: 0.2580, max mem: 10794.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 091ms, time_since_start: 54m 43s 138ms, eta: 05h 03m 01s 146ms
2022-04-21T15:32:05 | INFO | mmf.trainers.callbacks.logistics : progress: 3300/22000, train/hateful_memes/cross_entropy: 0.0429, train/hateful_memes/cross_entropy/avg: 0.2505, train/total_loss: 0.0429, train/total_loss/avg: 0.2505, max mem: 10794.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 869ms, time_since_start: 56m 19s 007ms, eta: 05h 03m 52s 347ms
2022-04-21T15:33:41 | INFO | mmf.trainers.callbacks.logistics : progress: 3400/22000, train/hateful_memes/cross_entropy: 0.0356, train/hateful_memes/cross_entropy/avg: 0.2434, train/total_loss: 0.0356, train/total_loss/avg: 0.2434, max mem: 10794.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 871ms, time_since_start: 57m 54s 878ms, eta: 05h 02m 15s 180ms
2022-04-21T15:35:17 | INFO | mmf.trainers.callbacks.logistics : progress: 3500/22000, train/hateful_memes/cross_entropy: 0.0324, train/hateful_memes/cross_entropy/avg: 0.2366, train/total_loss: 0.0324, train/total_loss/avg: 0.2366, max mem: 10794.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 677ms, time_since_start: 59m 30s 556ms, eta: 05h 01s 333ms
2022-04-21T15:36:53 | INFO | mmf.trainers.callbacks.logistics : progress: 3600/22000, train/hateful_memes/cross_entropy: 0.0324, train/hateful_memes/cross_entropy/avg: 0.2312, train/total_loss: 0.0324, train/total_loss/avg: 0.2312, max mem: 10794.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 777ms, time_since_start: 01h 01m 06s 334ms, eta: 04h 58m 42s 664ms
2022-04-21T15:38:28 | INFO | mmf.trainers.callbacks.logistics : progress: 3700/22000, train/hateful_memes/cross_entropy: 0.0302, train/hateful_memes/cross_entropy/avg: 0.2255, train/total_loss: 0.0302, train/total_loss/avg: 0.2255, max mem: 10794.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 787ms, time_since_start: 01h 02m 42s 121ms, eta: 04h 57m 07s 034ms
2022-04-21T15:40:04 | INFO | mmf.trainers.callbacks.logistics : progress: 3800/22000, train/hateful_memes/cross_entropy: 0.0287, train/hateful_memes/cross_entropy/avg: 0.2197, train/total_loss: 0.0287, train/total_loss/avg: 0.2197, max mem: 10794.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 339ms, time_since_start: 01h 04m 17s 460ms, eta: 04h 54m 06s 731ms
2022-04-21T15:41:40 | INFO | mmf.trainers.callbacks.logistics : progress: 3900/22000, train/hateful_memes/cross_entropy: 0.0272, train/hateful_memes/cross_entropy/avg: 0.2141, train/total_loss: 0.0272, train/total_loss/avg: 0.2141, max mem: 10794.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 888ms, time_since_start: 01h 05m 53s 349ms, eta: 04h 54m 10s 877ms
2022-04-21T15:43:15 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T15:43:15 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T15:43:27 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T15:43:38 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T15:43:38 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, train/hateful_memes/cross_entropy: 0.0216, train/hateful_memes/cross_entropy/avg: 0.2089, train/total_loss: 0.0216, train/total_loss/avg: 0.2089, max mem: 10794.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00001, ups: 0.85, time: 01m 58s 575ms, time_since_start: 01h 07m 51s 924ms, eta: 06h 01m 46s 350ms
2022-04-21T15:43:38 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T15:43:38 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T15:43:44 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T15:43:44 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T15:43:44 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T15:43:56 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T15:44:10 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T15:44:10 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, val/hateful_memes/cross_entropy: 1.5579, val/total_loss: 1.5579, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.4828, val/hateful_memes/roc_auc: 0.6971, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 31s 451ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.703941
2022-04-21T15:45:46 | INFO | mmf.trainers.callbacks.logistics : progress: 4100/22000, train/hateful_memes/cross_entropy: 0.0195, train/hateful_memes/cross_entropy/avg: 0.2038, train/total_loss: 0.0195, train/total_loss/avg: 0.2038, max mem: 10794.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 708ms, time_since_start: 01h 10m 085ms, eta: 04h 53m 25s 113ms
2022-04-21T15:47:22 | INFO | mmf.trainers.callbacks.logistics : progress: 4200/22000, train/hateful_memes/cross_entropy: 0.0176, train/hateful_memes/cross_entropy/avg: 0.1990, train/total_loss: 0.0176, train/total_loss/avg: 0.1990, max mem: 10794.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 730ms, time_since_start: 01h 11m 35s 816ms, eta: 04h 48m 49s 664ms
2022-04-21T15:48:57 | INFO | mmf.trainers.callbacks.logistics : progress: 4300/22000, train/hateful_memes/cross_entropy: 0.0097, train/hateful_memes/cross_entropy/avg: 0.1945, train/total_loss: 0.0097, train/total_loss/avg: 0.1945, max mem: 10794.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 050ms, time_since_start: 01h 13m 10s 866ms, eta: 04h 45m 09s 913ms
2022-04-21T15:50:33 | INFO | mmf.trainers.callbacks.logistics : progress: 4400/22000, train/hateful_memes/cross_entropy: 0.0091, train/hateful_memes/cross_entropy/avg: 0.1901, train/total_loss: 0.0091, train/total_loss/avg: 0.1901, max mem: 10794.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 527ms, time_since_start: 01h 14m 46s 393ms, eta: 04h 44m 58s 624ms
2022-04-21T15:52:08 | INFO | mmf.trainers.callbacks.logistics : progress: 4500/22000, train/hateful_memes/cross_entropy: 0.0087, train/hateful_memes/cross_entropy/avg: 0.1859, train/total_loss: 0.0087, train/total_loss/avg: 0.1859, max mem: 10794.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 582ms, time_since_start: 01h 16m 21s 976ms, eta: 04h 43m 31s 334ms
2022-04-21T15:53:43 | INFO | mmf.trainers.callbacks.logistics : progress: 4600/22000, train/hateful_memes/cross_entropy: 0.0065, train/hateful_memes/cross_entropy/avg: 0.1820, train/total_loss: 0.0065, train/total_loss/avg: 0.1820, max mem: 10794.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 247ms, time_since_start: 01h 17m 57s 224ms, eta: 04h 40m 54s 884ms
2022-04-21T15:55:19 | INFO | mmf.trainers.callbacks.logistics : progress: 4700/22000, train/hateful_memes/cross_entropy: 0.0065, train/hateful_memes/cross_entropy/avg: 0.1785, train/total_loss: 0.0065, train/total_loss/avg: 0.1785, max mem: 10794.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 598ms, time_since_start: 01h 19m 32s 822ms, eta: 04h 40m 19s 643ms
2022-04-21T15:56:54 | INFO | mmf.trainers.callbacks.logistics : progress: 4800/22000, train/hateful_memes/cross_entropy: 0.0065, train/hateful_memes/cross_entropy/avg: 0.1754, train/total_loss: 0.0065, train/total_loss/avg: 0.1754, max mem: 10794.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 946ms, time_since_start: 01h 21m 07s 769ms, eta: 04h 36m 48s 491ms
2022-04-21T15:58:29 | INFO | mmf.trainers.callbacks.logistics : progress: 4900/22000, train/hateful_memes/cross_entropy: 0.0056, train/hateful_memes/cross_entropy/avg: 0.1720, train/total_loss: 0.0056, train/total_loss/avg: 0.1720, max mem: 10794.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 432ms, time_since_start: 01h 22m 43s 202ms, eta: 04h 36m 36s 367ms
2022-04-21T16:00:05 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T16:00:05 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T16:00:18 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T16:00:31 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T16:00:31 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1686, train/total_loss: 0.0047, train/total_loss/avg: 0.1686, max mem: 10794.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00001, ups: 0.83, time: 02m 01s 675ms, time_since_start: 01h 24m 44s 877ms, eta: 05h 50m 36s 502ms
2022-04-21T16:00:31 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T16:00:31 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T16:00:37 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T16:00:37 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T16:00:37 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T16:00:51 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T16:01:02 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T16:01:02 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, val/hateful_memes/cross_entropy: 1.7670, val/total_loss: 1.7670, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4724, val/hateful_memes/roc_auc: 0.6952, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 30s 414ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.703941
2022-04-21T16:02:38 | INFO | mmf.trainers.callbacks.logistics : progress: 5100/22000, train/hateful_memes/cross_entropy: 0.0047, train/hateful_memes/cross_entropy/avg: 0.1659, train/total_loss: 0.0047, train/total_loss/avg: 0.1659, max mem: 10794.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 456ms, time_since_start: 01h 26m 51s 750ms, eta: 04h 36m 18s 214ms
2022-04-21T16:04:14 | INFO | mmf.trainers.callbacks.logistics : progress: 5200/22000, train/hateful_memes/cross_entropy: 0.0044, train/hateful_memes/cross_entropy/avg: 0.1627, train/total_loss: 0.0044, train/total_loss/avg: 0.1627, max mem: 10794.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 044ms, time_since_start: 01h 28m 27s 795ms, eta: 04h 33m 29s 833ms
2022-04-21T16:05:50 | INFO | mmf.trainers.callbacks.logistics : progress: 5300/22000, train/hateful_memes/cross_entropy: 0.0044, train/hateful_memes/cross_entropy/avg: 0.1609, train/total_loss: 0.0044, train/total_loss/avg: 0.1609, max mem: 10794.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 925ms, time_since_start: 01h 30m 03s 720ms, eta: 04h 31m 31s 877ms
2022-04-21T16:07:25 | INFO | mmf.trainers.callbacks.logistics : progress: 5400/22000, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1580, train/total_loss: 0.0036, train/total_loss/avg: 0.1580, max mem: 10794.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 229ms, time_since_start: 01h 31m 38s 949ms, eta: 04h 27m 56s 782ms
2022-04-21T16:09:01 | INFO | mmf.trainers.callbacks.logistics : progress: 5500/22000, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1554, train/total_loss: 0.0036, train/total_loss/avg: 0.1554, max mem: 10794.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 823ms, time_since_start: 01h 33m 14s 773ms, eta: 04h 27m 59s 714ms
2022-04-21T16:10:36 | INFO | mmf.trainers.callbacks.logistics : progress: 5600/22000, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1527, train/total_loss: 0.0036, train/total_loss/avg: 0.1527, max mem: 10794.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 454ms, time_since_start: 01h 34m 50s 228ms, eta: 04h 25m 20s 702ms
2022-04-21T16:12:12 | INFO | mmf.trainers.callbacks.logistics : progress: 5700/22000, train/hateful_memes/cross_entropy: 0.0036, train/hateful_memes/cross_entropy/avg: 0.1504, train/total_loss: 0.0036, train/total_loss/avg: 0.1504, max mem: 10794.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 644ms, time_since_start: 01h 36m 25s 873ms, eta: 04h 24m 15s 127ms
2022-04-21T16:13:48 | INFO | mmf.trainers.callbacks.logistics : progress: 5800/22000, train/hateful_memes/cross_entropy: 0.0035, train/hateful_memes/cross_entropy/avg: 0.1478, train/total_loss: 0.0035, train/total_loss/avg: 0.1478, max mem: 10794.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 648ms, time_since_start: 01h 38m 01s 522ms, eta: 04h 22m 38s 551ms
2022-04-21T16:15:23 | INFO | mmf.trainers.callbacks.logistics : progress: 5900/22000, train/hateful_memes/cross_entropy: 0.0032, train/hateful_memes/cross_entropy/avg: 0.1453, train/total_loss: 0.0032, train/total_loss/avg: 0.1453, max mem: 10794.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 074ms, time_since_start: 01h 39m 36s 596ms, eta: 04h 19m 27s 149ms
2022-04-21T16:16:58 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T16:16:58 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T16:17:11 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T16:17:21 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T16:17:21 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.1429, train/total_loss: 0.0031, train/total_loss/avg: 0.1429, max mem: 10794.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00001, ups: 0.85, time: 01m 58s 530ms, time_since_start: 01h 41m 35s 127ms, eta: 05h 21m 27s 351ms
2022-04-21T16:17:21 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T16:17:21 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T16:17:27 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T16:17:27 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T16:17:27 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T16:17:37 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T16:17:49 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T16:17:49 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, val/hateful_memes/cross_entropy: 1.9175, val/total_loss: 1.9175, val/hateful_memes/accuracy: 0.6759, val/hateful_memes/binary_f1: 0.4582, val/hateful_memes/roc_auc: 0.6988, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 28s 012ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.703941
2022-04-21T16:19:26 | INFO | mmf.trainers.callbacks.logistics : progress: 6100/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.1406, train/total_loss: 0.0031, train/total_loss/avg: 0.1406, max mem: 10794.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 415ms, time_since_start: 01h 43m 39s 556ms, eta: 04h 19m 50s 732ms
2022-04-21T16:21:01 | INFO | mmf.trainers.callbacks.logistics : progress: 6200/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.1384, train/total_loss: 0.0031, train/total_loss/avg: 0.1384, max mem: 10794.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 317ms, time_since_start: 01h 45m 14s 874ms, eta: 04h 15m 16s 243ms
2022-04-21T16:22:37 | INFO | mmf.trainers.callbacks.logistics : progress: 6300/22000, train/hateful_memes/cross_entropy: 0.0030, train/hateful_memes/cross_entropy/avg: 0.1362, train/total_loss: 0.0030, train/total_loss/avg: 0.1362, max mem: 10794.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 493ms, time_since_start: 01h 46m 50s 368ms, eta: 04h 14m 07s 334ms
2022-04-21T16:24:11 | INFO | mmf.trainers.callbacks.logistics : progress: 6400/22000, train/hateful_memes/cross_entropy: 0.0030, train/hateful_memes/cross_entropy/avg: 0.1341, train/total_loss: 0.0030, train/total_loss/avg: 0.1341, max mem: 10794.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 806ms, time_since_start: 01h 48m 25s 174ms, eta: 04h 10m 41s 264ms
2022-04-21T16:25:47 | INFO | mmf.trainers.callbacks.logistics : progress: 6500/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.1321, train/total_loss: 0.0031, train/total_loss/avg: 0.1321, max mem: 10794.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 290ms, time_since_start: 01h 50m 465ms, eta: 04h 10m 21s 122ms
2022-04-21T16:27:22 | INFO | mmf.trainers.callbacks.logistics : progress: 6600/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.1301, train/total_loss: 0.0031, train/total_loss/avg: 0.1301, max mem: 10794.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 314ms, time_since_start: 01h 51m 35s 779ms, eta: 04h 08m 47s 935ms
2022-04-21T16:28:57 | INFO | mmf.trainers.callbacks.logistics : progress: 6700/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.1283, train/total_loss: 0.0031, train/total_loss/avg: 0.1283, max mem: 10794.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 025ms, time_since_start: 01h 53m 10s 804ms, eta: 04h 06m 26s 029ms
2022-04-21T16:30:32 | INFO | mmf.trainers.callbacks.logistics : progress: 6800/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.1264, train/total_loss: 0.0025, train/total_loss/avg: 0.1264, max mem: 10794.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 429ms, time_since_start: 01h 54m 46s 234ms, eta: 04h 05m 51s 931ms
2022-04-21T16:32:08 | INFO | mmf.trainers.callbacks.logistics : progress: 6900/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.1247, train/total_loss: 0.0025, train/total_loss/avg: 0.1247, max mem: 10794.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 316ms, time_since_start: 01h 56m 21s 550ms, eta: 04h 03m 57s 417ms
2022-04-21T16:33:43 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T16:33:43 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T16:33:56 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T16:34:09 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T16:34:10 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.1229, train/total_loss: 0.0025, train/total_loss/avg: 0.1229, max mem: 10794.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00001, ups: 0.83, time: 02m 01s 865ms, time_since_start: 01h 58m 23s 416ms, eta: 05h 09m 50s 652ms
2022-04-21T16:34:10 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T16:34:10 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T16:34:15 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T16:34:15 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T16:34:15 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T16:34:28 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-04-21T16:34:44 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T16:35:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T16:35:00 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, val/hateful_memes/cross_entropy: 2.1071, val/total_loss: 2.1071, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.4873, val/hateful_memes/roc_auc: 0.7070, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 50s 101ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.707044
2022-04-21T16:36:36 | INFO | mmf.trainers.callbacks.logistics : progress: 7100/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.1212, train/total_loss: 0.0022, train/total_loss/avg: 0.1212, max mem: 10794.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 764ms, time_since_start: 02h 50s 284ms, eta: 04h 04m 23s 007ms
2022-04-21T16:38:12 | INFO | mmf.trainers.callbacks.logistics : progress: 7200/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.1196, train/total_loss: 0.0022, train/total_loss/avg: 0.1196, max mem: 10794.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 453ms, time_since_start: 02h 02m 25s 738ms, eta: 03h 59m 27s 275ms
2022-04-21T16:39:48 | INFO | mmf.trainers.callbacks.logistics : progress: 7300/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.1180, train/total_loss: 0.0022, train/total_loss/avg: 0.1180, max mem: 10794.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 557ms, time_since_start: 02h 04m 01s 295ms, eta: 03h 58m 05s 685ms
2022-04-21T16:41:23 | INFO | mmf.trainers.callbacks.logistics : progress: 7400/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1164, train/total_loss: 0.0020, train/total_loss/avg: 0.1164, max mem: 10794.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 589ms, time_since_start: 02h 05m 36s 885ms, eta: 03h 56m 33s 397ms
2022-04-21T16:42:58 | INFO | mmf.trainers.callbacks.logistics : progress: 7500/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1149, train/total_loss: 0.0017, train/total_loss/avg: 0.1149, max mem: 10794.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 007ms, time_since_start: 02h 07m 11s 892ms, eta: 03h 53m 30s 266ms
2022-04-21T16:44:34 | INFO | mmf.trainers.callbacks.logistics : progress: 7600/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1134, train/total_loss: 0.0017, train/total_loss/avg: 0.1134, max mem: 10794.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 612ms, time_since_start: 02h 08m 47s 505ms, eta: 03h 53m 22s 274ms
2022-04-21T16:46:09 | INFO | mmf.trainers.callbacks.logistics : progress: 7700/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1121, train/total_loss: 0.0017, train/total_loss/avg: 0.1121, max mem: 10794.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 594ms, time_since_start: 02h 10m 23s 099ms, eta: 03h 51m 42s 367ms
2022-04-21T16:47:44 | INFO | mmf.trainers.callbacks.logistics : progress: 7800/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1107, train/total_loss: 0.0017, train/total_loss/avg: 0.1107, max mem: 10794.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 087ms, time_since_start: 02h 11m 58s 186ms, eta: 03h 48m 51s 902ms
2022-04-21T16:49:20 | INFO | mmf.trainers.callbacks.logistics : progress: 7900/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1099, train/total_loss: 0.0020, train/total_loss/avg: 0.1099, max mem: 10794.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 350ms, time_since_start: 02h 13m 33s 537ms, eta: 03h 47m 53s 027ms
2022-04-21T16:50:55 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T16:50:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T16:51:06 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T16:51:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T16:51:18 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1086, train/total_loss: 0.0020, train/total_loss/avg: 0.1086, max mem: 10794.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00001, ups: 0.85, time: 01m 57s 843ms, time_since_start: 02h 15m 31s 381ms, eta: 04h 39m 38s 608ms
2022-04-21T16:51:18 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T16:51:18 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T16:51:23 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T16:51:23 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T16:51:23 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T16:51:35 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T16:51:50 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T16:51:50 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, val/hateful_memes/cross_entropy: 2.2494, val/total_loss: 2.2494, val/hateful_memes/accuracy: 0.6796, val/hateful_memes/binary_f1: 0.4136, val/hateful_memes/roc_auc: 0.6893, num_updates: 8000, epoch: 31, iterations: 8000, max_updates: 22000, val_time: 32s 220ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.707044
2022-04-21T16:53:26 | INFO | mmf.trainers.callbacks.logistics : progress: 8100/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.1073, train/total_loss: 0.0022, train/total_loss/avg: 0.1073, max mem: 10794.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 381ms, time_since_start: 02h 17m 39s 985ms, eta: 03h 47m 04s 752ms
2022-04-21T16:55:02 | INFO | mmf.trainers.callbacks.logistics : progress: 8200/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1060, train/total_loss: 0.0020, train/total_loss/avg: 0.1060, max mem: 10794.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 498ms, time_since_start: 02h 19m 15s 483ms, eta: 03h 43m 22s 813ms
2022-04-21T16:56:37 | INFO | mmf.trainers.callbacks.logistics : progress: 8300/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.1049, train/total_loss: 0.0025, train/total_loss/avg: 0.1049, max mem: 10794.0, experiment: run, epoch: 32, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 185ms, time_since_start: 02h 20m 50s 669ms, eta: 03h 41m 02s 131ms
2022-04-21T16:58:12 | INFO | mmf.trainers.callbacks.logistics : progress: 8400/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.1036, train/total_loss: 0.0025, train/total_loss/avg: 0.1036, max mem: 10794.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 517ms, time_since_start: 02h 22m 26s 186ms, eta: 03h 40m 11s 194ms
2022-04-21T16:59:48 | INFO | mmf.trainers.callbacks.logistics : progress: 8500/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1024, train/total_loss: 0.0020, train/total_loss/avg: 0.1024, max mem: 10794.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 477ms, time_since_start: 02h 24m 01s 663ms, eta: 03h 38m 28s 566ms
2022-04-21T17:01:23 | INFO | mmf.trainers.callbacks.logistics : progress: 8600/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.1017, train/total_loss: 0.0020, train/total_loss/avg: 0.1017, max mem: 10794.0, experiment: run, epoch: 33, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 832ms, time_since_start: 02h 25m 36s 496ms, eta: 03h 35m 23s 613ms
2022-04-21T17:02:58 | INFO | mmf.trainers.callbacks.logistics : progress: 8700/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.1006, train/total_loss: 0.0017, train/total_loss/avg: 0.1006, max mem: 10794.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 309ms, time_since_start: 02h 27m 11s 805ms, eta: 03h 34m 51s 639ms
2022-04-21T17:04:33 | INFO | mmf.trainers.callbacks.logistics : progress: 8800/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.0994, train/total_loss: 0.0014, train/total_loss/avg: 0.0994, max mem: 10794.0, experiment: run, epoch: 34, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 936ms, time_since_start: 02h 28m 46s 742ms, eta: 03h 32m 24s 673ms
2022-04-21T17:06:08 | INFO | mmf.trainers.callbacks.logistics : progress: 8900/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0983, train/total_loss: 0.0010, train/total_loss/avg: 0.0983, max mem: 10794.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 282ms, time_since_start: 02h 30m 22s 024ms, eta: 03h 31m 34s 152ms
2022-04-21T17:07:43 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T17:07:43 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T17:07:57 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T17:08:09 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T17:08:09 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0973, train/total_loss: 0.0010, train/total_loss/avg: 0.0973, max mem: 10794.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00001, ups: 0.83, time: 02m 01s 186ms, time_since_start: 02h 32m 23s 210ms, eta: 04h 27m 02s 016ms
2022-04-21T17:08:09 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T17:08:09 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T17:08:15 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T17:08:15 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T17:08:16 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T17:08:25 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T17:08:40 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T17:08:40 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, val/hateful_memes/cross_entropy: 2.1649, val/total_loss: 2.1649, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4377, val/hateful_memes/roc_auc: 0.6928, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 22000, val_time: 30s 286ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.707044
2022-04-21T17:10:16 | INFO | mmf.trainers.callbacks.logistics : progress: 9100/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.0963, train/total_loss: 0.0014, train/total_loss/avg: 0.0963, max mem: 10794.0, experiment: run, epoch: 35, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 092ms, time_since_start: 02h 34m 29s 591ms, eta: 03h 30m 06s 620ms
2022-04-21T17:11:51 | INFO | mmf.trainers.callbacks.logistics : progress: 9200/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0953, train/total_loss: 0.0010, train/total_loss/avg: 0.0953, max mem: 10794.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 553ms, time_since_start: 02h 36m 05s 144ms, eta: 03h 27m 18s 731ms
2022-04-21T17:13:27 | INFO | mmf.trainers.callbacks.logistics : progress: 9300/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0943, train/total_loss: 0.0010, train/total_loss/avg: 0.0943, max mem: 10794.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 597ms, time_since_start: 02h 37m 40s 742ms, eta: 03h 25m 47s 330ms
2022-04-21T17:15:02 | INFO | mmf.trainers.callbacks.logistics : progress: 9400/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0933, train/total_loss: 0.0009, train/total_loss/avg: 0.0933, max mem: 10794.0, experiment: run, epoch: 36, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 322ms, time_since_start: 02h 39m 16s 064ms, eta: 03h 23m 34s 803ms
2022-04-21T17:16:38 | INFO | mmf.trainers.callbacks.logistics : progress: 9500/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0923, train/total_loss: 0.0009, train/total_loss/avg: 0.0923, max mem: 10794.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 526ms, time_since_start: 02h 40m 51s 591ms, eta: 03h 22m 23s 866ms
2022-04-21T17:18:13 | INFO | mmf.trainers.callbacks.logistics : progress: 9600/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0916, train/total_loss: 0.0009, train/total_loss/avg: 0.0916, max mem: 10794.0, experiment: run, epoch: 37, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 975ms, time_since_start: 02h 42m 26s 567ms, eta: 03h 19m 37s 205ms
2022-04-21T17:19:48 | INFO | mmf.trainers.callbacks.logistics : progress: 9700/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0907, train/total_loss: 0.0009, train/total_loss/avg: 0.0907, max mem: 10794.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 408ms, time_since_start: 02h 44m 01s 976ms, eta: 03h 18m 54s 756ms
2022-04-21T17:21:24 | INFO | mmf.trainers.callbacks.logistics : progress: 9800/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0900, train/total_loss: 0.0010, train/total_loss/avg: 0.0900, max mem: 10794.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 436ms, time_since_start: 02h 45m 37s 412ms, eta: 03h 17m 21s 161ms
2022-04-21T17:22:59 | INFO | mmf.trainers.callbacks.logistics : progress: 9900/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0891, train/total_loss: 0.0009, train/total_loss/avg: 0.0891, max mem: 10794.0, experiment: run, epoch: 38, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 252ms, time_since_start: 02h 47m 12s 664ms, eta: 03h 15m 21s 463ms
2022-04-21T17:24:34 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T17:24:34 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T17:24:48 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T17:25:01 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T17:25:01 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0882, train/total_loss: 0.0009, train/total_loss/avg: 0.0882, max mem: 10794.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00001, ups: 0.82, time: 02m 02s 311ms, time_since_start: 02h 49m 14s 976ms, eta: 04h 08m 46s 900ms
2022-04-21T17:25:01 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T17:25:01 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T17:25:07 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T17:25:07 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T17:25:07 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T17:25:21 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T17:25:31 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T17:25:31 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, val/hateful_memes/cross_entropy: 2.3594, val/total_loss: 2.3594, val/hateful_memes/accuracy: 0.7019, val/hateful_memes/binary_f1: 0.4615, val/hateful_memes/roc_auc: 0.6864, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 22000, val_time: 30s 205ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.707044
2022-04-21T17:27:08 | INFO | mmf.trainers.callbacks.logistics : progress: 10100/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0873, train/total_loss: 0.0009, train/total_loss/avg: 0.0873, max mem: 10794.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 516ms, time_since_start: 02h 51m 21s 700ms, eta: 03h 14m 40s 738ms
2022-04-21T17:28:43 | INFO | mmf.trainers.callbacks.logistics : progress: 10200/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0865, train/total_loss: 0.0009, train/total_loss/avg: 0.0865, max mem: 10794.0, experiment: run, epoch: 39, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 930ms, time_since_start: 02h 52m 56s 631ms, eta: 03h 09m 52s 284ms
2022-04-21T17:30:18 | INFO | mmf.trainers.callbacks.logistics : progress: 10300/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0857, train/total_loss: 0.0009, train/total_loss/avg: 0.0857, max mem: 10794.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 358ms, time_since_start: 02h 54m 31s 990ms, eta: 03h 09m 06s 669ms
2022-04-21T17:31:53 | INFO | mmf.trainers.callbacks.logistics : progress: 10400/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0857, train/total_loss: 0.0009, train/total_loss/avg: 0.0857, max mem: 10794.0, experiment: run, epoch: 40, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 166ms, time_since_start: 02h 56m 07s 156ms, eta: 03h 07m 06s 946ms
2022-04-21T17:33:29 | INFO | mmf.trainers.callbacks.logistics : progress: 10500/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0849, train/total_loss: 0.0010, train/total_loss/avg: 0.0849, max mem: 10794.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 402ms, time_since_start: 02h 57m 42s 558ms, eta: 03h 05m 57s 774ms
2022-04-21T17:35:04 | INFO | mmf.trainers.callbacks.logistics : progress: 10600/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0841, train/total_loss: 0.0009, train/total_loss/avg: 0.0841, max mem: 10794.0, experiment: run, epoch: 40, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 382ms, time_since_start: 02h 59m 17s 941ms, eta: 03h 04m 18s 483ms
2022-04-21T17:36:39 | INFO | mmf.trainers.callbacks.logistics : progress: 10700/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0833, train/total_loss: 0.0006, train/total_loss/avg: 0.0833, max mem: 10794.0, experiment: run, epoch: 41, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 871ms, time_since_start: 03h 52s 812ms, eta: 03h 01m 42s 711ms
2022-04-21T17:38:14 | INFO | mmf.trainers.callbacks.logistics : progress: 10800/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0826, train/total_loss: 0.0006, train/total_loss/avg: 0.0826, max mem: 10794.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 391ms, time_since_start: 03h 02m 28s 204ms, eta: 03h 01m 05s 456ms
2022-04-21T17:39:50 | INFO | mmf.trainers.callbacks.logistics : progress: 10900/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0819, train/total_loss: 0.0009, train/total_loss/avg: 0.0819, max mem: 10794.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 431ms, time_since_start: 03h 04m 03s 636ms, eta: 02h 59m 33s 029ms
2022-04-21T17:41:25 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T17:41:25 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T17:41:36 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T17:41:49 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T17:41:49 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0811, train/total_loss: 0.0006, train/total_loss/avg: 0.0811, max mem: 10794.0, experiment: run, epoch: 42, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00001, ups: 0.85, time: 01m 58s 880ms, time_since_start: 03h 06m 02s 516ms, eta: 03h 41m 39s 150ms
2022-04-21T17:41:49 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T17:41:49 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T17:41:54 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T17:41:54 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T17:41:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T17:42:08 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T17:42:20 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T17:42:20 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, val/hateful_memes/cross_entropy: 2.3472, val/total_loss: 2.3472, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4281, val/hateful_memes/roc_auc: 0.6947, num_updates: 11000, epoch: 42, iterations: 11000, max_updates: 22000, val_time: 30s 982ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.707044
2022-04-21T17:43:56 | INFO | mmf.trainers.callbacks.logistics : progress: 11100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0805, train/total_loss: 0.0006, train/total_loss/avg: 0.0805, max mem: 10794.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00001, ups: 1.04, time: 01m 36s 383ms, time_since_start: 03h 08m 09s 884ms, eta: 02h 58m 04s 456ms
2022-04-21T17:45:31 | INFO | mmf.trainers.callbacks.logistics : progress: 11200/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0798, train/total_loss: 0.0004, train/total_loss/avg: 0.0798, max mem: 10794.0, experiment: run, epoch: 43, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 941ms, time_since_start: 03h 09m 44s 826ms, eta: 02h 53m 48s 004ms
2022-04-21T17:47:06 | INFO | mmf.trainers.callbacks.logistics : progress: 11300/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0791, train/total_loss: 0.0004, train/total_loss/avg: 0.0791, max mem: 10794.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 337ms, time_since_start: 03h 11m 20s 164ms, eta: 02h 52m 54s 545ms
2022-04-21T17:48:42 | INFO | mmf.trainers.callbacks.logistics : progress: 11400/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0784, train/total_loss: 0.0004, train/total_loss/avg: 0.0784, max mem: 10794.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 271ms, time_since_start: 03h 12m 55s 435ms, eta: 02h 51m 10s 418ms
2022-04-21T17:50:17 | INFO | mmf.trainers.callbacks.logistics : progress: 11500/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0781, train/total_loss: 0.0009, train/total_loss/avg: 0.0781, max mem: 10794.0, experiment: run, epoch: 44, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 979ms, time_since_start: 03h 14m 30s 414ms, eta: 02h 49m 02s 380ms
2022-04-21T17:51:52 | INFO | mmf.trainers.callbacks.logistics : progress: 11600/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0774, train/total_loss: 0.0005, train/total_loss/avg: 0.0774, max mem: 10794.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 204ms, time_since_start: 03h 16m 05s 619ms, eta: 02h 47m 49s 626ms
2022-04-21T17:53:27 | INFO | mmf.trainers.callbacks.logistics : progress: 11700/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0768, train/total_loss: 0.0004, train/total_loss/avg: 0.0768, max mem: 10794.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 077ms, time_since_start: 03h 17m 40s 697ms, eta: 02h 45m 59s 486ms
2022-04-21T17:55:02 | INFO | mmf.trainers.callbacks.logistics : progress: 11800/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0761, train/total_loss: 0.0004, train/total_loss/avg: 0.0761, max mem: 10794.0, experiment: run, epoch: 45, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00001, ups: 1.06, time: 01m 34s 703ms, time_since_start: 03h 19m 15s 400ms, eta: 02h 43m 43s 930ms
2022-04-21T17:56:37 | INFO | mmf.trainers.callbacks.logistics : progress: 11900/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0755, train/total_loss: 0.0004, train/total_loss/avg: 0.0755, max mem: 10794.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00001, ups: 1.05, time: 01m 35s 147ms, time_since_start: 03h 20m 50s 547ms, eta: 02h 42m 53s 264ms
2022-04-21T17:58:12 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T17:58:12 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T17:58:27 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T17:58:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T17:58:36 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0749, train/total_loss: 0.0004, train/total_loss/avg: 0.0749, max mem: 10794.0, experiment: run, epoch: 46, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00001, ups: 0.84, time: 01m 59s 616ms, time_since_start: 03h 22m 50s 164ms, eta: 03h 22m 45s 050ms
2022-04-21T17:58:36 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T17:58:36 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T17:58:42 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T17:58:42 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T17:58:42 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, val/hateful_memes/cross_entropy: 2.5599, val/total_loss: 2.5599, val/hateful_memes/accuracy: 0.6926, val/hateful_memes/binary_f1: 0.4392, val/hateful_memes/roc_auc: 0.6960, num_updates: 12000, epoch: 46, iterations: 12000, max_updates: 22000, val_time: 05s 784ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.707044
2022-04-21T18:00:19 | INFO | mmf.trainers.callbacks.logistics : progress: 12100/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0742, train/total_loss: 0.0004, train/total_loss/avg: 0.0742, max mem: 10794.0, experiment: run, epoch: 46, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 408ms, time_since_start: 03h 24m 32s 359ms, eta: 02h 41m 46s 711ms
2022-04-21T18:01:54 | INFO | mmf.trainers.callbacks.logistics : progress: 12200/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0736, train/total_loss: 0.0004, train/total_loss/avg: 0.0736, max mem: 10794.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 494ms, time_since_start: 03h 26m 07s 855ms, eta: 02h 38m 37s 606ms
2022-04-21T18:03:29 | INFO | mmf.trainers.callbacks.logistics : progress: 12300/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0731, train/total_loss: 0.0004, train/total_loss/avg: 0.0731, max mem: 10794.0, experiment: run, epoch: 47, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 995ms, time_since_start: 03h 27m 42s 850ms, eta: 02h 36m 11s 221ms
2022-04-21T18:05:05 | INFO | mmf.trainers.callbacks.logistics : progress: 12400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0725, train/total_loss: 0.0002, train/total_loss/avg: 0.0725, max mem: 10794.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 555ms, time_since_start: 03h 29m 18s 405ms, eta: 02h 35m 29s 242ms
2022-04-21T18:06:40 | INFO | mmf.trainers.callbacks.logistics : progress: 12500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0719, train/total_loss: 0.0002, train/total_loss/avg: 0.0719, max mem: 10794.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 495ms, time_since_start: 03h 30m 53s 901ms, eta: 02h 33m 46s 291ms
2022-04-21T18:08:16 | INFO | mmf.trainers.callbacks.logistics : progress: 12600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0713, train/total_loss: 0.0003, train/total_loss/avg: 0.0713, max mem: 10794.0, experiment: run, epoch: 48, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 437ms, time_since_start: 03h 32m 29s 338ms, eta: 02h 32m 03s 619ms
2022-04-21T18:09:51 | INFO | mmf.trainers.callbacks.logistics : progress: 12700/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0708, train/total_loss: 0.0003, train/total_loss/avg: 0.0708, max mem: 10794.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 675ms, time_since_start: 03h 34m 05s 014ms, eta: 02h 30m 49s 073ms
2022-04-21T18:11:27 | INFO | mmf.trainers.callbacks.logistics : progress: 12800/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0702, train/total_loss: 0.0003, train/total_loss/avg: 0.0702, max mem: 10794.0, experiment: run, epoch: 49, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 334ms, time_since_start: 03h 35m 40s 348ms, eta: 02h 28m 39s 847ms
2022-04-21T18:13:02 | INFO | mmf.trainers.callbacks.logistics : progress: 12900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0698, train/total_loss: 0.0003, train/total_loss/avg: 0.0698, max mem: 10794.0, experiment: run, epoch: 49, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 694ms, time_since_start: 03h 37m 16s 042ms, eta: 02h 27m 36s 225ms
2022-04-21T18:14:38 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T18:14:38 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T18:14:47 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T18:15:02 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T18:15:02 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0692, train/total_loss: 0.0003, train/total_loss/avg: 0.0692, max mem: 10794.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0., ups: 0.84, time: 01m 59s 937ms, time_since_start: 03h 39m 15s 979ms, eta: 03h 02m 57s 856ms
2022-04-21T18:15:02 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T18:15:02 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T18:15:08 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T18:15:08 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T18:15:08 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, val/hateful_memes/cross_entropy: 2.2074, val/total_loss: 2.2074, val/hateful_memes/accuracy: 0.6981, val/hateful_memes/binary_f1: 0.4985, val/hateful_memes/roc_auc: 0.7029, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 22000, val_time: 05s 667ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.707044
2022-04-21T18:16:44 | INFO | mmf.trainers.callbacks.logistics : progress: 13100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0687, train/total_loss: 0.0002, train/total_loss/avg: 0.0687, max mem: 10794.0, experiment: run, epoch: 50, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 368ms, time_since_start: 03h 40m 58s 017ms, eta: 02h 25m 22s 641ms
2022-04-21T18:18:20 | INFO | mmf.trainers.callbacks.logistics : progress: 13200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0682, train/total_loss: 0.0002, train/total_loss/avg: 0.0682, max mem: 10794.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 933ms, time_since_start: 03h 42m 33s 951ms, eta: 02h 23m 05s 682ms
2022-04-21T18:19:56 | INFO | mmf.trainers.callbacks.logistics : progress: 13300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0679, train/total_loss: 0.0002, train/total_loss/avg: 0.0679, max mem: 10794.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 379ms, time_since_start: 03h 44m 09s 330ms, eta: 02h 20m 39s 044ms
2022-04-21T18:21:31 | INFO | mmf.trainers.callbacks.logistics : progress: 13400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0674, train/total_loss: 0.0002, train/total_loss/avg: 0.0674, max mem: 10794.0, experiment: run, epoch: 51, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 811ms, time_since_start: 03h 45m 45s 142ms, eta: 02h 19m 39s 909ms
2022-04-21T18:23:07 | INFO | mmf.trainers.callbacks.logistics : progress: 13500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0669, train/total_loss: 0.0001, train/total_loss/avg: 0.0669, max mem: 10794.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 840ms, time_since_start: 03h 47m 20s 983ms, eta: 02h 18m 04s 930ms
2022-04-21T18:24:43 | INFO | mmf.trainers.callbacks.logistics : progress: 13600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0664, train/total_loss: 0.0001, train/total_loss/avg: 0.0664, max mem: 10794.0, experiment: run, epoch: 52, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 447ms, time_since_start: 03h 48m 56s 431ms, eta: 02h 15m 53s 921ms
2022-04-21T18:26:18 | INFO | mmf.trainers.callbacks.logistics : progress: 13700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0659, train/total_loss: 0.0001, train/total_loss/avg: 0.0659, max mem: 10794.0, experiment: run, epoch: 52, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 807ms, time_since_start: 03h 50m 32s 238ms, eta: 02h 14m 47s 203ms
2022-04-21T18:27:54 | INFO | mmf.trainers.callbacks.logistics : progress: 13800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0654, train/total_loss: 0.0001, train/total_loss/avg: 0.0654, max mem: 10794.0, experiment: run, epoch: 52, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 802ms, time_since_start: 03h 52m 08s 041ms, eta: 02h 13m 09s 361ms
2022-04-21T18:29:30 | INFO | mmf.trainers.callbacks.logistics : progress: 13900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0649, train/total_loss: 0.0001, train/total_loss/avg: 0.0649, max mem: 10794.0, experiment: run, epoch: 53, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 347ms, time_since_start: 03h 53m 43s 389ms, eta: 02h 10m 54s 478ms
2022-04-21T18:31:05 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T18:31:05 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T18:31:17 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T18:31:30 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T18:31:30 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0645, train/total_loss: 0.0001, train/total_loss/avg: 0.0645, max mem: 10794.0, experiment: run, epoch: 53, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0., ups: 0.83, time: 02m 565ms, time_since_start: 03h 55m 43s 954ms, eta: 02h 43m 29s 207ms
2022-04-21T18:31:30 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T18:31:30 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T18:31:36 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T18:31:36 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T18:31:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T18:31:48 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-04-21T18:32:26 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T18:32:40 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T18:32:40 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, val/hateful_memes/cross_entropy: 2.2292, val/total_loss: 2.2292, val/hateful_memes/accuracy: 0.7019, val/hateful_memes/binary_f1: 0.5165, val/hateful_memes/roc_auc: 0.7135, num_updates: 14000, epoch: 53, iterations: 14000, max_updates: 22000, val_time: 01m 10s 123ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.713515
2022-04-21T18:34:17 | INFO | mmf.trainers.callbacks.logistics : progress: 14100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0640, train/total_loss: 0.0001, train/total_loss/avg: 0.0640, max mem: 10794.0, experiment: run, epoch: 54, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 551ms, time_since_start: 03h 58m 30s 631ms, eta: 02h 09m 17s 238ms
2022-04-21T18:35:52 | INFO | mmf.trainers.callbacks.logistics : progress: 14200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0636, train/total_loss: 0.0001, train/total_loss/avg: 0.0636, max mem: 10794.0, experiment: run, epoch: 54, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 603ms, time_since_start: 04h 06s 235ms, eta: 02h 06m 23s 881ms
2022-04-21T18:37:28 | INFO | mmf.trainers.callbacks.logistics : progress: 14300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0631, train/total_loss: 0.0001, train/total_loss/avg: 0.0631, max mem: 10794.0, experiment: run, epoch: 54, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 677ms, time_since_start: 04h 01m 41s 912ms, eta: 02h 04m 52s 379ms
2022-04-21T18:39:03 | INFO | mmf.trainers.callbacks.logistics : progress: 14400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0627, train/total_loss: 0.0001, train/total_loss/avg: 0.0627, max mem: 10794.0, experiment: run, epoch: 55, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 054ms, time_since_start: 04h 03m 16s 967ms, eta: 02h 02m 26s 934ms
2022-04-21T18:40:39 | INFO | mmf.trainers.callbacks.logistics : progress: 14500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0622, train/total_loss: 0.0001, train/total_loss/avg: 0.0622, max mem: 10794.0, experiment: run, epoch: 55, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 682ms, time_since_start: 04h 04m 52s 650ms, eta: 02h 01m 38s 218ms
2022-04-21T18:42:14 | INFO | mmf.trainers.callbacks.logistics : progress: 14600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0618, train/total_loss: 0.0001, train/total_loss/avg: 0.0618, max mem: 10794.0, experiment: run, epoch: 55, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 600ms, time_since_start: 04h 06m 28s 250ms, eta: 01h 59m 54s 703ms
2022-04-21T18:43:50 | INFO | mmf.trainers.callbacks.logistics : progress: 14700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0614, train/total_loss: 0.0001, train/total_loss/avg: 0.0614, max mem: 10794.0, experiment: run, epoch: 56, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 233ms, time_since_start: 04h 08m 03s 483ms, eta: 01h 57m 50s 210ms
2022-04-21T18:45:25 | INFO | mmf.trainers.callbacks.logistics : progress: 14800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0610, train/total_loss: 0.0001, train/total_loss/avg: 0.0610, max mem: 10794.0, experiment: run, epoch: 56, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 642ms, time_since_start: 04h 09m 39s 126ms, eta: 01h 56m 43s 319ms
2022-04-21T18:47:01 | INFO | mmf.trainers.callbacks.logistics : progress: 14900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0606, train/total_loss: 0.0001, train/total_loss/avg: 0.0606, max mem: 10794.0, experiment: run, epoch: 57, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 190ms, time_since_start: 04h 11m 14s 316ms, eta: 01h 54m 33s 419ms
2022-04-21T18:48:36 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T18:48:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T18:48:45 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T18:48:59 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T18:48:59 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0602, train/total_loss: 0.0001, train/total_loss/avg: 0.0602, max mem: 10794.0, experiment: run, epoch: 57, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0., ups: 0.85, time: 01m 58s 311ms, time_since_start: 04h 13m 12s 628ms, eta: 02h 20m 22s 596ms
2022-04-21T18:48:59 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T18:48:59 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T18:49:05 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T18:49:05 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T18:49:05 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T18:49:17 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T18:49:28 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T18:49:28 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/22000, val/hateful_memes/cross_entropy: 2.4510, val/total_loss: 2.4510, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.4815, val/hateful_memes/roc_auc: 0.7038, num_updates: 15000, epoch: 57, iterations: 15000, max_updates: 22000, val_time: 28s 853ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.713515
2022-04-21T18:51:04 | INFO | mmf.trainers.callbacks.logistics : progress: 15100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0598, train/total_loss: 0.0001, train/total_loss/avg: 0.0598, max mem: 10794.0, experiment: run, epoch: 57, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 714ms, time_since_start: 04h 15m 18s 197ms, eta: 01h 53m 06s 715ms
2022-04-21T18:52:40 | INFO | mmf.trainers.callbacks.logistics : progress: 15200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0594, train/total_loss: 0.0001, train/total_loss/avg: 0.0594, max mem: 10794.0, experiment: run, epoch: 58, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 529ms, time_since_start: 04h 16m 53s 726ms, eta: 01h 50m 06s 426ms
2022-04-21T18:54:16 | INFO | mmf.trainers.callbacks.logistics : progress: 15300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0590, train/total_loss: 0.0001, train/total_loss/avg: 0.0590, max mem: 10794.0, experiment: run, epoch: 58, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 691ms, time_since_start: 04h 18m 29s 418ms, eta: 01h 48m 40s 338ms
2022-04-21T18:55:51 | INFO | mmf.trainers.callbacks.logistics : progress: 15400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0586, train/total_loss: 0.0001, train/total_loss/avg: 0.0586, max mem: 10794.0, experiment: run, epoch: 58, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 639ms, time_since_start: 04h 20m 05s 058ms, eta: 01h 46m 59s 508ms
2022-04-21T18:57:26 | INFO | mmf.trainers.callbacks.logistics : progress: 15500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0583, train/total_loss: 0.0001, train/total_loss/avg: 0.0583, max mem: 10794.0, experiment: run, epoch: 59, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 133ms, time_since_start: 04h 21m 40s 191ms, eta: 01h 44m 48s 822ms
2022-04-21T18:59:02 | INFO | mmf.trainers.callbacks.logistics : progress: 15600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0579, train/total_loss: 0.0001, train/total_loss/avg: 0.0579, max mem: 10794.0, experiment: run, epoch: 59, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 552ms, time_since_start: 04h 23m 15s 744ms, eta: 01h 43m 39s 339ms
2022-04-21T19:00:37 | INFO | mmf.trainers.callbacks.logistics : progress: 15700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0575, train/total_loss: 0.0001, train/total_loss/avg: 0.0575, max mem: 10794.0, experiment: run, epoch: 60, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 270ms, time_since_start: 04h 24m 51s 014ms, eta: 01h 41m 44s 063ms
2022-04-21T19:02:13 | INFO | mmf.trainers.callbacks.logistics : progress: 15800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0572, train/total_loss: 0.0001, train/total_loss/avg: 0.0572, max mem: 10794.0, experiment: run, epoch: 60, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 603ms, time_since_start: 04h 26m 26s 618ms, eta: 01h 40m 28s 210ms
2022-04-21T19:03:48 | INFO | mmf.trainers.callbacks.logistics : progress: 15900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0568, train/total_loss: 0.0001, train/total_loss/avg: 0.0568, max mem: 10794.0, experiment: run, epoch: 60, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 558ms, time_since_start: 04h 28m 02s 177ms, eta: 01h 38m 48s 192ms
2022-04-21T19:05:24 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T19:05:24 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T19:05:36 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T19:05:48 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T19:05:49 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0566, train/total_loss: 0.0001, train/total_loss/avg: 0.0566, max mem: 10794.0, experiment: run, epoch: 61, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0., ups: 0.83, time: 02m 272ms, time_since_start: 04h 30m 02s 450ms, eta: 02h 02m 19s 011ms
2022-04-21T19:05:49 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T19:05:49 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T19:05:54 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T19:05:54 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T19:05:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T19:06:06 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T19:06:21 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T19:06:21 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/22000, val/hateful_memes/cross_entropy: 2.2674, val/total_loss: 2.2674, val/hateful_memes/accuracy: 0.6981, val/hateful_memes/binary_f1: 0.5356, val/hateful_memes/roc_auc: 0.7089, num_updates: 16000, epoch: 61, iterations: 16000, max_updates: 22000, val_time: 32s 319ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.713515
2022-04-21T19:07:58 | INFO | mmf.trainers.callbacks.logistics : progress: 16100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0562, train/total_loss: 0.0001, train/total_loss/avg: 0.0562, max mem: 10794.0, experiment: run, epoch: 61, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 531ms, time_since_start: 04h 32m 11s 303ms, eta: 01h 36m 32s 190ms
2022-04-21T19:09:33 | INFO | mmf.trainers.callbacks.logistics : progress: 16200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0559, train/total_loss: 0.0001, train/total_loss/avg: 0.0559, max mem: 10794.0, experiment: run, epoch: 61, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 470ms, time_since_start: 04h 33m 46s 773ms, eta: 01h 33m 51s 418ms
2022-04-21T19:11:08 | INFO | mmf.trainers.callbacks.logistics : progress: 16300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0555, train/total_loss: 0.0001, train/total_loss/avg: 0.0555, max mem: 10794.0, experiment: run, epoch: 62, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 144ms, time_since_start: 04h 35m 21s 918ms, eta: 01h 31m 55s 414ms
2022-04-21T19:12:44 | INFO | mmf.trainers.callbacks.logistics : progress: 16400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0552, train/total_loss: 0.0001, train/total_loss/avg: 0.0552, max mem: 10794.0, experiment: run, epoch: 62, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 484ms, time_since_start: 04h 36m 57s 402ms, eta: 01h 30m 38s 041ms
2022-04-21T19:14:19 | INFO | mmf.trainers.callbacks.logistics : progress: 16500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0549, train/total_loss: 0.0001, train/total_loss/avg: 0.0549, max mem: 10794.0, experiment: run, epoch: 63, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 088ms, time_since_start: 04h 38m 32s 490ms, eta: 01h 28m 38s 757ms
2022-04-21T19:15:54 | INFO | mmf.trainers.callbacks.logistics : progress: 16600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0545, train/total_loss: 0.0001, train/total_loss/avg: 0.0545, max mem: 10794.0, experiment: run, epoch: 63, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 560ms, time_since_start: 04h 40m 08s 051ms, eta: 01h 27m 28s 008ms
2022-04-21T19:17:30 | INFO | mmf.trainers.callbacks.logistics : progress: 16700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0542, train/total_loss: 0.0001, train/total_loss/avg: 0.0542, max mem: 10794.0, experiment: run, epoch: 63, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 322ms, time_since_start: 04h 41m 43s 374ms, eta: 01h 25m 37s 988ms
2022-04-21T19:19:05 | INFO | mmf.trainers.callbacks.logistics : progress: 16800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0539, train/total_loss: 0.0001, train/total_loss/avg: 0.0539, max mem: 10794.0, experiment: run, epoch: 64, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 028ms, time_since_start: 04h 43m 18s 402ms, eta: 01h 23m 45s 471ms
2022-04-21T19:20:40 | INFO | mmf.trainers.callbacks.logistics : progress: 16900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0536, train/total_loss: 0.0001, train/total_loss/avg: 0.0536, max mem: 10794.0, experiment: run, epoch: 64, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 271ms, time_since_start: 04h 44m 53s 674ms, eta: 01h 22m 21s 450ms
2022-04-21T19:22:15 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T19:22:15 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T19:22:26 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T19:22:38 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T19:22:38 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0532, train/total_loss: 0.0001, train/total_loss/avg: 0.0532, max mem: 10794.0, experiment: run, epoch: 64, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0., ups: 0.85, time: 01m 57s 727ms, time_since_start: 04h 46m 51s 401ms, eta: 01h 39m 46s 425ms
2022-04-21T19:22:38 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T19:22:38 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T19:22:43 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T19:22:43 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T19:22:43 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T19:22:57 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T19:23:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T19:23:08 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/22000, val/hateful_memes/cross_entropy: 2.6155, val/total_loss: 2.6155, val/hateful_memes/accuracy: 0.6963, val/hateful_memes/binary_f1: 0.4777, val/hateful_memes/roc_auc: 0.7072, num_updates: 17000, epoch: 64, iterations: 17000, max_updates: 22000, val_time: 30s 165ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.713515
2022-04-21T19:24:44 | INFO | mmf.trainers.callbacks.logistics : progress: 17100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0529, train/total_loss: 0.0001, train/total_loss/avg: 0.0529, max mem: 10794.0, experiment: run, epoch: 65, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 027ms, time_since_start: 04h 48m 57s 595ms, eta: 01h 19m 45s 316ms
2022-04-21T19:26:20 | INFO | mmf.trainers.callbacks.logistics : progress: 17200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0526, train/total_loss: 0.0001, train/total_loss/avg: 0.0526, max mem: 10794.0, experiment: run, epoch: 65, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 771ms, time_since_start: 04h 50m 33s 367ms, eta: 01h 17m 55s 199ms
2022-04-21T19:27:55 | INFO | mmf.trainers.callbacks.logistics : progress: 17300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0523, train/total_loss: 0.0001, train/total_loss/avg: 0.0523, max mem: 10794.0, experiment: run, epoch: 66, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 493ms, time_since_start: 04h 52m 08s 861ms, eta: 01h 16m 04s 494ms
2022-04-21T19:29:31 | INFO | mmf.trainers.callbacks.logistics : progress: 17400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0520, train/total_loss: 0.0001, train/total_loss/avg: 0.0520, max mem: 10794.0, experiment: run, epoch: 66, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 700ms, time_since_start: 04h 53m 44s 561ms, eta: 01h 14m 37s 041ms
2022-04-21T19:31:07 | INFO | mmf.trainers.callbacks.logistics : progress: 17500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0517, train/total_loss: 0.0001, train/total_loss/avg: 0.0517, max mem: 10794.0, experiment: run, epoch: 66, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 815ms, time_since_start: 04h 55m 20s 377ms, eta: 01h 13m 05s 007ms
2022-04-21T19:32:42 | INFO | mmf.trainers.callbacks.logistics : progress: 17600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0514, train/total_loss: 0.0001, train/total_loss/avg: 0.0514, max mem: 10794.0, experiment: run, epoch: 67, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 355ms, time_since_start: 04h 56m 55s 732ms, eta: 01h 11m 06s 968ms
2022-04-21T19:34:18 | INFO | mmf.trainers.callbacks.logistics : progress: 17700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0511, train/total_loss: 0.0001, train/total_loss/avg: 0.0511, max mem: 10794.0, experiment: run, epoch: 67, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 710ms, time_since_start: 04h 58m 31s 443ms, eta: 01h 09m 45s 521ms
2022-04-21T19:35:53 | INFO | mmf.trainers.callbacks.logistics : progress: 17800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0509, train/total_loss: 0.0001, train/total_loss/avg: 0.0509, max mem: 10794.0, experiment: run, epoch: 67, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 798ms, time_since_start: 05h 07s 242ms, eta: 01h 08m 11s 944ms
2022-04-21T19:37:29 | INFO | mmf.trainers.callbacks.logistics : progress: 17900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0506, train/total_loss: 0.0001, train/total_loss/avg: 0.0506, max mem: 10794.0, experiment: run, epoch: 68, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 370ms, time_since_start: 05h 01m 42s 612ms, eta: 01h 06m 16s 656ms
2022-04-21T19:39:04 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T19:39:04 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T19:39:15 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T19:39:26 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T19:39:26 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0503, train/total_loss: 0.0001, train/total_loss/avg: 0.0503, max mem: 10794.0, experiment: run, epoch: 68, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0., ups: 0.85, time: 01m 57s 400ms, time_since_start: 05h 03m 40s 013ms, eta: 01h 19m 35s 859ms
2022-04-21T19:39:26 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T19:39:26 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T19:39:31 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T19:39:31 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T19:39:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T19:39:41 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T19:39:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T19:39:55 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/22000, val/hateful_memes/cross_entropy: 2.5684, val/total_loss: 2.5684, val/hateful_memes/accuracy: 0.6963, val/hateful_memes/binary_f1: 0.4710, val/hateful_memes/roc_auc: 0.7127, num_updates: 18000, epoch: 68, iterations: 18000, max_updates: 22000, val_time: 29s 115ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.713515
2022-04-21T19:41:32 | INFO | mmf.trainers.callbacks.logistics : progress: 18100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0500, train/total_loss: 0.0001, train/total_loss/avg: 0.0500, max mem: 10794.0, experiment: run, epoch: 69, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 453ms, time_since_start: 05h 05m 45s 583ms, eta: 01h 03m 45s 623ms
2022-04-21T19:43:08 | INFO | mmf.trainers.callbacks.logistics : progress: 18200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0497, train/total_loss: 0.0001, train/total_loss/avg: 0.0497, max mem: 10794.0, experiment: run, epoch: 69, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 088ms, time_since_start: 05h 07m 21s 672ms, eta: 01h 01m 53s 451ms
2022-04-21T19:44:44 | INFO | mmf.trainers.callbacks.logistics : progress: 18300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0495, train/total_loss: 0.0001, train/total_loss/avg: 0.0495, max mem: 10794.0, experiment: run, epoch: 69, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 035ms, time_since_start: 05h 08m 57s 708ms, eta: 01h 13s 735ms
2022-04-21T19:46:20 | INFO | mmf.trainers.callbacks.logistics : progress: 18400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0492, train/total_loss: 0.0001, train/total_loss/avg: 0.0492, max mem: 10794.0, experiment: run, epoch: 70, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 657ms, time_since_start: 05h 10m 33s 366ms, eta: 58m 22s 225ms
2022-04-21T19:47:55 | INFO | mmf.trainers.callbacks.logistics : progress: 18500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0489, train/total_loss: 0.0001, train/total_loss/avg: 0.0489, max mem: 10794.0, experiment: run, epoch: 70, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 807ms, time_since_start: 05h 12m 09s 173ms, eta: 56m 50s 269ms
2022-04-21T19:49:31 | INFO | mmf.trainers.callbacks.logistics : progress: 18600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0487, train/total_loss: 0.0000, train/total_loss/avg: 0.0487, max mem: 10794.0, experiment: run, epoch: 70, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 595ms, time_since_start: 05h 13m 44s 769ms, eta: 55m 05s 508ms
2022-04-21T19:51:06 | INFO | mmf.trainers.callbacks.logistics : progress: 18700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0484, train/total_loss: 0.0000, train/total_loss/avg: 0.0484, max mem: 10794.0, experiment: run, epoch: 71, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 232ms, time_since_start: 05h 15m 20s 002ms, eta: 53m 16s 096ms
2022-04-21T19:52:42 | INFO | mmf.trainers.callbacks.logistics : progress: 18800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0481, train/total_loss: 0.0000, train/total_loss/avg: 0.0481, max mem: 10794.0, experiment: run, epoch: 71, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 630ms, time_since_start: 05h 16m 55s 632ms, eta: 51m 52s 205ms
2022-04-21T19:54:17 | INFO | mmf.trainers.callbacks.logistics : progress: 18900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0479, train/total_loss: 0.0000, train/total_loss/avg: 0.0479, max mem: 10794.0, experiment: run, epoch: 72, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 164ms, time_since_start: 05h 18m 30s 797ms, eta: 50m 250ms
2022-04-21T19:55:52 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T19:55:52 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T19:56:02 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T19:56:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T19:56:13 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0476, train/total_loss: 0.0000, train/total_loss/avg: 0.0476, max mem: 10794.0, experiment: run, epoch: 72, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0., ups: 0.87, time: 01m 55s 932ms, time_since_start: 05h 20m 26s 730ms, eta: 58m 57s 112ms
2022-04-21T19:56:13 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T19:56:13 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T19:56:19 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T19:56:19 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T19:56:19 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/22000, val/hateful_memes/cross_entropy: 2.7689, val/total_loss: 2.7689, val/hateful_memes/accuracy: 0.6759, val/hateful_memes/binary_f1: 0.4186, val/hateful_memes/roc_auc: 0.7118, num_updates: 19000, epoch: 72, iterations: 19000, max_updates: 22000, val_time: 06s 093ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.713515
2022-04-21T19:57:55 | INFO | mmf.trainers.callbacks.logistics : progress: 19100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0474, train/total_loss: 0.0000, train/total_loss/avg: 0.0474, max mem: 10794.0, experiment: run, epoch: 72, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 443ms, time_since_start: 05h 22m 09s 268ms, eta: 47m 24s 405ms
2022-04-21T19:59:31 | INFO | mmf.trainers.callbacks.logistics : progress: 19200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0471, train/total_loss: 0.0000, train/total_loss/avg: 0.0471, max mem: 10794.0, experiment: run, epoch: 73, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 232ms, time_since_start: 05h 23m 44s 500ms, eta: 45m 11s 833ms
2022-04-21T20:01:06 | INFO | mmf.trainers.callbacks.logistics : progress: 19300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0469, train/total_loss: 0.0000, train/total_loss/avg: 0.0469, max mem: 10794.0, experiment: run, epoch: 73, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 283ms, time_since_start: 05h 25m 19s 783ms, eta: 43m 36s 381ms
2022-04-21T20:02:41 | INFO | mmf.trainers.callbacks.logistics : progress: 19400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0467, train/total_loss: 0.0000, train/total_loss/avg: 0.0467, max mem: 10794.0, experiment: run, epoch: 73, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 291ms, time_since_start: 05h 26m 55s 075ms, eta: 41m 59s 696ms
2022-04-21T20:04:16 | INFO | mmf.trainers.callbacks.logistics : progress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0464, train/total_loss: 0.0000, train/total_loss/avg: 0.0464, max mem: 10794.0, experiment: run, epoch: 74, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 956ms, time_since_start: 05h 28m 30s 031ms, eta: 40m 14s 258ms
2022-04-21T20:05:52 | INFO | mmf.trainers.callbacks.logistics : progress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0462, train/total_loss: 0.0000, train/total_loss/avg: 0.0462, max mem: 10794.0, experiment: run, epoch: 74, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 268ms, time_since_start: 05h 30m 05s 299ms, eta: 38m 45s 306ms
2022-04-21T20:07:26 | INFO | mmf.trainers.callbacks.logistics : progress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0459, train/total_loss: 0.0000, train/total_loss/avg: 0.0459, max mem: 10794.0, experiment: run, epoch: 75, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 898ms, time_since_start: 05h 31m 40s 198ms, eta: 36m 59s 778ms
2022-04-21T20:09:02 | INFO | mmf.trainers.callbacks.logistics : progress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0457, train/total_loss: 0.0000, train/total_loss/avg: 0.0457, max mem: 10794.0, experiment: run, epoch: 75, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 266ms, time_since_start: 05h 33m 15s 465ms, eta: 35m 31s 502ms
2022-04-21T20:10:37 | INFO | mmf.trainers.callbacks.logistics : progress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0455, train/total_loss: 0.0000, train/total_loss/avg: 0.0455, max mem: 10794.0, experiment: run, epoch: 75, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 313ms, time_since_start: 05h 34m 50s 778ms, eta: 33m 55s 600ms
2022-04-21T20:12:12 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T20:12:12 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T20:12:21 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T20:12:33 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T20:12:33 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0453, train/total_loss: 0.0000, train/total_loss/avg: 0.0453, max mem: 10794.0, experiment: run, epoch: 76, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0., ups: 0.87, time: 01m 55s 993ms, time_since_start: 05h 36m 46s 772ms, eta: 39m 19s 315ms
2022-04-21T20:12:33 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T20:12:33 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T20:12:39 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T20:12:39 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T20:12:39 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/22000, val/hateful_memes/cross_entropy: 2.7243, val/total_loss: 2.7243, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4601, val/hateful_memes/roc_auc: 0.7101, num_updates: 20000, epoch: 76, iterations: 20000, max_updates: 22000, val_time: 05s 958ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.713515
2022-04-21T20:14:15 | INFO | mmf.trainers.callbacks.logistics : progress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0450, train/total_loss: 0.0000, train/total_loss/avg: 0.0450, max mem: 10794.0, experiment: run, epoch: 76, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 364ms, time_since_start: 05h 38m 29s 096ms, eta: 31m 02s 049ms
2022-04-21T20:15:51 | INFO | mmf.trainers.callbacks.logistics : progress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0448, train/total_loss: 0.0000, train/total_loss/avg: 0.0448, max mem: 10794.0, experiment: run, epoch: 76, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 356ms, time_since_start: 05h 40m 04s 452ms, eta: 29m 05s 593ms
2022-04-21T20:17:25 | INFO | mmf.trainers.callbacks.logistics : progress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0446, train/total_loss: 0.0000, train/total_loss/avg: 0.0446, max mem: 10794.0, experiment: run, epoch: 77, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 787ms, time_since_start: 05h 41m 39s 240ms, eta: 27m 18s 783ms
2022-04-21T20:19:01 | INFO | mmf.trainers.callbacks.logistics : progress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0444, train/total_loss: 0.0000, train/total_loss/avg: 0.0444, max mem: 10794.0, experiment: run, epoch: 77, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 325ms, time_since_start: 05h 43m 14s 566ms, eta: 25m 51s 142ms
2022-04-21T20:20:36 | INFO | mmf.trainers.callbacks.logistics : progress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0441, train/total_loss: 0.0000, train/total_loss/avg: 0.0441, max mem: 10794.0, experiment: run, epoch: 78, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 995ms, time_since_start: 05h 44m 49s 561ms, eta: 24m 09s 156ms
2022-04-21T20:22:11 | INFO | mmf.trainers.callbacks.logistics : progress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0439, train/total_loss: 0.0000, train/total_loss/avg: 0.0439, max mem: 10794.0, experiment: run, epoch: 78, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 284ms, time_since_start: 05h 46m 24s 846ms, eta: 22m 36s 660ms
2022-04-21T20:23:46 | INFO | mmf.trainers.callbacks.logistics : progress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0437, train/total_loss: 0.0000, train/total_loss/avg: 0.0437, max mem: 10794.0, experiment: run, epoch: 78, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 328ms, time_since_start: 05h 48m 175ms, eta: 21m 344ms
2022-04-21T20:25:21 | INFO | mmf.trainers.callbacks.logistics : progress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0435, train/total_loss: 0.0000, train/total_loss/avg: 0.0435, max mem: 10794.0, experiment: run, epoch: 79, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 857ms, time_since_start: 05h 49m 35s 032ms, eta: 19m 17s 635ms
2022-04-21T20:26:57 | INFO | mmf.trainers.callbacks.logistics : progress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0433, train/total_loss: 0.0000, train/total_loss/avg: 0.0433, max mem: 10794.0, experiment: run, epoch: 79, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 363ms, time_since_start: 05h 51m 10s 396ms, eta: 17m 46s 837ms
2022-04-21T20:28:32 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T20:28:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T20:28:44 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T20:28:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T20:28:55 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0431, train/total_loss: 0.0000, train/total_loss/avg: 0.0431, max mem: 10794.0, experiment: run, epoch: 79, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 0.85, time: 01m 58s 442ms, time_since_start: 05h 53m 08s 839ms, eta: 20m 04s 565ms
2022-04-21T20:28:55 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T20:28:55 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T20:29:00 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T20:29:00 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T20:29:01 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/22000, val/hateful_memes/cross_entropy: 2.7642, val/total_loss: 2.7642, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4430, val/hateful_memes/roc_auc: 0.7112, num_updates: 21000, epoch: 79, iterations: 21000, max_updates: 22000, val_time: 05s 680ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.713515
2022-04-21T20:30:37 | INFO | mmf.trainers.callbacks.logistics : progress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0429, train/total_loss: 0.0000, train/total_loss/avg: 0.0429, max mem: 10794.0, experiment: run, epoch: 80, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 997ms, time_since_start: 05h 54m 50s 519ms, eta: 14m 38s 666ms
2022-04-21T20:32:12 | INFO | mmf.trainers.callbacks.logistics : progress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0427, train/total_loss: 0.0000, train/total_loss/avg: 0.0427, max mem: 10794.0, experiment: run, epoch: 80, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 346ms, time_since_start: 05h 56m 25s 865ms, eta: 12m 55s 736ms
2022-04-21T20:33:47 | INFO | mmf.trainers.callbacks.logistics : progress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0425, train/total_loss: 0.0000, train/total_loss/avg: 0.0425, max mem: 10794.0, experiment: run, epoch: 81, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 952ms, time_since_start: 05h 58m 817ms, eta: 11m 15s 968ms
2022-04-21T20:35:23 | INFO | mmf.trainers.callbacks.logistics : progress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0423, train/total_loss: 0.0000, train/total_loss/avg: 0.0423, max mem: 10794.0, experiment: run, epoch: 81, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 476ms, time_since_start: 05h 59m 36s 294ms, eta: 09m 42s 599ms
2022-04-21T20:36:58 | INFO | mmf.trainers.callbacks.logistics : progress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0421, train/total_loss: 0.0000, train/total_loss/avg: 0.0421, max mem: 10794.0, experiment: run, epoch: 81, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 458ms, time_since_start: 06h 01m 11s 752ms, eta: 08m 05s 404ms
2022-04-21T20:38:33 | INFO | mmf.trainers.callbacks.logistics : progress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0419, train/total_loss: 0.0000, train/total_loss/avg: 0.0419, max mem: 10794.0, experiment: run, epoch: 82, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 262ms, time_since_start: 06h 02m 47s 015ms, eta: 06m 27s 528ms
2022-04-21T20:40:09 | INFO | mmf.trainers.callbacks.logistics : progress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0417, train/total_loss: 0.0000, train/total_loss/avg: 0.0417, max mem: 10794.0, experiment: run, epoch: 82, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 378ms, time_since_start: 06h 04m 22s 394ms, eta: 04m 50s 999ms
2022-04-21T20:41:44 | INFO | mmf.trainers.callbacks.logistics : progress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0415, train/total_loss: 0.0000, train/total_loss/avg: 0.0415, max mem: 10794.0, experiment: run, epoch: 82, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 1.05, time: 01m 35s 457ms, time_since_start: 06h 05m 57s 851ms, eta: 03m 14s 159ms
2022-04-21T20:43:19 | INFO | mmf.trainers.callbacks.logistics : progress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0413, train/total_loss: 0.0000, train/total_loss/avg: 0.0413, max mem: 10794.0, experiment: run, epoch: 83, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 1.06, time: 01m 34s 966ms, time_since_start: 06h 07m 32s 817ms, eta: 01m 36s 580ms
2022-04-21T20:44:54 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-04-21T20:44:54 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-04-21T20:45:04 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-04-21T20:45:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-04-21T20:45:18 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0411, train/total_loss: 0.0000, train/total_loss/avg: 0.0411, max mem: 10794.0, experiment: run, epoch: 83, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 0.84, time: 01m 59s 252ms, time_since_start: 06h 09m 32s 069ms, eta: 0ms
2022-04-21T20:45:18 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-04-21T20:45:18 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T20:45:24 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T20:45:24 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T20:45:24 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/22000, val/hateful_memes/cross_entropy: 2.7464, val/total_loss: 2.7464, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4531, val/hateful_memes/roc_auc: 0.7115, num_updates: 22000, epoch: 83, iterations: 22000, max_updates: 22000, val_time: 05s 972ms, best_update: 14000, best_iteration: 14000, best_val/hateful_memes/roc_auc: 0.713515
2022-04-21T20:45:25 | INFO | mmf.trainers.core.training_loop : Stepping into final validation check
2022-04-21T20:45:25 | INFO | mmf.utils.checkpoint : Restoring checkpoint
2022-04-21T20:45:25 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-04-21T20:45:42 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-04-21T20:45:42 | INFO | mmf.utils.checkpoint : Current num updates: 14000
2022-04-21T20:45:42 | INFO | mmf.utils.checkpoint : Current iteration: 14000
2022-04-21T20:45:42 | INFO | mmf.utils.checkpoint : Current epoch: 53
2022-04-21T20:45:48 | INFO | mmf.trainers.mmf_trainer : Starting inference on test set
2022-04-21T20:45:48 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T20:46:08 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 63
2022-04-21T20:46:08 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T20:46:08 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, test/hateful_memes/cross_entropy: 2.1028, test/total_loss: 2.1028, test/hateful_memes/accuracy: 0.7155, test/hateful_memes/binary_f1: 0.5325, test/hateful_memes/roc_auc: 0.7472
2022-04-21T20:46:08 | INFO | mmf.trainers.callbacks.logistics : Finished run in 06h 10m 21s 576ms
2022-04-21T22:53:08 | INFO | mmf : Logging to: ./save/train.log
2022-04-21T22:53:08 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/from_cc.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False'])
2022-04-21T22:53:08 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-04-21T22:53:08 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla P100-PCIE-16GB
2022-04-21T22:53:08 | INFO | mmf_cli.run : Using seed 8676515
2022-04-21T22:53:08 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-04-21T22:53:10 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-21T22:53:10 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-21T22:53:10 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-21T22:53:10 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-04-21T22:53:18 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-04-21T22:53:18 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-04-21T22:53:19 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-04-21T22:53:22 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-04-21T22:53:22 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-04-21T22:53:22 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-04-21T22:53:22 | INFO | mmf.utils.checkpoint : Current num updates: 14000
2022-04-21T22:53:22 | INFO | mmf.utils.checkpoint : Current iteration: 14000
2022-04-21T22:53:22 | INFO | mmf.utils.checkpoint : Current epoch: 53
2022-04-21T22:53:22 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2022-04-21T22:53:22 | INFO | mmf.trainers.mmf_trainer : ViLBERT(
  (model): ViLBERTForClassification(
    (bert): ViLBERTBase(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (v_embeddings): BertImageFeatureEmbeddings(
        (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)
        (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (v_layer): ModuleList(
          (0): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (c_layer): ModuleList(
          (0): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (t_pooler): BertTextPooler(
        (dense): Linear(in_features=768, out_features=1024, bias=True)
        (activation): ReLU()
      )
      (v_pooler): BertImagePooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): ReLU()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2022-04-21T22:53:22 | INFO | mmf.utils.general : Total Parameters: 247780354. Trained Parameters: 247780354
2022-04-21T22:53:22 | INFO | mmf.trainers.mmf_trainer : Starting inference on val set
2022-04-21T22:53:22 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-21T22:53:28 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 17
2022-04-21T22:53:28 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-21T22:53:28 | INFO | mmf.trainers.callbacks.logistics : val/hateful_memes/cross_entropy: 2.2292, val/total_loss: 2.2292, val/hateful_memes/accuracy: 0.7019, val/hateful_memes/binary_f1: 0.5165, val/hateful_memes/roc_auc: 0.7135
2022-04-21T22:53:28 | INFO | mmf.trainers.callbacks.logistics : Finished run in 09s 275ms
2022-04-25T16:26:39 | INFO | mmf : Logging to: ./save/train.log
2022-04-25T16:26:40 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save_vilbert_default/best.ckpt', 'checkpoint.resume_pretrained=False'])
2022-04-25T16:26:40 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-04-25T16:26:40 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2022-04-25T16:26:40 | INFO | mmf_cli.run : Using seed 39212665
2022-04-25T16:26:40 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-04-25T16:35:51 | INFO | mmf : Logging to: ./save/train.log
2022-04-25T16:35:51 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/from_cc.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False'])
2022-04-25T16:35:51 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-04-25T16:35:51 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2022-04-25T16:35:51 | INFO | mmf_cli.run : Using seed 51823477
2022-04-25T16:35:51 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-04-25T16:39:48 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T16:39:48 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T16:39:48 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T16:39:48 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-04-25T16:40:04 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-04-25T16:40:04 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-04-25T16:40:05 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-04-25T16:41:13 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-04-25T16:41:13 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-04-25T16:41:13 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-04-25T16:41:13 | INFO | mmf.utils.checkpoint : Current num updates: 14000
2022-04-25T16:41:13 | INFO | mmf.utils.checkpoint : Current iteration: 14000
2022-04-25T16:41:13 | INFO | mmf.utils.checkpoint : Current epoch: 53
2022-04-25T16:41:13 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2022-04-25T16:41:13 | INFO | mmf.trainers.mmf_trainer : ViLBERT(
  (model): ViLBERTForClassification(
    (bert): ViLBERTBase(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (v_embeddings): BertImageFeatureEmbeddings(
        (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)
        (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (v_layer): ModuleList(
          (0): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (c_layer): ModuleList(
          (0): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (t_pooler): BertTextPooler(
        (dense): Linear(in_features=768, out_features=1024, bias=True)
        (activation): ReLU()
      )
      (v_pooler): BertImagePooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): ReLU()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2022-04-25T16:41:14 | INFO | mmf.utils.general : Total Parameters: 247780354. Trained Parameters: 247780354
2022-04-25T16:41:14 | INFO | mmf.trainers.mmf_trainer : Starting inference on test set
2022-04-25T16:41:14 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-25T16:41:45 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 63
2022-04-25T16:41:45 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-25T16:41:45 | INFO | mmf.trainers.callbacks.logistics : test/hateful_memes/cross_entropy: 2.1028, test/total_loss: 2.1028, test/hateful_memes/accuracy: 0.7155, test/hateful_memes/binary_f1: 0.5325, test/hateful_memes/roc_auc: 0.7472
2022-04-25T16:41:45 | INFO | mmf.trainers.callbacks.logistics : Finished run in 01m 40s 157ms
2022-04-25T16:41:53 | INFO | mmf : Logging to: ./save/train.log
2022-04-25T16:41:53 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/vilbert/defaults.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save_vilbert_default/best.ckpt', 'checkpoint.resume_pretrained=False'])
2022-04-25T16:41:53 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-04-25T16:41:53 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2022-04-25T16:41:53 | INFO | mmf_cli.run : Using seed 53326153
2022-04-25T16:41:53 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-04-25T16:42:01 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T16:42:01 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T16:42:01 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T16:42:01 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-04-25T16:42:08 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-04-25T16:42:08 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-04-25T16:42:08 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-04-25T16:43:07 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-04-25T16:43:07 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-04-25T16:43:07 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-04-25T16:43:07 | INFO | mmf.utils.checkpoint : Current num updates: 2000
2022-04-25T16:43:07 | INFO | mmf.utils.checkpoint : Current iteration: 2000
2022-04-25T16:43:07 | INFO | mmf.utils.checkpoint : Current epoch: 8
2022-04-25T16:43:07 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2022-04-25T16:43:07 | INFO | mmf.trainers.mmf_trainer : ViLBERT(
  (model): ViLBERTForClassification(
    (bert): ViLBERTBase(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (v_embeddings): BertImageFeatureEmbeddings(
        (image_embeddings): Linear(in_features=2048, out_features=1024, bias=True)
        (image_location_embeddings): Linear(in_features=5, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (v_layer): ModuleList(
          (0): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertImageLayer(
            (attention): BertImageAttention(
              (self): BertImageSelfAttention(
                (query): Linear(in_features=1024, out_features=1024, bias=True)
                (key): Linear(in_features=1024, out_features=1024, bias=True)
                (value): Linear(in_features=1024, out_features=1024, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertImageSelfOutput(
                (dense): Linear(in_features=1024, out_features=1024, bias=True)
                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (c_layer): ModuleList(
          (0): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertConnectionLayer(
            (biattention): BertBiAttention(
              (query1): Linear(in_features=1024, out_features=1024, bias=True)
              (key1): Linear(in_features=1024, out_features=1024, bias=True)
              (value1): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (query2): Linear(in_features=768, out_features=1024, bias=True)
              (key2): Linear(in_features=768, out_features=1024, bias=True)
              (value2): Linear(in_features=768, out_features=1024, bias=True)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
            (biOutput): BertBiOutput(
              (dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm1): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (q_dense1): Linear(in_features=1024, out_features=1024, bias=True)
              (q_dropout1): Dropout(p=0.1, inplace=False)
              (dense2): Linear(in_features=1024, out_features=768, bias=True)
              (LayerNorm2): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout2): Dropout(p=0.1, inplace=False)
              (q_dense2): Linear(in_features=1024, out_features=768, bias=True)
              (q_dropout2): Dropout(p=0.1, inplace=False)
            )
            (v_intermediate): BertImageIntermediate(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
            )
            (v_output): BertImageOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (t_intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (t_output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (t_pooler): BertTextPooler(
        (dense): Linear(in_features=768, out_features=1024, bias=True)
        (activation): ReLU()
      )
      (v_pooler): BertImagePooler(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (activation): ReLU()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=1024, out_features=1024, bias=True)
        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2022-04-25T16:43:07 | INFO | mmf.utils.general : Total Parameters: 247780354. Trained Parameters: 247780354
2022-04-25T16:43:07 | INFO | mmf.trainers.mmf_trainer : Starting inference on test set
2022-04-25T16:43:07 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-25T16:43:40 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 63
2022-04-25T16:43:40 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-25T16:43:40 | INFO | mmf.trainers.callbacks.logistics : test/hateful_memes/cross_entropy: 0.7706, test/total_loss: 0.7706, test/hateful_memes/accuracy: 0.6895, test/hateful_memes/binary_f1: 0.5278, test/hateful_memes/roc_auc: 0.7166
2022-04-25T16:43:40 | INFO | mmf.trainers.callbacks.logistics : Finished run in 01m 32s 669ms
2022-04-25T16:59:40 | INFO | mmf : Logging to: ./save/train.log
2022-04-25T16:59:40 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/mmbt/defaults.yaml', 'model=mmbt', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save_mmbt_default/best.ckpt', 'checkpoint.resume_pretrained=False'])
2022-04-25T16:59:40 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-04-25T16:59:40 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2022-04-25T16:59:40 | INFO | mmf_cli.run : Using seed 40581969
2022-04-25T16:59:40 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-04-25T16:59:48 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T16:59:48 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T16:59:48 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T16:59:48 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-04-25T17:00:08 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-04-25T17:00:08 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-04-25T17:00:08 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-04-25T17:00:49 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-04-25T17:00:49 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-04-25T17:00:50 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-04-25T17:00:50 | INFO | mmf.utils.checkpoint : Current num updates: 8000
2022-04-25T17:00:50 | INFO | mmf.utils.checkpoint : Current iteration: 8000
2022-04-25T17:00:50 | INFO | mmf.utils.checkpoint : Current epoch: 31
2022-04-25T17:00:50 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2022-04-25T17:00:50 | INFO | mmf.trainers.mmf_trainer : MMBT(
  (model): MMBTForClassification(
    (bert): MMBTBase(
      (mmbt): MMBTModel(
        (transformer): BertModelJit(
          (embeddings): BertEmbeddingsJit(
            (word_embeddings): Embedding(30522, 768, padding_idx=0)
            (position_embeddings): Embedding(512, 768)
            (token_type_embeddings): Embedding(2, 768)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder): BertEncoderJit(
            (layer): ModuleList(
              (0): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (1): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (2): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (3): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (4): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (5): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (6): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (7): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (8): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (9): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (10): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (11): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
          (pooler): BertPooler(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (activation): Tanh()
          )
        )
        (modal_encoder): ModalEmbeddings(
          (encoder): ResNet152ImageEncoder(
            (model): Sequential(
              (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
              (4): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
              (5): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (3): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (4): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (5): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (6): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (7): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
              (6): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (3): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (4): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (5): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (6): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (7): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (8): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (9): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (10): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (11): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (12): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (13): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (14): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (15): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (16): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (17): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (18): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (19): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (20): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (21): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (22): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (23): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (24): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (25): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (26): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (27): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (28): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (29): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (30): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (31): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (32): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (33): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (34): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (35): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
              (7): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
            )
            (pool): AdaptiveAvgPool2d(output_size=(1, 1))
          )
          (proj_embeddings): Linear(in_features=2048, out_features=768, bias=True)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2022-04-25T17:00:50 | INFO | mmf.utils.general : Total Parameters: 169793346. Trained Parameters: 169793346
2022-04-25T17:00:50 | INFO | mmf.trainers.mmf_trainer : Starting inference on test set
2022-04-25T17:00:50 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-25T17:00:51 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-04-25T17:00:51 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-04-25T17:01:19 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 63
2022-04-25T17:01:19 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-25T17:01:19 | INFO | mmf.trainers.callbacks.logistics : test/hateful_memes/cross_entropy: 2.4298, test/total_loss: 2.4298, test/hateful_memes/accuracy: 0.6745, test/hateful_memes/binary_f1: 0.4402, test/hateful_memes/roc_auc: 0.6922
2022-04-25T17:01:19 | INFO | mmf.trainers.callbacks.logistics : Finished run in 01m 11s 589ms
2022-04-25T17:06:21 | INFO | mmf : Logging to: ./save/train.log
2022-04-25T17:06:21 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save_visual_bert_default_bs32/best.ckpt', 'checkpoint.resume_pretrained=False'])
2022-04-25T17:06:21 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-04-25T17:06:21 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2022-04-25T17:06:21 | INFO | mmf_cli.run : Using seed 21114096
2022-04-25T17:06:21 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-04-25T17:06:29 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T17:06:29 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T17:06:29 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T17:06:29 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-04-25T17:06:35 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-04-25T17:06:35 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-04-25T17:06:35 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-04-25T17:06:58 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-04-25T17:06:58 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-04-25T17:06:58 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-04-25T17:06:58 | INFO | mmf.utils.checkpoint : Current num updates: 10000
2022-04-25T17:06:58 | INFO | mmf.utils.checkpoint : Current iteration: 10000
2022-04-25T17:06:58 | INFO | mmf.utils.checkpoint : Current epoch: 38
2022-04-25T17:06:58 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2022-04-25T17:06:58 | INFO | mmf.trainers.mmf_trainer : VisualBERT(
  (model): VisualBERTForClassification(
    (bert): VisualBERTBase(
      (embeddings): BertVisioLinguisticEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (token_type_embeddings_visual): Embedding(2, 768)
        (position_embeddings_visual): Embedding(512, 768)
        (projection): Linear(in_features=2048, out_features=768, bias=True)
      )
      (encoder): BertEncoderJit(
        (layer): ModuleList(
          (0): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2022-04-25T17:06:58 | INFO | mmf.utils.general : Total Parameters: 112044290. Trained Parameters: 112044290
2022-04-25T17:06:58 | INFO | mmf.trainers.mmf_trainer : Starting inference on test set
2022-04-25T17:06:58 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-25T17:07:27 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 32
2022-04-25T17:07:27 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-25T17:07:28 | INFO | mmf.trainers.callbacks.logistics : test/hateful_memes/cross_entropy: 1.7315, test/total_loss: 1.7315, test/hateful_memes/accuracy: 0.6985, test/hateful_memes/binary_f1: 0.4668, test/hateful_memes/roc_auc: 0.7151
2022-04-25T17:07:28 | INFO | mmf.trainers.callbacks.logistics : Finished run in 52s 262ms
2022-04-25T17:15:18 | INFO | mmf : Logging to: ./save/train.log
2022-04-25T17:15:18 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/visual_bert/from_coco.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save_visual_bert_coco_bs32/best.ckpt', 'checkpoint.resume_pretrained=False'])
2022-04-25T17:15:18 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-04-25T17:15:18 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2022-04-25T17:15:18 | INFO | mmf_cli.run : Using seed 18578278
2022-04-25T17:15:18 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-04-25T17:15:26 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T17:15:26 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T17:15:26 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-04-25T17:15:26 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-04-25T17:15:33 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-04-25T17:15:33 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-04-25T17:15:33 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-04-25T17:15:55 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-04-25T17:15:55 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-04-25T17:15:55 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-04-25T17:15:55 | INFO | mmf.utils.checkpoint : Current num updates: 3000
2022-04-25T17:15:55 | INFO | mmf.utils.checkpoint : Current iteration: 3000
2022-04-25T17:15:55 | INFO | mmf.utils.checkpoint : Current epoch: 12
2022-04-25T17:15:55 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2022-04-25T17:15:55 | INFO | mmf.trainers.mmf_trainer : VisualBERT(
  (model): VisualBERTForClassification(
    (bert): VisualBERTBase(
      (embeddings): BertVisioLinguisticEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (token_type_embeddings_visual): Embedding(2, 768)
        (position_embeddings_visual): Embedding(512, 768)
        (projection): Linear(in_features=2048, out_features=768, bias=True)
      )
      (encoder): BertEncoderJit(
        (layer): ModuleList(
          (0): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayerJit(
            (attention): BertAttentionJit(
              (self): BertSelfAttentionJit(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2022-04-25T17:15:55 | INFO | mmf.utils.general : Total Parameters: 112044290. Trained Parameters: 112044290
2022-04-25T17:15:55 | INFO | mmf.trainers.mmf_trainer : Starting inference on test set
2022-04-25T17:15:55 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-04-25T17:16:24 | INFO | mmf.trainers.core.evaluation_loop : Finished training. Loaded 32
2022-04-25T17:16:24 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-04-25T17:16:25 | INFO | mmf.trainers.callbacks.logistics : test/hateful_memes/cross_entropy: 1.4032, test/total_loss: 1.4032, test/hateful_memes/accuracy: 0.7205, test/hateful_memes/binary_f1: 0.5539, test/hateful_memes/roc_auc: 0.7590
2022-04-25T17:16:25 | INFO | mmf.trainers.callbacks.logistics : Finished run in 51s 641ms
