2022-05-03T08:30:31 | INFO | mmf : Logging to: ./save/train.log
2022-05-03T08:30:31 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/mmbt/defaults.yaml', 'model=mmbt', 'dataset=hateful_memes'])
2022-05-03T08:30:31 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-05-03T08:30:31 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-16GB
2022-05-03T08:30:31 | INFO | mmf_cli.run : Using seed 31732289
2022-05-03T08:30:31 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-03T08:30:39 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T08:30:39 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T08:30:39 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T08:30:39 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-03T08:30:59 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-03T08:30:59 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-03T08:30:59 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2022-05-03T08:30:59 | INFO | mmf.trainers.mmf_trainer : MMBT(
  (model): MMBTForClassification(
    (bert): MMBTBase(
      (mmbt): MMBTModel(
        (transformer): BertModelJit(
          (embeddings): BertEmbeddingsJit(
            (word_embeddings): Embedding(30522, 768, padding_idx=0)
            (position_embeddings): Embedding(512, 768)
            (token_type_embeddings): Embedding(2, 768)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder): BertEncoderJit(
            (layer): ModuleList(
              (0): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (1): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (2): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (3): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (4): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (5): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (6): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (7): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (8): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (9): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (10): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (11): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
          (pooler): BertPooler(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (activation): Tanh()
          )
        )
        (modal_encoder): ModalEmbeddings(
          (encoder): ResNet152ImageEncoder(
            (model): Sequential(
              (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
              (4): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
              (5): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (3): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (4): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (5): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (6): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (7): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
              (6): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (3): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (4): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (5): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (6): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (7): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (8): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (9): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (10): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (11): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (12): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (13): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (14): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (15): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (16): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (17): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (18): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (19): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (20): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (21): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (22): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (23): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (24): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (25): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (26): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (27): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (28): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (29): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (30): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (31): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (32): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (33): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (34): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (35): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
              (7): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
            )
            (pool): AdaptiveAvgPool2d(output_size=(1, 1))
          )
          (proj_embeddings): Linear(in_features=2048, out_features=768, bias=True)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2022-05-03T08:30:59 | INFO | mmf.utils.general : Total Parameters: 169793346. Trained Parameters: 169793346
2022-05-03T08:30:59 | INFO | mmf.trainers.core.training_loop : Starting training...
2022-05-03T08:31:00 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-05-03T08:31:00 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-05-03T08:31:54 | INFO | mmf.trainers.callbacks.logistics : progress: 100/22000, train/hateful_memes/cross_entropy: 0.7619, train/hateful_memes/cross_entropy/avg: 0.7619, train/total_loss: 0.7619, train/total_loss/avg: 0.7619, max mem: 11656.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 1.82, time: 55s 087ms, time_since_start: 55s 184ms, eta: 03h 24m 29s 357ms
2022-05-03T08:32:48 | INFO | mmf.trainers.callbacks.logistics : progress: 200/22000, train/hateful_memes/cross_entropy: 0.6621, train/hateful_memes/cross_entropy/avg: 0.7120, train/total_loss: 0.6621, train/total_loss/avg: 0.7120, max mem: 11656.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 251ms, time_since_start: 01m 49s 435ms, eta: 03h 20m 27s 944ms
2022-05-03T08:33:43 | INFO | mmf.trainers.callbacks.logistics : progress: 300/22000, train/hateful_memes/cross_entropy: 0.7167, train/hateful_memes/cross_entropy/avg: 0.7135, train/total_loss: 0.7167, train/total_loss/avg: 0.7135, max mem: 11656.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 544ms, time_since_start: 02m 43s 980ms, eta: 03h 20m 37s 471ms
2022-05-03T08:34:37 | INFO | mmf.trainers.callbacks.logistics : progress: 400/22000, train/hateful_memes/cross_entropy: 0.7007, train/hateful_memes/cross_entropy/avg: 0.7103, train/total_loss: 0.7007, train/total_loss/avg: 0.7103, max mem: 11656.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 276ms, time_since_start: 03m 38s 257ms, eta: 03h 18m 43s 090ms
2022-05-03T08:35:31 | INFO | mmf.trainers.callbacks.logistics : progress: 500/22000, train/hateful_memes/cross_entropy: 0.7007, train/hateful_memes/cross_entropy/avg: 0.6707, train/total_loss: 0.7007, train/total_loss/avg: 0.6707, max mem: 11656.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 358ms, time_since_start: 04m 32s 615ms, eta: 03h 18m 05s 720ms
2022-05-03T08:36:26 | INFO | mmf.trainers.callbacks.logistics : progress: 600/22000, train/hateful_memes/cross_entropy: 0.6621, train/hateful_memes/cross_entropy/avg: 0.6476, train/total_loss: 0.6621, train/total_loss/avg: 0.6476, max mem: 11656.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 678ms, time_since_start: 05m 27s 294ms, eta: 03h 18m 20s 014ms
2022-05-03T08:37:20 | INFO | mmf.trainers.callbacks.logistics : progress: 700/22000, train/hateful_memes/cross_entropy: 0.6621, train/hateful_memes/cross_entropy/avg: 0.6358, train/total_loss: 0.6621, train/total_loss/avg: 0.6358, max mem: 11656.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 417ms, time_since_start: 06m 21s 711ms, eta: 03h 16m 28s 058ms
2022-05-03T08:38:15 | INFO | mmf.trainers.callbacks.logistics : progress: 800/22000, train/hateful_memes/cross_entropy: 0.6550, train/hateful_memes/cross_entropy/avg: 0.6382, train/total_loss: 0.6550, train/total_loss/avg: 0.6382, max mem: 11656.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 647ms, time_since_start: 07m 16s 359ms, eta: 03h 16m 22s 139ms
2022-05-03T08:39:10 | INFO | mmf.trainers.callbacks.logistics : progress: 900/22000, train/hateful_memes/cross_entropy: 0.6550, train/hateful_memes/cross_entropy/avg: 0.6389, train/total_loss: 0.6550, train/total_loss/avg: 0.6389, max mem: 11656.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 498ms, time_since_start: 08m 10s 857ms, eta: 03h 14m 54s 734ms
2022-05-03T08:40:04 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T08:40:04 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T08:40:10 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T08:40:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T08:40:18 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, train/hateful_memes/cross_entropy: 0.6444, train/hateful_memes/cross_entropy/avg: 0.6358, train/total_loss: 0.6444, train/total_loss/avg: 0.6358, max mem: 11656.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00001, ups: 1.47, time: 01m 08s 497ms, time_since_start: 09m 19s 355ms, eta: 04h 03m 48s 985ms
2022-05-03T08:40:18 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T08:40:18 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T08:40:22 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T08:40:22 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T08:40:22 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T08:40:29 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-03T08:40:38 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T08:40:48 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T08:40:48 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, val/hateful_memes/cross_entropy: 0.7253, val/total_loss: 0.7253, val/hateful_memes/accuracy: 0.6315, val/hateful_memes/binary_f1: 0.3066, val/hateful_memes/roc_auc: 0.5985, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 22000, val_time: 30s 151ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.598456
2022-05-03T08:41:44 | INFO | mmf.trainers.callbacks.logistics : progress: 1100/22000, train/hateful_memes/cross_entropy: 0.6444, train/hateful_memes/cross_entropy/avg: 0.6295, train/total_loss: 0.6444, train/total_loss/avg: 0.6295, max mem: 11667.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 650ms, time_since_start: 10m 45s 158ms, eta: 03h 17m 08s 742ms
2022-05-03T08:42:38 | INFO | mmf.trainers.callbacks.logistics : progress: 1200/22000, train/hateful_memes/cross_entropy: 0.6079, train/hateful_memes/cross_entropy/avg: 0.6157, train/total_loss: 0.6079, train/total_loss/avg: 0.6157, max mem: 11667.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 369ms, time_since_start: 11m 39s 528ms, eta: 03h 11m 41s 084ms
2022-05-03T08:43:33 | INFO | mmf.trainers.callbacks.logistics : progress: 1300/22000, train/hateful_memes/cross_entropy: 0.6079, train/hateful_memes/cross_entropy/avg: 0.6080, train/total_loss: 0.6079, train/total_loss/avg: 0.6080, max mem: 11667.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 338ms, time_since_start: 12m 33s 867ms, eta: 03h 10m 39s 344ms
2022-05-03T08:44:27 | INFO | mmf.trainers.callbacks.logistics : progress: 1400/22000, train/hateful_memes/cross_entropy: 0.5659, train/hateful_memes/cross_entropy/avg: 0.6011, train/total_loss: 0.5659, train/total_loss/avg: 0.6011, max mem: 11667.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 726ms, time_since_start: 13m 28s 593ms, eta: 03h 11m 05s 396ms
2022-05-03T08:45:22 | INFO | mmf.trainers.callbacks.logistics : progress: 1500/22000, train/hateful_memes/cross_entropy: 0.5659, train/hateful_memes/cross_entropy/avg: 0.5795, train/total_loss: 0.5659, train/total_loss/avg: 0.5795, max mem: 11667.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 402ms, time_since_start: 14m 22s 996ms, eta: 03h 09m 02s 193ms
2022-05-03T08:46:16 | INFO | mmf.trainers.callbacks.logistics : progress: 1600/22000, train/hateful_memes/cross_entropy: 0.5652, train/hateful_memes/cross_entropy/avg: 0.5572, train/total_loss: 0.5652, train/total_loss/avg: 0.5572, max mem: 11667.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 683ms, time_since_start: 15m 17s 680ms, eta: 03h 09m 05s 118ms
2022-05-03T08:47:11 | INFO | mmf.trainers.callbacks.logistics : progress: 1700/22000, train/hateful_memes/cross_entropy: 0.5652, train/hateful_memes/cross_entropy/avg: 0.5438, train/total_loss: 0.5652, train/total_loss/avg: 0.5438, max mem: 11667.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 446ms, time_since_start: 16m 12s 126ms, eta: 03h 07m 20s 503ms
2022-05-03T08:48:05 | INFO | mmf.trainers.callbacks.logistics : progress: 1800/22000, train/hateful_memes/cross_entropy: 0.5319, train/hateful_memes/cross_entropy/avg: 0.5244, train/total_loss: 0.5319, train/total_loss/avg: 0.5244, max mem: 11667.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 331ms, time_since_start: 17m 06s 458ms, eta: 03h 06m 01s 493ms
2022-05-03T08:49:00 | INFO | mmf.trainers.callbacks.logistics : progress: 1900/22000, train/hateful_memes/cross_entropy: 0.5319, train/hateful_memes/cross_entropy/avg: 0.5045, train/total_loss: 0.5319, train/total_loss/avg: 0.5045, max mem: 11667.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 955ms, time_since_start: 18m 01s 413ms, eta: 03h 07m 13s 869ms
2022-05-03T08:49:55 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T08:49:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T08:50:00 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T08:50:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T08:50:08 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, train/hateful_memes/cross_entropy: 0.5161, train/hateful_memes/cross_entropy/avg: 0.4973, train/total_loss: 0.5161, train/total_loss/avg: 0.4973, max mem: 11667.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00001, ups: 1.47, time: 01m 08s 075ms, time_since_start: 19m 09s 489ms, eta: 03h 50m 46s 648ms
2022-05-03T08:50:08 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T08:50:08 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T08:50:12 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T08:50:12 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T08:50:12 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T08:50:18 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T08:50:28 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T08:50:28 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, val/hateful_memes/cross_entropy: 1.1800, val/total_loss: 1.1800, val/hateful_memes/accuracy: 0.6278, val/hateful_memes/binary_f1: 0.3699, val/hateful_memes/roc_auc: 0.5921, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 22000, val_time: 19s 292ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.598456
2022-05-03T08:51:23 | INFO | mmf.trainers.callbacks.logistics : progress: 2100/22000, train/hateful_memes/cross_entropy: 0.5124, train/hateful_memes/cross_entropy/avg: 0.4777, train/total_loss: 0.5124, train/total_loss/avg: 0.4777, max mem: 11667.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 050ms, time_since_start: 20m 23s 835ms, eta: 03h 05m 41s 344ms
2022-05-03T08:52:18 | INFO | mmf.trainers.callbacks.logistics : progress: 2200/22000, train/hateful_memes/cross_entropy: 0.5111, train/hateful_memes/cross_entropy/avg: 0.4611, train/total_loss: 0.5111, train/total_loss/avg: 0.4611, max mem: 11667.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 953ms, time_since_start: 21m 18s 788ms, eta: 03h 04m 25s 750ms
2022-05-03T08:53:12 | INFO | mmf.trainers.callbacks.logistics : progress: 2300/22000, train/hateful_memes/cross_entropy: 0.4641, train/hateful_memes/cross_entropy/avg: 0.4464, train/total_loss: 0.4641, train/total_loss/avg: 0.4464, max mem: 11667.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 546ms, time_since_start: 22m 13s 335ms, eta: 03h 02m 08s 375ms
2022-05-03T08:54:07 | INFO | mmf.trainers.callbacks.logistics : progress: 2400/22000, train/hateful_memes/cross_entropy: 0.3592, train/hateful_memes/cross_entropy/avg: 0.4323, train/total_loss: 0.3592, train/total_loss/avg: 0.4323, max mem: 11667.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 924ms, time_since_start: 23m 08s 259ms, eta: 03h 02m 28s 230ms
2022-05-03T08:55:01 | INFO | mmf.trainers.callbacks.logistics : progress: 2500/22000, train/hateful_memes/cross_entropy: 0.3286, train/hateful_memes/cross_entropy/avg: 0.4173, train/total_loss: 0.3286, train/total_loss/avg: 0.4173, max mem: 11667.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 419ms, time_since_start: 24m 02s 679ms, eta: 02h 59m 52s 232ms
2022-05-03T08:55:56 | INFO | mmf.trainers.callbacks.logistics : progress: 2600/22000, train/hateful_memes/cross_entropy: 0.2769, train/hateful_memes/cross_entropy/avg: 0.4016, train/total_loss: 0.2769, train/total_loss/avg: 0.4016, max mem: 11667.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 466ms, time_since_start: 24m 57s 145ms, eta: 02h 59m 06s 045ms
2022-05-03T08:56:51 | INFO | mmf.trainers.callbacks.logistics : progress: 2700/22000, train/hateful_memes/cross_entropy: 0.2236, train/hateful_memes/cross_entropy/avg: 0.3875, train/total_loss: 0.2236, train/total_loss/avg: 0.3875, max mem: 11667.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 761ms, time_since_start: 25m 51s 907ms, eta: 02h 59m 08s 708ms
2022-05-03T08:57:45 | INFO | mmf.trainers.callbacks.logistics : progress: 2800/22000, train/hateful_memes/cross_entropy: 0.1939, train/hateful_memes/cross_entropy/avg: 0.3782, train/total_loss: 0.1939, train/total_loss/avg: 0.3782, max mem: 11667.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 504ms, time_since_start: 26m 46s 411ms, eta: 02h 57m 22s 714ms
2022-05-03T08:58:40 | INFO | mmf.trainers.callbacks.logistics : progress: 2900/22000, train/hateful_memes/cross_entropy: 0.1476, train/hateful_memes/cross_entropy/avg: 0.3669, train/total_loss: 0.1476, train/total_loss/avg: 0.3669, max mem: 11667.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 426ms, time_since_start: 27m 40s 838ms, eta: 02h 56m 12s 204ms
2022-05-03T08:59:34 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T08:59:34 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T08:59:40 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T08:59:49 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T08:59:49 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, train/hateful_memes/cross_entropy: 0.1270, train/hateful_memes/cross_entropy/avg: 0.3550, train/total_loss: 0.1270, train/total_loss/avg: 0.3550, max mem: 11667.0, experiment: run, epoch: 12, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00001, ups: 1.45, time: 01m 09s 409ms, time_since_start: 28m 50s 247ms, eta: 03h 43m 31s 991ms
2022-05-03T08:59:49 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T08:59:49 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T08:59:52 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T08:59:52 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T08:59:53 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T08:59:59 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-03T09:00:08 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:00:16 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:00:16 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, val/hateful_memes/cross_entropy: 2.0143, val/total_loss: 2.0143, val/hateful_memes/accuracy: 0.6315, val/hateful_memes/binary_f1: 0.2657, val/hateful_memes/roc_auc: 0.6036, num_updates: 3000, epoch: 12, iterations: 3000, max_updates: 22000, val_time: 27s 459ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.603577
2022-05-03T09:01:12 | INFO | mmf.trainers.callbacks.logistics : progress: 3100/22000, train/hateful_memes/cross_entropy: 0.1239, train/hateful_memes/cross_entropy/avg: 0.3444, train/total_loss: 0.1239, train/total_loss/avg: 0.3444, max mem: 11667.0, experiment: run, epoch: 12, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 103ms, time_since_start: 30m 12s 812ms, eta: 02h 56m 31s 611ms
2022-05-03T09:02:07 | INFO | mmf.trainers.callbacks.logistics : progress: 3200/22000, train/hateful_memes/cross_entropy: 0.1117, train/hateful_memes/cross_entropy/avg: 0.3347, train/total_loss: 0.1117, train/total_loss/avg: 0.3347, max mem: 11667.0, experiment: run, epoch: 13, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 068ms, time_since_start: 31m 07s 880ms, eta: 02h 55m 28s 863ms
2022-05-03T09:03:01 | INFO | mmf.trainers.callbacks.logistics : progress: 3300/22000, train/hateful_memes/cross_entropy: 0.1088, train/hateful_memes/cross_entropy/avg: 0.3253, train/total_loss: 0.1088, train/total_loss/avg: 0.3253, max mem: 11667.0, experiment: run, epoch: 13, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 443ms, time_since_start: 32m 02s 323ms, eta: 02h 52m 33s 930ms
2022-05-03T09:03:55 | INFO | mmf.trainers.callbacks.logistics : progress: 3400/22000, train/hateful_memes/cross_entropy: 0.0860, train/hateful_memes/cross_entropy/avg: 0.3162, train/total_loss: 0.0860, train/total_loss/avg: 0.3162, max mem: 11667.0, experiment: run, epoch: 13, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 371ms, time_since_start: 32m 56s 695ms, eta: 02h 51m 25s 049ms
2022-05-03T09:04:50 | INFO | mmf.trainers.callbacks.logistics : progress: 3500/22000, train/hateful_memes/cross_entropy: 0.0559, train/hateful_memes/cross_entropy/avg: 0.3072, train/total_loss: 0.0559, train/total_loss/avg: 0.3072, max mem: 11667.0, experiment: run, epoch: 14, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 839ms, time_since_start: 33m 51s 534ms, eta: 02h 51m 57s 705ms
2022-05-03T09:05:45 | INFO | mmf.trainers.callbacks.logistics : progress: 3600/22000, train/hateful_memes/cross_entropy: 0.0514, train/hateful_memes/cross_entropy/avg: 0.2988, train/total_loss: 0.0514, train/total_loss/avg: 0.2988, max mem: 11667.0, experiment: run, epoch: 14, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 469ms, time_since_start: 34m 46s 004ms, eta: 02h 49m 52s 796ms
2022-05-03T09:06:39 | INFO | mmf.trainers.callbacks.logistics : progress: 3700/22000, train/hateful_memes/cross_entropy: 0.0342, train/hateful_memes/cross_entropy/avg: 0.2908, train/total_loss: 0.0342, train/total_loss/avg: 0.2908, max mem: 11667.0, experiment: run, epoch: 14, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 455ms, time_since_start: 35m 40s 460ms, eta: 02h 48m 54s 796ms
2022-05-03T09:07:34 | INFO | mmf.trainers.callbacks.logistics : progress: 3800/22000, train/hateful_memes/cross_entropy: 0.0289, train/hateful_memes/cross_entropy/avg: 0.2833, train/total_loss: 0.0289, train/total_loss/avg: 0.2833, max mem: 11667.0, experiment: run, epoch: 15, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 763ms, time_since_start: 36m 35s 223ms, eta: 02h 48m 56s 351ms
2022-05-03T09:08:29 | INFO | mmf.trainers.callbacks.logistics : progress: 3900/22000, train/hateful_memes/cross_entropy: 0.0289, train/hateful_memes/cross_entropy/avg: 0.2774, train/total_loss: 0.0289, train/total_loss/avg: 0.2774, max mem: 11667.0, experiment: run, epoch: 15, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 495ms, time_since_start: 37m 29s 718ms, eta: 02h 47m 11s 342ms
2022-05-03T09:09:23 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T09:09:23 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:09:30 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:09:37 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:09:37 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, train/hateful_memes/cross_entropy: 0.0289, train/hateful_memes/cross_entropy/avg: 0.2713, train/total_loss: 0.0289, train/total_loss/avg: 0.2713, max mem: 11667.0, experiment: run, epoch: 16, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00001, ups: 1.47, time: 01m 08s 552ms, time_since_start: 38m 38s 271ms, eta: 03h 29m 09s 258ms
2022-05-03T09:09:37 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T09:09:37 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T09:09:41 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T09:09:41 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T09:09:41 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:09:47 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-03T09:09:55 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:10:05 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:10:05 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, val/hateful_memes/cross_entropy: 2.0545, val/total_loss: 2.0545, val/hateful_memes/accuracy: 0.6407, val/hateful_memes/binary_f1: 0.2707, val/hateful_memes/roc_auc: 0.6182, num_updates: 4000, epoch: 16, iterations: 4000, max_updates: 22000, val_time: 27s 856ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.618191
2022-05-03T09:11:00 | INFO | mmf.trainers.callbacks.logistics : progress: 4100/22000, train/hateful_memes/cross_entropy: 0.0245, train/hateful_memes/cross_entropy/avg: 0.2648, train/total_loss: 0.0245, train/total_loss/avg: 0.2648, max mem: 11667.0, experiment: run, epoch: 16, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 160ms, time_since_start: 40m 01s 290ms, eta: 02h 47m 21s 626ms
2022-05-03T09:11:55 | INFO | mmf.trainers.callbacks.logistics : progress: 4200/22000, train/hateful_memes/cross_entropy: 0.0245, train/hateful_memes/cross_entropy/avg: 0.2600, train/total_loss: 0.0245, train/total_loss/avg: 0.2600, max mem: 11667.0, experiment: run, epoch: 16, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 501ms, time_since_start: 40m 55s 791ms, eta: 02h 44m 26s 225ms
2022-05-03T09:12:49 | INFO | mmf.trainers.callbacks.logistics : progress: 4300/22000, train/hateful_memes/cross_entropy: 0.0245, train/hateful_memes/cross_entropy/avg: 0.2554, train/total_loss: 0.0245, train/total_loss/avg: 0.2554, max mem: 11667.0, experiment: run, epoch: 17, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 855ms, time_since_start: 41m 50s 646ms, eta: 02h 44m 34s 399ms
2022-05-03T09:13:44 | INFO | mmf.trainers.callbacks.logistics : progress: 4400/22000, train/hateful_memes/cross_entropy: 0.0199, train/hateful_memes/cross_entropy/avg: 0.2496, train/total_loss: 0.0199, train/total_loss/avg: 0.2496, max mem: 11667.0, experiment: run, epoch: 17, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 452ms, time_since_start: 42m 45s 099ms, eta: 02h 42m 26s 518ms
2022-05-03T09:14:38 | INFO | mmf.trainers.callbacks.logistics : progress: 4500/22000, train/hateful_memes/cross_entropy: 0.0199, train/hateful_memes/cross_entropy/avg: 0.2464, train/total_loss: 0.0199, train/total_loss/avg: 0.2464, max mem: 11667.0, experiment: run, epoch: 17, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 446ms, time_since_start: 43m 39s 545ms, eta: 02h 41m 30s 191ms
2022-05-03T09:15:33 | INFO | mmf.trainers.callbacks.logistics : progress: 4600/22000, train/hateful_memes/cross_entropy: 0.0245, train/hateful_memes/cross_entropy/avg: 0.2416, train/total_loss: 0.0245, train/total_loss/avg: 0.2416, max mem: 11667.0, experiment: run, epoch: 18, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 823ms, time_since_start: 44m 34s 369ms, eta: 02h 41m 41s 391ms
2022-05-03T09:16:28 | INFO | mmf.trainers.callbacks.logistics : progress: 4700/22000, train/hateful_memes/cross_entropy: 0.0273, train/hateful_memes/cross_entropy/avg: 0.2374, train/total_loss: 0.0273, train/total_loss/avg: 0.2374, max mem: 11667.0, experiment: run, epoch: 18, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 447ms, time_since_start: 45m 28s 817ms, eta: 02h 39m 39s 620ms
2022-05-03T09:17:22 | INFO | mmf.trainers.callbacks.logistics : progress: 4800/22000, train/hateful_memes/cross_entropy: 0.0245, train/hateful_memes/cross_entropy/avg: 0.2325, train/total_loss: 0.0245, train/total_loss/avg: 0.2325, max mem: 11667.0, experiment: run, epoch: 19, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 705ms, time_since_start: 46m 23s 522ms, eta: 02h 39m 29s 361ms
2022-05-03T09:18:17 | INFO | mmf.trainers.callbacks.logistics : progress: 4900/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.2280, train/total_loss: 0.0141, train/total_loss/avg: 0.2280, max mem: 11667.0, experiment: run, epoch: 19, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 229ms, time_since_start: 47m 17s 752ms, eta: 02h 37m 10s 969ms
2022-05-03T09:19:11 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T09:19:11 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:19:17 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:19:28 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:19:28 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.2234, train/total_loss: 0.0141, train/total_loss/avg: 0.2234, max mem: 11667.0, experiment: run, epoch: 19, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00001, ups: 1.41, time: 01m 11s 894ms, time_since_start: 48m 29s 647ms, eta: 03h 27m 09s 893ms
2022-05-03T09:19:28 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T09:19:28 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T09:19:32 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T09:19:32 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T09:19:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:19:40 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:19:53 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:19:53 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, val/hateful_memes/cross_entropy: 2.1521, val/total_loss: 2.1521, val/hateful_memes/accuracy: 0.6370, val/hateful_memes/binary_f1: 0.3636, val/hateful_memes/roc_auc: 0.6062, num_updates: 5000, epoch: 19, iterations: 5000, max_updates: 22000, val_time: 24s 820ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.618191
2022-05-03T09:20:49 | INFO | mmf.trainers.callbacks.logistics : progress: 5100/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.2194, train/total_loss: 0.0141, train/total_loss/avg: 0.2194, max mem: 11667.0, experiment: run, epoch: 20, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 367ms, time_since_start: 49m 49s 837ms, eta: 02h 38m 36s 118ms
2022-05-03T09:21:43 | INFO | mmf.trainers.callbacks.logistics : progress: 5200/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.2159, train/total_loss: 0.0141, train/total_loss/avg: 0.2159, max mem: 11667.0, experiment: run, epoch: 20, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 379ms, time_since_start: 50m 44s 217ms, eta: 02h 34m 51s 139ms
2022-05-03T09:22:37 | INFO | mmf.trainers.callbacks.logistics : progress: 5300/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.2123, train/total_loss: 0.0141, train/total_loss/avg: 0.2123, max mem: 11667.0, experiment: run, epoch: 20, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 405ms, time_since_start: 51m 38s 622ms, eta: 02h 34m 106ms
2022-05-03T09:23:32 | INFO | mmf.trainers.callbacks.logistics : progress: 5400/22000, train/hateful_memes/cross_entropy: 0.0114, train/hateful_memes/cross_entropy/avg: 0.2084, train/total_loss: 0.0114, train/total_loss/avg: 0.2084, max mem: 11667.0, experiment: run, epoch: 21, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 738ms, time_since_start: 52m 33s 360ms, eta: 02h 34m 01s 033ms
2022-05-03T09:24:27 | INFO | mmf.trainers.callbacks.logistics : progress: 5500/22000, train/hateful_memes/cross_entropy: 0.0192, train/hateful_memes/cross_entropy/avg: 0.2074, train/total_loss: 0.0192, train/total_loss/avg: 0.2074, max mem: 11667.0, experiment: run, epoch: 21, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 387ms, time_since_start: 53m 27s 748ms, eta: 02h 32m 06s 519ms
2022-05-03T09:25:21 | INFO | mmf.trainers.callbacks.logistics : progress: 5600/22000, train/hateful_memes/cross_entropy: 0.0244, train/hateful_memes/cross_entropy/avg: 0.2044, train/total_loss: 0.0244, train/total_loss/avg: 0.2044, max mem: 11667.0, experiment: run, epoch: 22, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 814ms, time_since_start: 54m 22s 562ms, eta: 02h 32m 22s 328ms
2022-05-03T09:26:16 | INFO | mmf.trainers.callbacks.logistics : progress: 5700/22000, train/hateful_memes/cross_entropy: 0.0244, train/hateful_memes/cross_entropy/avg: 0.2008, train/total_loss: 0.0244, train/total_loss/avg: 0.2008, max mem: 11667.0, experiment: run, epoch: 22, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 356ms, time_since_start: 55m 16s 919ms, eta: 02h 30m 10s 788ms
2022-05-03T09:27:10 | INFO | mmf.trainers.callbacks.logistics : progress: 5800/22000, train/hateful_memes/cross_entropy: 0.0273, train/hateful_memes/cross_entropy/avg: 0.1979, train/total_loss: 0.0273, train/total_loss/avg: 0.1979, max mem: 11667.0, experiment: run, epoch: 22, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 421ms, time_since_start: 56m 11s 341ms, eta: 02h 29m 26s 240ms
2022-05-03T09:28:05 | INFO | mmf.trainers.callbacks.logistics : progress: 5900/22000, train/hateful_memes/cross_entropy: 0.0244, train/hateful_memes/cross_entropy/avg: 0.1946, train/total_loss: 0.0244, train/total_loss/avg: 0.1946, max mem: 11667.0, experiment: run, epoch: 23, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 748ms, time_since_start: 57m 06s 089ms, eta: 02h 29m 24s 285ms
2022-05-03T09:28:59 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T09:28:59 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:29:08 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:29:15 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:29:15 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, train/hateful_memes/cross_entropy: 0.0244, train/hateful_memes/cross_entropy/avg: 0.1918, train/total_loss: 0.0244, train/total_loss/avg: 0.1918, max mem: 11667.0, experiment: run, epoch: 23, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00001, ups: 1.45, time: 01m 09s 958ms, time_since_start: 58m 16s 048ms, eta: 03h 09m 43s 717ms
2022-05-03T09:29:15 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T09:29:15 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T09:29:18 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T09:29:18 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T09:29:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:29:25 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:29:33 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:29:33 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, val/hateful_memes/cross_entropy: 2.4332, val/total_loss: 2.4332, val/hateful_memes/accuracy: 0.6333, val/hateful_memes/binary_f1: 0.2929, val/hateful_memes/roc_auc: 0.5965, num_updates: 6000, epoch: 23, iterations: 6000, max_updates: 22000, val_time: 18s 168ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.618191
2022-05-03T09:30:28 | INFO | mmf.trainers.callbacks.logistics : progress: 6100/22000, train/hateful_memes/cross_entropy: 0.0244, train/hateful_memes/cross_entropy/avg: 0.1887, train/total_loss: 0.0244, train/total_loss/avg: 0.1887, max mem: 11667.0, experiment: run, epoch: 23, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 987ms, time_since_start: 59m 29s 205ms, eta: 02h 28m 11s 686ms
2022-05-03T09:31:23 | INFO | mmf.trainers.callbacks.logistics : progress: 6200/22000, train/hateful_memes/cross_entropy: 0.0244, train/hateful_memes/cross_entropy/avg: 0.1864, train/total_loss: 0.0244, train/total_loss/avg: 0.1864, max mem: 11667.0, experiment: run, epoch: 24, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 855ms, time_since_start: 01h 24s 061ms, eta: 02h 26m 54s 537ms
2022-05-03T09:32:17 | INFO | mmf.trainers.callbacks.logistics : progress: 6300/22000, train/hateful_memes/cross_entropy: 0.0192, train/hateful_memes/cross_entropy/avg: 0.1836, train/total_loss: 0.0192, train/total_loss/avg: 0.1836, max mem: 11667.0, experiment: run, epoch: 24, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 300ms, time_since_start: 01h 01m 18s 362ms, eta: 02h 24m 30s 156ms
2022-05-03T09:33:12 | INFO | mmf.trainers.callbacks.logistics : progress: 6400/22000, train/hateful_memes/cross_entropy: 0.0192, train/hateful_memes/cross_entropy/avg: 0.1807, train/total_loss: 0.0192, train/total_loss/avg: 0.1807, max mem: 11667.0, experiment: run, epoch: 25, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 752ms, time_since_start: 01h 02m 13s 115ms, eta: 02h 24m 46s 654ms
2022-05-03T09:34:06 | INFO | mmf.trainers.callbacks.logistics : progress: 6500/22000, train/hateful_memes/cross_entropy: 0.0114, train/hateful_memes/cross_entropy/avg: 0.1780, train/total_loss: 0.0114, train/total_loss/avg: 0.1780, max mem: 11667.0, experiment: run, epoch: 25, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 276ms, time_since_start: 01h 03m 07s 391ms, eta: 02h 22m 35s 801ms
2022-05-03T09:35:01 | INFO | mmf.trainers.callbacks.logistics : progress: 6600/22000, train/hateful_memes/cross_entropy: 0.0114, train/hateful_memes/cross_entropy/avg: 0.1769, train/total_loss: 0.0114, train/total_loss/avg: 0.1769, max mem: 11667.0, experiment: run, epoch: 25, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 346ms, time_since_start: 01h 04m 01s 738ms, eta: 02h 21m 51s 689ms
2022-05-03T09:35:55 | INFO | mmf.trainers.callbacks.logistics : progress: 6700/22000, train/hateful_memes/cross_entropy: 0.0114, train/hateful_memes/cross_entropy/avg: 0.1760, train/total_loss: 0.0114, train/total_loss/avg: 0.1760, max mem: 11667.0, experiment: run, epoch: 26, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 715ms, time_since_start: 01h 04m 56s 453ms, eta: 02h 21m 53s 747ms
2022-05-03T09:36:50 | INFO | mmf.trainers.callbacks.logistics : progress: 6800/22000, train/hateful_memes/cross_entropy: 0.0114, train/hateful_memes/cross_entropy/avg: 0.1734, train/total_loss: 0.0114, train/total_loss/avg: 0.1734, max mem: 11667.0, experiment: run, epoch: 26, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 451ms, time_since_start: 01h 05m 50s 904ms, eta: 02h 20m 17s 256ms
2022-05-03T09:37:44 | INFO | mmf.trainers.callbacks.logistics : progress: 6900/22000, train/hateful_memes/cross_entropy: 0.0089, train/hateful_memes/cross_entropy/avg: 0.1710, train/total_loss: 0.0089, train/total_loss/avg: 0.1710, max mem: 11667.0, experiment: run, epoch: 26, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 499ms, time_since_start: 01h 06m 45s 404ms, eta: 02h 19m 29s 365ms
2022-05-03T09:38:39 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T09:38:39 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:38:45 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:38:53 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:38:53 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, train/hateful_memes/cross_entropy: 0.0089, train/hateful_memes/cross_entropy/avg: 0.1685, train/total_loss: 0.0089, train/total_loss/avg: 0.1685, max mem: 11667.0, experiment: run, epoch: 27, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00001, ups: 1.45, time: 01m 09s 032ms, time_since_start: 01h 07m 54s 436ms, eta: 02h 55m 30s 895ms
2022-05-03T09:38:53 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T09:38:53 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T09:38:57 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T09:38:57 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T09:38:57 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:39:03 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2022-05-03T09:39:15 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:39:25 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:39:25 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, val/hateful_memes/cross_entropy: 2.5168, val/total_loss: 2.5168, val/hateful_memes/accuracy: 0.6389, val/hateful_memes/binary_f1: 0.2909, val/hateful_memes/roc_auc: 0.6290, num_updates: 7000, epoch: 27, iterations: 7000, max_updates: 22000, val_time: 31s 709ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.629033
2022-05-03T09:40:20 | INFO | mmf.trainers.callbacks.logistics : progress: 7100/22000, train/hateful_memes/cross_entropy: 0.0056, train/hateful_memes/cross_entropy/avg: 0.1662, train/total_loss: 0.0056, train/total_loss/avg: 0.1662, max mem: 11667.0, experiment: run, epoch: 27, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 116ms, time_since_start: 01h 09m 21s 265ms, eta: 02h 19m 12s 013ms
2022-05-03T09:41:15 | INFO | mmf.trainers.callbacks.logistics : progress: 7200/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.1639, train/total_loss: 0.0031, train/total_loss/avg: 0.1639, max mem: 11667.0, experiment: run, epoch: 28, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 956ms, time_since_start: 01h 10m 16s 221ms, eta: 02h 17m 51s 879ms
2022-05-03T09:42:09 | INFO | mmf.trainers.callbacks.logistics : progress: 7300/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.1617, train/total_loss: 0.0025, train/total_loss/avg: 0.1617, max mem: 11667.0, experiment: run, epoch: 28, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 292ms, time_since_start: 01h 11m 10s 514ms, eta: 02h 15m 16s 624ms
2022-05-03T09:43:04 | INFO | mmf.trainers.callbacks.logistics : progress: 7400/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.1595, train/total_loss: 0.0025, train/total_loss/avg: 0.1595, max mem: 11667.0, experiment: run, epoch: 28, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 314ms, time_since_start: 01h 12m 04s 828ms, eta: 02h 14m 24s 713ms
2022-05-03T09:43:58 | INFO | mmf.trainers.callbacks.logistics : progress: 7500/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.1574, train/total_loss: 0.0025, train/total_loss/avg: 0.1574, max mem: 11667.0, experiment: run, epoch: 29, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 715ms, time_since_start: 01h 12m 59s 543ms, eta: 02h 14m 28s 599ms
2022-05-03T09:44:53 | INFO | mmf.trainers.callbacks.logistics : progress: 7600/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1554, train/total_loss: 0.0019, train/total_loss/avg: 0.1554, max mem: 11667.0, experiment: run, epoch: 29, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 227ms, time_since_start: 01h 13m 53s 771ms, eta: 02h 12m 21s 547ms
2022-05-03T09:45:47 | INFO | mmf.trainers.callbacks.logistics : progress: 7700/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1534, train/total_loss: 0.0019, train/total_loss/avg: 0.1534, max mem: 11667.0, experiment: run, epoch: 29, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 316ms, time_since_start: 01h 14m 48s 087ms, eta: 02h 11m 39s 256ms
2022-05-03T09:46:42 | INFO | mmf.trainers.callbacks.logistics : progress: 7800/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.1515, train/total_loss: 0.0019, train/total_loss/avg: 0.1515, max mem: 11667.0, experiment: run, epoch: 30, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 851ms, time_since_start: 01h 15m 42s 939ms, eta: 02h 12m 01s 391ms
2022-05-03T09:47:36 | INFO | mmf.trainers.callbacks.logistics : progress: 7900/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.1495, train/total_loss: 0.0015, train/total_loss/avg: 0.1495, max mem: 11667.0, experiment: run, epoch: 30, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 443ms, time_since_start: 01h 16m 37s 383ms, eta: 02h 10m 07s 042ms
2022-05-03T09:48:31 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T09:48:31 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:48:39 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:48:49 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:48:49 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1477, train/total_loss: 0.0013, train/total_loss/avg: 0.1477, max mem: 11667.0, experiment: run, epoch: 31, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00001, ups: 1.37, time: 01m 13s 169ms, time_since_start: 01h 17m 50s 553ms, eta: 02h 53m 37s 913ms
2022-05-03T09:48:49 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T09:48:49 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T09:48:53 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T09:48:53 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T09:48:53 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:49:03 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:49:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:49:13 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, val/hateful_memes/cross_entropy: 2.6070, val/total_loss: 2.6070, val/hateful_memes/accuracy: 0.6389, val/hateful_memes/binary_f1: 0.3478, val/hateful_memes/roc_auc: 0.6149, num_updates: 8000, epoch: 31, iterations: 8000, max_updates: 22000, val_time: 23s 243ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.629033
2022-05-03T09:50:08 | INFO | mmf.trainers.callbacks.logistics : progress: 8100/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1481, train/total_loss: 0.0013, train/total_loss/avg: 0.1481, max mem: 11667.0, experiment: run, epoch: 31, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 973ms, time_since_start: 01h 19m 08s 771ms, eta: 02h 09m 31s 180ms
2022-05-03T09:51:02 | INFO | mmf.trainers.callbacks.logistics : progress: 8200/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1463, train/total_loss: 0.0013, train/total_loss/avg: 0.1463, max mem: 11667.0, experiment: run, epoch: 31, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 419ms, time_since_start: 01h 20m 03s 191ms, eta: 02h 07m 17s 554ms
2022-05-03T09:51:57 | INFO | mmf.trainers.callbacks.logistics : progress: 8300/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1446, train/total_loss: 0.0013, train/total_loss/avg: 0.1446, max mem: 11667.0, experiment: run, epoch: 32, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 724ms, time_since_start: 01h 20m 57s 915ms, eta: 02h 07m 04s 663ms
2022-05-03T09:52:51 | INFO | mmf.trainers.callbacks.logistics : progress: 8400/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1429, train/total_loss: 0.0013, train/total_loss/avg: 0.1429, max mem: 11667.0, experiment: run, epoch: 32, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 303ms, time_since_start: 01h 21m 52s 218ms, eta: 02h 05m 10s 774ms
2022-05-03T09:53:45 | INFO | mmf.trainers.callbacks.logistics : progress: 8500/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1412, train/total_loss: 0.0013, train/total_loss/avg: 0.1412, max mem: 11667.0, experiment: run, epoch: 32, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 443ms, time_since_start: 01h 22m 46s 662ms, eta: 02h 04m 34s 890ms
2022-05-03T09:54:40 | INFO | mmf.trainers.callbacks.logistics : progress: 8600/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1396, train/total_loss: 0.0013, train/total_loss/avg: 0.1396, max mem: 11667.0, experiment: run, epoch: 33, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 599ms, time_since_start: 01h 23m 41s 262ms, eta: 02h 04m 731ms
2022-05-03T09:55:34 | INFO | mmf.trainers.callbacks.logistics : progress: 8700/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1382, train/total_loss: 0.0013, train/total_loss/avg: 0.1382, max mem: 11667.0, experiment: run, epoch: 33, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 301ms, time_since_start: 01h 24m 35s 563ms, eta: 02h 02m 24s 819ms
2022-05-03T09:56:29 | INFO | mmf.trainers.callbacks.logistics : progress: 8800/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1367, train/total_loss: 0.0013, train/total_loss/avg: 0.1367, max mem: 11667.0, experiment: run, epoch: 34, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 795ms, time_since_start: 01h 25m 30s 359ms, eta: 02h 02m 36s 023ms
2022-05-03T09:57:24 | INFO | mmf.trainers.callbacks.logistics : progress: 8900/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1352, train/total_loss: 0.0013, train/total_loss/avg: 0.1352, max mem: 11667.0, experiment: run, epoch: 34, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 409ms, time_since_start: 01h 26m 24s 768ms, eta: 02h 48s 786ms
2022-05-03T09:58:18 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T09:58:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:58:24 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:58:34 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:58:34 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1337, train/total_loss: 0.0014, train/total_loss/avg: 0.1337, max mem: 11667.0, experiment: run, epoch: 34, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00001, ups: 1.45, time: 01m 09s 966ms, time_since_start: 01h 27m 34s 734ms, eta: 02h 34m 10s 223ms
2022-05-03T09:58:34 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T09:58:34 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T09:58:37 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T09:58:37 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T09:58:37 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T09:58:44 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T09:58:52 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T09:58:52 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, val/hateful_memes/cross_entropy: 2.7957, val/total_loss: 2.7957, val/hateful_memes/accuracy: 0.6500, val/hateful_memes/binary_f1: 0.3274, val/hateful_memes/roc_auc: 0.6079, num_updates: 9000, epoch: 34, iterations: 9000, max_updates: 22000, val_time: 18s 586ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.629033
2022-05-03T09:59:48 | INFO | mmf.trainers.callbacks.logistics : progress: 9100/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1322, train/total_loss: 0.0013, train/total_loss/avg: 0.1322, max mem: 11667.0, experiment: run, epoch: 35, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 720ms, time_since_start: 01h 28m 49s 042ms, eta: 02h 01m 50s 088ms
2022-05-03T10:00:42 | INFO | mmf.trainers.callbacks.logistics : progress: 9200/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1312, train/total_loss: 0.0013, train/total_loss/avg: 0.1312, max mem: 11667.0, experiment: run, epoch: 35, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 349ms, time_since_start: 01h 29m 43s 392ms, eta: 01h 57m 55s 023ms
2022-05-03T10:01:37 | INFO | mmf.trainers.callbacks.logistics : progress: 9300/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1298, train/total_loss: 0.0013, train/total_loss/avg: 0.1298, max mem: 11667.0, experiment: run, epoch: 35, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 422ms, time_since_start: 01h 30m 37s 814ms, eta: 01h 57m 09s 133ms
2022-05-03T10:02:31 | INFO | mmf.trainers.callbacks.logistics : progress: 9400/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1285, train/total_loss: 0.0013, train/total_loss/avg: 0.1285, max mem: 11667.0, experiment: run, epoch: 36, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 779ms, time_since_start: 01h 31m 32s 594ms, eta: 01h 56m 59s 581ms
2022-05-03T10:03:26 | INFO | mmf.trainers.callbacks.logistics : progress: 9500/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1271, train/total_loss: 0.0013, train/total_loss/avg: 0.1271, max mem: 11667.0, experiment: run, epoch: 36, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 325ms, time_since_start: 01h 32m 26s 919ms, eta: 01h 55m 06s 095ms
2022-05-03T10:04:20 | INFO | mmf.trainers.callbacks.logistics : progress: 9600/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1258, train/total_loss: 0.0013, train/total_loss/avg: 0.1258, max mem: 11667.0, experiment: run, epoch: 37, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 752ms, time_since_start: 01h 33m 21s 672ms, eta: 01h 55m 04s 787ms
2022-05-03T10:05:15 | INFO | mmf.trainers.callbacks.logistics : progress: 9700/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1246, train/total_loss: 0.0013, train/total_loss/avg: 0.1246, max mem: 11667.0, experiment: run, epoch: 37, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 301ms, time_since_start: 01h 34m 15s 973ms, eta: 01h 53m 12s 586ms
2022-05-03T10:06:09 | INFO | mmf.trainers.callbacks.logistics : progress: 9800/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.1233, train/total_loss: 0.0013, train/total_loss/avg: 0.1233, max mem: 11667.0, experiment: run, epoch: 37, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 463ms, time_since_start: 01h 35m 10s 437ms, eta: 01h 52m 37s 487ms
2022-05-03T10:07:04 | INFO | mmf.trainers.callbacks.logistics : progress: 9900/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1221, train/total_loss: 0.0014, train/total_loss/avg: 0.1221, max mem: 11667.0, experiment: run, epoch: 38, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 715ms, time_since_start: 01h 36m 05s 153ms, eta: 01h 52m 13s 178ms
2022-05-03T10:07:58 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T10:07:58 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T10:08:05 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T10:08:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T10:08:13 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1209, train/total_loss: 0.0014, train/total_loss/avg: 0.1209, max mem: 11667.0, experiment: run, epoch: 38, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00001, ups: 1.45, time: 01m 09s 164ms, time_since_start: 01h 37m 14s 317ms, eta: 02h 20m 40s 832ms
2022-05-03T10:08:13 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T10:08:13 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T10:08:17 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T10:08:17 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T10:08:17 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T10:08:23 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T10:08:35 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T10:08:35 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, val/hateful_memes/cross_entropy: 2.8361, val/total_loss: 2.8361, val/hateful_memes/accuracy: 0.6370, val/hateful_memes/binary_f1: 0.3194, val/hateful_memes/roc_auc: 0.6076, num_updates: 10000, epoch: 38, iterations: 10000, max_updates: 22000, val_time: 22s 311ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.629033
2022-05-03T10:09:31 | INFO | mmf.trainers.callbacks.logistics : progress: 10100/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1197, train/total_loss: 0.0014, train/total_loss/avg: 0.1197, max mem: 11667.0, experiment: run, epoch: 38, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 186ms, time_since_start: 01h 38m 31s 817ms, eta: 01h 51m 18s 870ms
2022-05-03T10:10:25 | INFO | mmf.trainers.callbacks.logistics : progress: 10200/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1186, train/total_loss: 0.0014, train/total_loss/avg: 0.1186, max mem: 11667.0, experiment: run, epoch: 39, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 666ms, time_since_start: 01h 39m 26s 483ms, eta: 01h 49m 20s 340ms
2022-05-03T10:11:20 | INFO | mmf.trainers.callbacks.logistics : progress: 10300/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1192, train/total_loss: 0.0014, train/total_loss/avg: 0.1192, max mem: 11667.0, experiment: run, epoch: 39, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 343ms, time_since_start: 01h 40m 20s 827ms, eta: 01h 47m 46s 314ms
2022-05-03T10:12:15 | INFO | mmf.trainers.callbacks.logistics : progress: 10400/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1182, train/total_loss: 0.0014, train/total_loss/avg: 0.1182, max mem: 11667.0, experiment: run, epoch: 40, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 922ms, time_since_start: 01h 41m 15s 750ms, eta: 01h 47m 59s 306ms
2022-05-03T10:13:09 | INFO | mmf.trainers.callbacks.logistics : progress: 10500/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1171, train/total_loss: 0.0014, train/total_loss/avg: 0.1171, max mem: 11667.0, experiment: run, epoch: 40, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 420ms, time_since_start: 01h 42m 10s 171ms, eta: 01h 46m 04s 783ms
2022-05-03T10:14:03 | INFO | mmf.trainers.callbacks.logistics : progress: 10600/22000, train/hateful_memes/cross_entropy: 0.0014, train/hateful_memes/cross_entropy/avg: 0.1160, train/total_loss: 0.0014, train/total_loss/avg: 0.1160, max mem: 11667.0, experiment: run, epoch: 40, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 423ms, time_since_start: 01h 43m 04s 594ms, eta: 01h 45m 09s 716ms
2022-05-03T10:14:58 | INFO | mmf.trainers.callbacks.logistics : progress: 10700/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1149, train/total_loss: 0.0010, train/total_loss/avg: 0.1149, max mem: 11667.0, experiment: run, epoch: 41, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 687ms, time_since_start: 01h 43m 59s 281ms, eta: 01h 44m 44s 737ms
2022-05-03T10:15:52 | INFO | mmf.trainers.callbacks.logistics : progress: 10800/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.1139, train/total_loss: 0.0010, train/total_loss/avg: 0.1139, max mem: 11667.0, experiment: run, epoch: 41, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 390ms, time_since_start: 01h 44m 53s 671ms, eta: 01h 43m 15s 246ms
2022-05-03T10:16:47 | INFO | mmf.trainers.callbacks.logistics : progress: 10900/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.1128, train/total_loss: 0.0009, train/total_loss/avg: 0.1128, max mem: 11667.0, experiment: run, epoch: 41, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 382ms, time_since_start: 01h 45m 48s 053ms, eta: 01h 42m 19s 039ms
2022-05-03T10:17:42 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T10:17:42 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T10:17:51 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T10:18:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T10:18:00 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1118, train/total_loss: 0.0006, train/total_loss/avg: 0.1118, max mem: 11667.0, experiment: run, epoch: 42, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00001, ups: 1.37, time: 01m 13s 170ms, time_since_start: 01h 47m 01s 223ms, eta: 02h 16m 25s 531ms
2022-05-03T10:18:01 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T10:18:01 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T10:18:04 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T10:18:04 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T10:18:04 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T10:18:14 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T10:18:24 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T10:18:24 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, val/hateful_memes/cross_entropy: 2.9954, val/total_loss: 2.9954, val/hateful_memes/accuracy: 0.6426, val/hateful_memes/binary_f1: 0.3458, val/hateful_memes/roc_auc: 0.6000, num_updates: 11000, epoch: 42, iterations: 11000, max_updates: 22000, val_time: 23s 605ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.629033
2022-05-03T10:19:19 | INFO | mmf.trainers.callbacks.logistics : progress: 11100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.1108, train/total_loss: 0.0006, train/total_loss/avg: 0.1108, max mem: 11667.0, experiment: run, epoch: 42, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00001, ups: 1.82, time: 55s 098ms, time_since_start: 01h 48m 20s 535ms, eta: 01h 41m 47s 861ms
2022-05-03T10:20:14 | INFO | mmf.trainers.callbacks.logistics : progress: 11200/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.1098, train/total_loss: 0.0005, train/total_loss/avg: 0.1098, max mem: 11667.0, experiment: run, epoch: 43, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 851ms, time_since_start: 01h 49m 15s 386ms, eta: 01h 40m 24s 620ms
2022-05-03T10:21:09 | INFO | mmf.trainers.callbacks.logistics : progress: 11300/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.1089, train/total_loss: 0.0004, train/total_loss/avg: 0.1089, max mem: 11667.0, experiment: run, epoch: 43, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 511ms, time_since_start: 01h 50m 09s 898ms, eta: 01h 38m 51s 933ms
2022-05-03T10:22:03 | INFO | mmf.trainers.callbacks.logistics : progress: 11400/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.1079, train/total_loss: 0.0003, train/total_loss/avg: 0.1079, max mem: 11667.0, experiment: run, epoch: 43, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 395ms, time_since_start: 01h 51m 04s 293ms, eta: 01h 37m 43s 948ms
2022-05-03T10:22:58 | INFO | mmf.trainers.callbacks.logistics : progress: 11500/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.1070, train/total_loss: 0.0003, train/total_loss/avg: 0.1070, max mem: 11667.0, experiment: run, epoch: 44, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 815ms, time_since_start: 01h 51m 59s 109ms, eta: 01h 37m 33s 522ms
2022-05-03T10:23:52 | INFO | mmf.trainers.callbacks.logistics : progress: 11600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.1060, train/total_loss: 0.0003, train/total_loss/avg: 0.1060, max mem: 11667.0, experiment: run, epoch: 44, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 517ms, time_since_start: 01h 52m 53s 627ms, eta: 01h 36m 06s 251ms
2022-05-03T10:24:47 | INFO | mmf.trainers.callbacks.logistics : progress: 11700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1051, train/total_loss: 0.0002, train/total_loss/avg: 0.1051, max mem: 11667.0, experiment: run, epoch: 44, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 412ms, time_since_start: 01h 53m 48s 040ms, eta: 01h 34m 59s 808ms
2022-05-03T10:25:42 | INFO | mmf.trainers.callbacks.logistics : progress: 11800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1042, train/total_loss: 0.0002, train/total_loss/avg: 0.1042, max mem: 11667.0, experiment: run, epoch: 45, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 673ms, time_since_start: 01h 54m 42s 714ms, eta: 01h 34m 31s 554ms
2022-05-03T10:26:36 | INFO | mmf.trainers.callbacks.logistics : progress: 11900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1034, train/total_loss: 0.0002, train/total_loss/avg: 0.1034, max mem: 11667.0, experiment: run, epoch: 45, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00001, ups: 1.85, time: 54s 348ms, time_since_start: 01h 55m 37s 063ms, eta: 01h 33m 02s 559ms
2022-05-03T10:27:31 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T10:27:31 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T10:27:39 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T10:27:49 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T10:27:49 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1025, train/total_loss: 0.0002, train/total_loss/avg: 0.1025, max mem: 11667.0, experiment: run, epoch: 46, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00001, ups: 1.39, time: 01m 12s 716ms, time_since_start: 01h 56m 49s 780ms, eta: 02h 03m 15s 273ms
2022-05-03T10:27:49 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T10:27:49 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T10:27:52 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T10:27:52 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T10:27:52 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, val/hateful_memes/cross_entropy: 3.0057, val/total_loss: 3.0057, val/hateful_memes/accuracy: 0.6444, val/hateful_memes/binary_f1: 0.3287, val/hateful_memes/roc_auc: 0.6116, num_updates: 12000, epoch: 46, iterations: 12000, max_updates: 22000, val_time: 03s 618ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.629033
2022-05-03T10:28:48 | INFO | mmf.trainers.callbacks.logistics : progress: 12100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1017, train/total_loss: 0.0002, train/total_loss/avg: 0.1017, max mem: 11667.0, experiment: run, epoch: 46, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0., ups: 1.82, time: 55s 207ms, time_since_start: 01h 57m 48s 753ms, eta: 01h 32m 38s 506ms
2022-05-03T10:29:42 | INFO | mmf.trainers.callbacks.logistics : progress: 12200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1008, train/total_loss: 0.0002, train/total_loss/avg: 0.1008, max mem: 11667.0, experiment: run, epoch: 46, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 664ms, time_since_start: 01h 58m 43s 417ms, eta: 01h 30m 48s 156ms
2022-05-03T10:30:37 | INFO | mmf.trainers.callbacks.logistics : progress: 12300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.1000, train/total_loss: 0.0002, train/total_loss/avg: 0.1000, max mem: 11667.0, experiment: run, epoch: 47, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 675ms, time_since_start: 01h 59m 38s 093ms, eta: 01h 29m 53s 709ms
2022-05-03T10:31:31 | INFO | mmf.trainers.callbacks.logistics : progress: 12400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0992, train/total_loss: 0.0001, train/total_loss/avg: 0.0992, max mem: 11667.0, experiment: run, epoch: 47, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 372ms, time_since_start: 02h 32s 466ms, eta: 01h 28m 28s 537ms
2022-05-03T10:32:26 | INFO | mmf.trainers.callbacks.logistics : progress: 12500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0987, train/total_loss: 0.0001, train/total_loss/avg: 0.0987, max mem: 11667.0, experiment: run, epoch: 47, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 344ms, time_since_start: 02h 01m 26s 810ms, eta: 01h 27m 30s 479ms
2022-05-03T10:33:20 | INFO | mmf.trainers.callbacks.logistics : progress: 12600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0979, train/total_loss: 0.0001, train/total_loss/avg: 0.0979, max mem: 11667.0, experiment: run, epoch: 48, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 844ms, time_since_start: 02h 02m 21s 655ms, eta: 01h 27m 23s 033ms
2022-05-03T10:34:15 | INFO | mmf.trainers.callbacks.logistics : progress: 12700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0971, train/total_loss: 0.0001, train/total_loss/avg: 0.0971, max mem: 11667.0, experiment: run, epoch: 48, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 525ms, time_since_start: 02h 03m 16s 181ms, eta: 01h 25m 57s 101ms
2022-05-03T10:35:10 | INFO | mmf.trainers.callbacks.logistics : progress: 12800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0964, train/total_loss: 0.0001, train/total_loss/avg: 0.0964, max mem: 11667.0, experiment: run, epoch: 49, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 750ms, time_since_start: 02h 04m 10s 932ms, eta: 01h 25m 22s 691ms
2022-05-03T10:36:04 | INFO | mmf.trainers.callbacks.logistics : progress: 12900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0956, train/total_loss: 0.0001, train/total_loss/avg: 0.0956, max mem: 11667.0, experiment: run, epoch: 49, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 322ms, time_since_start: 02h 05m 05s 254ms, eta: 01h 23m 47s 359ms
2022-05-03T10:36:59 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T10:36:59 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T10:37:04 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T10:37:12 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T10:37:12 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0949, train/total_loss: 0.0002, train/total_loss/avg: 0.0949, max mem: 11667.0, experiment: run, epoch: 49, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0., ups: 1.47, time: 01m 08s 291ms, time_since_start: 02h 06m 13s 546ms, eta: 01h 44m 10s 758ms
2022-05-03T10:37:12 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T10:37:14 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T10:37:17 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T10:37:17 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T10:37:18 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, val/hateful_memes/cross_entropy: 2.7626, val/total_loss: 2.7626, val/hateful_memes/accuracy: 0.6333, val/hateful_memes/binary_f1: 0.2929, val/hateful_memes/roc_auc: 0.6104, num_updates: 13000, epoch: 49, iterations: 13000, max_updates: 22000, val_time: 05s 341ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.629033
2022-05-03T10:38:13 | INFO | mmf.trainers.callbacks.logistics : progress: 13100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0942, train/total_loss: 0.0001, train/total_loss/avg: 0.0942, max mem: 11667.0, experiment: run, epoch: 50, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0., ups: 1.82, time: 55s 394ms, time_since_start: 02h 07m 14s 283ms, eta: 01h 23m 33s 892ms
2022-05-03T10:39:08 | INFO | mmf.trainers.callbacks.logistics : progress: 13200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0935, train/total_loss: 0.0002, train/total_loss/avg: 0.0935, max mem: 11667.0, experiment: run, epoch: 50, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 574ms, time_since_start: 02h 08m 08s 858ms, eta: 01h 21m 24s 244ms
2022-05-03T10:40:02 | INFO | mmf.trainers.callbacks.logistics : progress: 13300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0931, train/total_loss: 0.0001, train/total_loss/avg: 0.0931, max mem: 11667.0, experiment: run, epoch: 50, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 289ms, time_since_start: 02h 09m 03s 148ms, eta: 01h 20m 03s 474ms
2022-05-03T10:40:57 | INFO | mmf.trainers.callbacks.logistics : progress: 13400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0924, train/total_loss: 0.0001, train/total_loss/avg: 0.0924, max mem: 11667.0, experiment: run, epoch: 51, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0., ups: 1.82, time: 55s 049ms, time_since_start: 02h 09m 58s 197ms, eta: 01h 20m 14s 749ms
2022-05-03T10:41:52 | INFO | mmf.trainers.callbacks.logistics : progress: 13500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0917, train/total_loss: 0.0001, train/total_loss/avg: 0.0917, max mem: 11667.0, experiment: run, epoch: 51, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 555ms, time_since_start: 02h 10m 52s 753ms, eta: 01h 18m 36s 028ms
2022-05-03T10:42:46 | INFO | mmf.trainers.callbacks.logistics : progress: 13600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0910, train/total_loss: 0.0001, train/total_loss/avg: 0.0910, max mem: 11667.0, experiment: run, epoch: 52, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 878ms, time_since_start: 02h 11m 47s 632ms, eta: 01h 18m 08s 202ms
2022-05-03T10:43:41 | INFO | mmf.trainers.callbacks.logistics : progress: 13700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0907, train/total_loss: 0.0002, train/total_loss/avg: 0.0907, max mem: 11667.0, experiment: run, epoch: 52, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 525ms, time_since_start: 02h 12m 42s 158ms, eta: 01h 16m 42s 584ms
2022-05-03T10:44:35 | INFO | mmf.trainers.callbacks.logistics : progress: 13800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0901, train/total_loss: 0.0002, train/total_loss/avg: 0.0901, max mem: 11667.0, experiment: run, epoch: 52, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 506ms, time_since_start: 02h 13m 36s 664ms, eta: 01h 15m 45s 535ms
2022-05-03T10:45:30 | INFO | mmf.trainers.callbacks.logistics : progress: 13900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0894, train/total_loss: 0.0002, train/total_loss/avg: 0.0894, max mem: 11667.0, experiment: run, epoch: 53, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0., ups: 1.85, time: 54s 941ms, time_since_start: 02h 14m 31s 606ms, eta: 01h 15m 25s 925ms
2022-05-03T10:46:25 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2022-05-03T10:46:25 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2022-05-03T10:46:31 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2022-05-03T10:46:44 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2022-05-03T10:46:44 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0888, train/total_loss: 0.0003, train/total_loss/avg: 0.0888, max mem: 11667.0, experiment: run, epoch: 53, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0., ups: 1.37, time: 01m 13s 856ms, time_since_start: 02h 15m 45s 462ms, eta: 01h 40m 08s 934ms
2022-05-03T10:46:44 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2022-05-03T10:46:44 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T10:46:48 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T10:46:48 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T10:46:48 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, val/hateful_memes/cross_entropy: 2.8171, val/total_loss: 2.8171, val/hateful_memes/accuracy: 0.6352, val/hateful_memes/binary_f1: 0.3411, val/hateful_memes/roc_auc: 0.6177, num_updates: 14000, epoch: 53, iterations: 14000, max_updates: 22000, val_time: 03s 623ms, best_update: 7000, best_iteration: 7000, best_val/hateful_memes/roc_auc: 0.629033
2022-05-03T10:47:20 | INFO | mmf : Logging to: ./save/train.log
2022-05-03T10:47:20 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/mmbt/defaults.yaml', 'model=mmbt', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2022-05-03T10:47:20 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-05-03T10:47:20 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-16GB
2022-05-03T10:47:20 | INFO | mmf_cli.run : Using seed 20123067
2022-05-03T10:47:20 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-03T10:47:23 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:47:23 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:47:23 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:47:23 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-03T10:47:35 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-03T10:47:35 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-03T10:47:35 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-05-03T10:47:43 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-05-03T10:47:43 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-05-03T10:47:43 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-05-03T10:47:43 | INFO | mmf.utils.checkpoint : Current num updates: 7000
2022-05-03T10:47:43 | INFO | mmf.utils.checkpoint : Current iteration: 7000
2022-05-03T10:47:43 | INFO | mmf.utils.checkpoint : Current epoch: 27
2022-05-03T10:47:43 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2022-05-03T10:47:43 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T10:47:44 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-05-03T10:47:44 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-05-03T10:47:55 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/drive/MyDrive/DL7643_Group_project/vilbert/hateful-memes/save/hateful_memes_mmbt_20123067/reports/hateful_memes_run_test_2022-05-03T10:47:55.csv
2022-05-03T10:47:55 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 63
2022-05-03T10:47:55 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T10:48:01 | INFO | mmf : Logging to: ./save/train.log
2022-05-03T10:48:01 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/mmbt/defaults.yaml', 'model=mmbt', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2022-05-03T10:48:01 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-05-03T10:48:01 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-16GB
2022-05-03T10:48:01 | INFO | mmf_cli.run : Using seed 1628773
2022-05-03T10:48:01 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-03T10:48:05 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:48:05 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:48:05 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:48:05 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-03T10:48:13 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-03T10:48:13 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-03T10:48:13 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-05-03T10:48:16 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-05-03T10:48:16 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-05-03T10:48:16 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-05-03T10:48:16 | INFO | mmf.utils.checkpoint : Current num updates: 7000
2022-05-03T10:48:16 | INFO | mmf.utils.checkpoint : Current iteration: 7000
2022-05-03T10:48:16 | INFO | mmf.utils.checkpoint : Current epoch: 27
2022-05-03T10:48:16 | INFO | mmf.trainers.core.evaluation_loop : Starting val inference predictions
2022-05-03T10:48:16 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T10:48:17 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-05-03T10:48:17 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-05-03T10:48:20 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/drive/MyDrive/DL7643_Group_project/vilbert/hateful-memes/save/hateful_memes_mmbt_1628773/reports/hateful_memes_run_val_2022-05-03T10:48:20.csv
2022-05-03T10:48:20 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 17
2022-05-03T10:48:20 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T10:48:32 | INFO | mmf : Logging to: ./save/train.log
2022-05-03T10:48:32 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/mmbt/defaults.yaml', 'model=mmbt', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=save/best.ckpt', 'checkpoint.resume_pretrained=False'])
2022-05-03T10:48:32 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-05-03T10:48:32 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-16GB
2022-05-03T10:48:32 | INFO | mmf_cli.run : Using seed 32291586
2022-05-03T10:48:32 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-03T10:48:35 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:48:35 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:48:35 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:48:35 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-03T10:48:44 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-03T10:48:44 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2022-05-03T10:48:44 | INFO | mmf.utils.checkpoint : Loading checkpoint
2022-05-03T10:48:47 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2022-05-03T10:48:47 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2022-05-03T10:48:47 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2022-05-03T10:48:47 | INFO | mmf.utils.checkpoint : Current num updates: 7000
2022-05-03T10:48:47 | INFO | mmf.utils.checkpoint : Current iteration: 7000
2022-05-03T10:48:47 | INFO | mmf.utils.checkpoint : Current epoch: 27
2022-05-03T10:48:47 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2022-05-03T10:48:47 | INFO | mmf.trainers.mmf_trainer : MMBT(
  (model): MMBTForClassification(
    (bert): MMBTBase(
      (mmbt): MMBTModel(
        (transformer): BertModelJit(
          (embeddings): BertEmbeddingsJit(
            (word_embeddings): Embedding(30522, 768, padding_idx=0)
            (position_embeddings): Embedding(512, 768)
            (token_type_embeddings): Embedding(2, 768)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder): BertEncoderJit(
            (layer): ModuleList(
              (0): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (1): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (2): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (3): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (4): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (5): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (6): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (7): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (8): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (9): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (10): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (11): BertLayerJit(
                (attention): BertAttentionJit(
                  (self): BertSelfAttentionJit(
                    (query): Linear(in_features=768, out_features=768, bias=True)
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(in_features=768, out_features=768, bias=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
          (pooler): BertPooler(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (activation): Tanh()
          )
        )
        (modal_encoder): ModalEmbeddings(
          (encoder): ResNet152ImageEncoder(
            (model): Sequential(
              (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
              (4): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
              (5): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
                    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (3): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (4): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (5): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (6): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (7): Bottleneck(
                  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
              (6): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
                    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (3): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (4): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (5): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (6): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (7): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (8): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (9): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (10): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (11): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (12): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (13): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (14): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (15): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (16): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (17): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (18): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (19): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (20): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (21): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (22): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (23): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (24): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (25): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (26): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (27): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (28): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (29): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (30): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (31): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (32): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (33): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (34): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (35): Bottleneck(
                  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
              (7): Sequential(
                (0): Bottleneck(
                  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                  (downsample): Sequential(
                    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
                    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  )
                )
                (1): Bottleneck(
                  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
                (2): Bottleneck(
                  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
                  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (relu): ReLU(inplace=True)
                )
              )
            )
            (pool): AdaptiveAvgPool2d(output_size=(1, 1))
          )
          (proj_embeddings): Linear(in_features=2048, out_features=768, bias=True)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Sequential(
      (0): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (1): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2022-05-03T10:48:47 | INFO | mmf.utils.general : Total Parameters: 169793346. Trained Parameters: 169793346
2022-05-03T10:48:47 | INFO | mmf.trainers.mmf_trainer : Starting inference on val set
2022-05-03T10:48:47 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2022-05-03T10:48:48 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-05-03T10:48:48 | WARNING | py.warnings : /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)

2022-05-03T10:48:50 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 17
2022-05-03T10:48:50 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2022-05-03T10:48:51 | INFO | mmf.trainers.callbacks.logistics : val/hateful_memes/cross_entropy: 2.5168, val/total_loss: 2.5168, val/hateful_memes/accuracy: 0.6389, val/hateful_memes/binary_f1: 0.2909, val/hateful_memes/roc_auc: 0.6290
2022-05-03T10:48:51 | INFO | mmf.trainers.callbacks.logistics : Finished run in 06s 464ms
2022-05-03T10:48:56 | INFO | mmf : Logging to: ./save/train.log
2022-05-03T10:48:56 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=mmf-hateful-memes/projects/hateful_memes/configs/mmbt/defaults.yaml', 'model=mmbt', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_file=save_mmbt_default/best.ckpt', 'checkpoint.resume_pretrained=False'])
2022-05-03T10:48:56 | INFO | mmf_cli.run : Torch version: 1.9.0+cu102
2022-05-03T10:48:56 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-16GB
2022-05-03T10:48:56 | INFO | mmf_cli.run : Using seed 57015931
2022-05-03T10:48:56 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2022-05-03T10:49:00 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:49:00 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:49:00 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2022-05-03T10:49:00 | INFO | mmf.trainers.mmf_trainer : Loading model
2022-05-03T10:49:09 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2022-05-03T10:49:09 | INFO | mmf.trainers.mmf_trainer : Loading metrics
